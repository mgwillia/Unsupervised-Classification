vulcan03.umiacs.umd.edu
[31m{'setup': 'simclr', 'backbone': 'resnet50', 'model_kwargs': {'head': 'mlp', 'features_dim': 128}, 'train_db_name': 'pascal-pretrained', 'val_db_name': 'pascal-pretrained', 'num_classes': 20, 'criterion': 'simclr', 'criterion_kwargs': {'temperature': 0.1}, 'epochs': 50, 'optimizer': 'sgd', 'optimizer_kwargs': {'nesterov': False, 'weight_decay': 0.0001, 'momentum': 0.9, 'lr': 0.001}, 'scheduler': 'cosine', 'scheduler_kwargs': {'lr_decay_rate': 0.1}, 'batch_size': 256, 'num_workers': 8, 'augmentation_strategy': 'simclr', 'augmentation_kwargs': {'random_resized_crop': {'size': 112, 'scale': [0.2, 1.0]}, 'color_jitter_random_apply': {'p': 0.8}, 'color_jitter': {'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}, 'random_grayscale': {'p': 0.2}, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'transformation_kwargs': {'crop_size': 112, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'pretext_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained/pretext', 'pretext_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained/pretext/checkpoint.pth.tar', 'pretext_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained/pretext/model.pth.tar', 'topk_neighbors_train_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained/pretext/topk-val-neighbors.npy'}[0m
[34mRetrieve model[0m
{'setup': 'simclr', 'backbone': 'resnet50', 'model_kwargs': {'head': 'mlp', 'features_dim': 128}, 'train_db_name': 'pascal-pretrained', 'val_db_name': 'pascal-pretrained', 'num_classes': 20, 'criterion': 'simclr', 'criterion_kwargs': {'temperature': 0.1}, 'epochs': 50, 'optimizer': 'sgd', 'optimizer_kwargs': {'nesterov': False, 'weight_decay': 0.0001, 'momentum': 0.9, 'lr': 0.001}, 'scheduler': 'cosine', 'scheduler_kwargs': {'lr_decay_rate': 0.1}, 'batch_size': 256, 'num_workers': 8, 'augmentation_strategy': 'simclr', 'augmentation_kwargs': {'random_resized_crop': {'size': 112, 'scale': [0.2, 1.0]}, 'color_jitter_random_apply': {'p': 0.8}, 'color_jitter': {'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}, 'random_grayscale': {'p': 0.2}, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'transformation_kwargs': {'crop_size': 112, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'pretext_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained/pretext', 'pretext_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained/pretext/checkpoint.pth.tar', 'pretext_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained/pretext/model.pth.tar', 'topk_neighbors_train_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained/pretext/topk-val-neighbors.npy'}
loading pretrained
Model is ContrastiveModel
Model parameters: 30.02M
ContrastiveModel(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
  (contrastive_head): Sequential(
    (0): Linear(in_features=2048, out_features=2048, bias=True)
    (1): ReLU()
    (2): Linear(in_features=2048, out_features=128, bias=True)
  )
)
[34mSet CuDNN benchmark[0m
[34mRetrieve dataset[0m
Train transforms: Compose(
    RandomResizedCrop(size=(112, 112), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)
    RandomHorizontalFlip(p=0.5)
    RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
)
    RandomGrayscale(p=0.2)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
Validation transforms: Compose(
    CenterCrop(size=(112, 112))
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
Dataset contains 15774/15774 train/val samples
[34mBuild MemoryBank[0m
[34mRetrieve criterion[0m
Criterion is SimCLRLoss
[34mRetrieve optimizer[0m
SGD (
Parameter Group 0
    dampening: 0
    lr: 0.001
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0001
)
[34mNo checkpoint file at /cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained/pretext/checkpoint.pth.tar[0m
[34mStarting main loop[0m
[33mEpoch 0/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [0][ 0/61]	Loss 5.1173e+00 (5.1173e+00)
Epoch: [0][25/61]	Loss 3.1082e+00 (3.7144e+00)
Epoch: [0][50/61]	Loss 2.5336e+00 (3.2783e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.86
Checkpoint ...
[33mEpoch 1/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [1][ 0/61]	Loss 2.4789e+00 (2.4789e+00)
Epoch: [1][25/61]	Loss 2.3841e+00 (2.4118e+00)
Epoch: [1][50/61]	Loss 2.1656e+00 (2.3436e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 88.35
Checkpoint ...
[33mEpoch 2/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [2][ 0/61]	Loss 2.1753e+00 (2.1753e+00)
Epoch: [2][25/61]	Loss 1.8336e+00 (2.1144e+00)
Epoch: [2][50/61]	Loss 2.1475e+00 (2.0806e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.13
Checkpoint ...
[33mEpoch 3/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00099
Train ...
Epoch: [3][ 0/61]	Loss 1.9533e+00 (1.9533e+00)
Epoch: [3][25/61]	Loss 1.9337e+00 (1.9325e+00)
Epoch: [3][50/61]	Loss 1.7168e+00 (1.9021e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 88.36
Checkpoint ...
[33mEpoch 4/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00098
Train ...
Epoch: [4][ 0/61]	Loss 1.9832e+00 (1.9832e+00)
Epoch: [4][25/61]	Loss 1.7884e+00 (1.8116e+00)
Epoch: [4][50/61]	Loss 1.7932e+00 (1.7854e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 88.47
Checkpoint ...
[33mEpoch 5/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00098
Train ...
Epoch: [5][ 0/61]	Loss 1.7321e+00 (1.7321e+00)
Epoch: [5][25/61]	Loss 1.8394e+00 (1.7252e+00)
Epoch: [5][50/61]	Loss 1.5931e+00 (1.7083e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 88.58
Checkpoint ...
[33mEpoch 6/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00096
Train ...
Epoch: [6][ 0/61]	Loss 1.7830e+00 (1.7830e+00)
Epoch: [6][25/61]	Loss 1.6801e+00 (1.6612e+00)
Epoch: [6][50/61]	Loss 1.7417e+00 (1.6570e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.17
Checkpoint ...
[33mEpoch 7/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00095
Train ...
Epoch: [7][ 0/61]	Loss 1.5378e+00 (1.5378e+00)
Epoch: [7][25/61]	Loss 1.7596e+00 (1.5738e+00)
Epoch: [7][50/61]	Loss 1.4918e+00 (1.5807e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 88.35
Checkpoint ...
[33mEpoch 8/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00094
Train ...
Epoch: [8][ 0/61]	Loss 1.5592e+00 (1.5592e+00)
Epoch: [8][25/61]	Loss 1.5985e+00 (1.5466e+00)
Epoch: [8][50/61]	Loss 1.5034e+00 (1.5473e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.29
Checkpoint ...
[33mEpoch 9/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00092
Train ...
Epoch: [9][ 0/61]	Loss 1.6203e+00 (1.6203e+00)
Epoch: [9][25/61]	Loss 1.5745e+00 (1.4961e+00)
Epoch: [9][50/61]	Loss 1.7089e+00 (1.5024e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 88.98
Checkpoint ...
[33mEpoch 10/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00090
Train ...
Epoch: [10][ 0/61]	Loss 1.4699e+00 (1.4699e+00)
Epoch: [10][25/61]	Loss 1.3948e+00 (1.4525e+00)
Epoch: [10][50/61]	Loss 1.4278e+00 (1.4566e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 88.96
Checkpoint ...
[33mEpoch 11/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00089
Train ...
Epoch: [11][ 0/61]	Loss 1.3771e+00 (1.3771e+00)
Epoch: [11][25/61]	Loss 1.2185e+00 (1.4332e+00)
Epoch: [11][50/61]	Loss 1.3694e+00 (1.4206e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.11
Checkpoint ...
[33mEpoch 12/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00086
Train ...
Epoch: [12][ 0/61]	Loss 1.4346e+00 (1.4346e+00)
Epoch: [12][25/61]	Loss 1.4062e+00 (1.4115e+00)
Epoch: [12][50/61]	Loss 1.2668e+00 (1.4104e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.86
Checkpoint ...
[33mEpoch 13/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00084
Train ...
Epoch: [13][ 0/61]	Loss 1.3689e+00 (1.3689e+00)
Epoch: [13][25/61]	Loss 1.2868e+00 (1.3821e+00)
Epoch: [13][50/61]	Loss 1.3334e+00 (1.3791e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.09
Checkpoint ...
[33mEpoch 14/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00082
Train ...
Epoch: [14][ 0/61]	Loss 1.3929e+00 (1.3929e+00)
Epoch: [14][25/61]	Loss 1.3193e+00 (1.3743e+00)
Epoch: [14][50/61]	Loss 1.3785e+00 (1.3510e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.28
Checkpoint ...
[33mEpoch 15/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00079
Train ...
Epoch: [15][ 0/61]	Loss 1.3084e+00 (1.3084e+00)
Epoch: [15][25/61]	Loss 1.3653e+00 (1.3646e+00)
Epoch: [15][50/61]	Loss 1.3252e+00 (1.3502e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.05
Checkpoint ...
[33mEpoch 16/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00077
Train ...
Epoch: [16][ 0/61]	Loss 1.3058e+00 (1.3058e+00)
Epoch: [16][25/61]	Loss 1.3713e+00 (1.3354e+00)
Epoch: [16][50/61]	Loss 1.2811e+00 (1.3231e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.08
Checkpoint ...
[33mEpoch 17/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00074
Train ...
Epoch: [17][ 0/61]	Loss 1.3346e+00 (1.3346e+00)
Epoch: [17][25/61]	Loss 1.4162e+00 (1.3179e+00)
Epoch: [17][50/61]	Loss 1.3137e+00 (1.3094e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.63
Checkpoint ...
[33mEpoch 18/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00071
Train ...
Epoch: [18][ 0/61]	Loss 1.2589e+00 (1.2589e+00)
Epoch: [18][25/61]	Loss 1.2288e+00 (1.3060e+00)
Epoch: [18][50/61]	Loss 1.3125e+00 (1.3035e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.39
Checkpoint ...
[33mEpoch 19/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00068
Train ...
Epoch: [19][ 0/61]	Loss 1.2257e+00 (1.2257e+00)
Epoch: [19][25/61]	Loss 1.3317e+00 (1.2877e+00)
Epoch: [19][50/61]	Loss 1.2001e+00 (1.2684e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.02
Checkpoint ...
[33mEpoch 20/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00065
Train ...
Epoch: [20][ 0/61]	Loss 1.1804e+00 (1.1804e+00)
Epoch: [20][25/61]	Loss 1.2354e+00 (1.2514e+00)
Epoch: [20][50/61]	Loss 1.3631e+00 (1.2722e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.16
Checkpoint ...
[33mEpoch 21/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00062
Train ...
Epoch: [21][ 0/61]	Loss 1.3817e+00 (1.3817e+00)
Epoch: [21][25/61]	Loss 1.1505e+00 (1.2482e+00)
Epoch: [21][50/61]	Loss 1.2256e+00 (1.2489e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.87
Checkpoint ...
[33mEpoch 22/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00059
Train ...
Epoch: [22][ 0/61]	Loss 1.1297e+00 (1.1297e+00)
Epoch: [22][25/61]	Loss 1.1815e+00 (1.2042e+00)
Epoch: [22][50/61]	Loss 1.2842e+00 (1.2255e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.88
Checkpoint ...
[33mEpoch 23/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00056
Train ...
Epoch: [23][ 0/61]	Loss 1.2546e+00 (1.2546e+00)
Epoch: [23][25/61]	Loss 1.2352e+00 (1.2206e+00)
Epoch: [23][50/61]	Loss 1.2257e+00 (1.2284e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.24
Checkpoint ...
[33mEpoch 24/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00053
Train ...
Epoch: [24][ 0/61]	Loss 1.2361e+00 (1.2361e+00)
Epoch: [24][25/61]	Loss 1.1954e+00 (1.2111e+00)
Epoch: [24][50/61]	Loss 1.1553e+00 (1.2140e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.19
Checkpoint ...
[33mEpoch 25/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00050
Train ...
Epoch: [25][ 0/61]	Loss 1.2574e+00 (1.2574e+00)
Epoch: [25][25/61]	Loss 1.1414e+00 (1.1994e+00)
Epoch: [25][50/61]	Loss 1.3260e+00 (1.2166e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.19
Checkpoint ...
[33mEpoch 26/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00047
Train ...
Epoch: [26][ 0/61]	Loss 1.1380e+00 (1.1380e+00)
Epoch: [26][25/61]	Loss 1.2006e+00 (1.2012e+00)
Epoch: [26][50/61]	Loss 1.1507e+00 (1.1996e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.72
Checkpoint ...
[33mEpoch 27/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00044
Train ...
Epoch: [27][ 0/61]	Loss 1.1924e+00 (1.1924e+00)
Epoch: [27][25/61]	Loss 1.1458e+00 (1.2012e+00)
Epoch: [27][50/61]	Loss 1.1606e+00 (1.2027e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.35
Checkpoint ...
[33mEpoch 28/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00041
Train ...
Epoch: [28][ 0/61]	Loss 1.2024e+00 (1.2024e+00)
Epoch: [28][25/61]	Loss 1.1514e+00 (1.1613e+00)
Epoch: [28][50/61]	Loss 1.3154e+00 (1.1787e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.48
Checkpoint ...
[33mEpoch 29/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00038
Train ...
Epoch: [29][ 0/61]	Loss 1.2844e+00 (1.2844e+00)
Epoch: [29][25/61]	Loss 1.2816e+00 (1.2088e+00)
Epoch: [29][50/61]	Loss 1.1449e+00 (1.2003e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 89.85
Checkpoint ...
[33mEpoch 30/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00035
Train ...
Epoch: [30][ 0/61]	Loss 1.2268e+00 (1.2268e+00)
Epoch: [30][25/61]	Loss 1.2317e+00 (1.1910e+00)
Epoch: [30][50/61]	Loss 1.0495e+00 (1.1817e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.19
Checkpoint ...
[33mEpoch 31/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00032
Train ...
Epoch: [31][ 0/61]	Loss 1.2037e+00 (1.2037e+00)
Epoch: [31][25/61]	Loss 1.0957e+00 (1.1515e+00)
Epoch: [31][50/61]	Loss 1.2886e+00 (1.1739e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.03
Checkpoint ...
[33mEpoch 32/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00029
Train ...
Epoch: [32][ 0/61]	Loss 1.2715e+00 (1.2715e+00)
Epoch: [32][25/61]	Loss 1.0243e+00 (1.1772e+00)
Epoch: [32][50/61]	Loss 1.1887e+00 (1.1705e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.07
Checkpoint ...
[33mEpoch 33/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00026
Train ...
Epoch: [33][ 0/61]	Loss 1.1969e+00 (1.1969e+00)
Epoch: [33][25/61]	Loss 1.0620e+00 (1.1590e+00)
Epoch: [33][50/61]	Loss 1.0759e+00 (1.1514e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.52
Checkpoint ...
[33mEpoch 34/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00023
Train ...
Epoch: [34][ 0/61]	Loss 1.1795e+00 (1.1795e+00)
Epoch: [34][25/61]	Loss 1.1517e+00 (1.1593e+00)
Epoch: [34][50/61]	Loss 1.2897e+00 (1.1699e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.22
Checkpoint ...
[33mEpoch 35/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00021
Train ...
Epoch: [35][ 0/61]	Loss 1.3017e+00 (1.3017e+00)
Epoch: [35][25/61]	Loss 1.1312e+00 (1.1408e+00)
Epoch: [35][50/61]	Loss 1.1590e+00 (1.1520e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.83
Checkpoint ...
[33mEpoch 36/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00018
Train ...
Epoch: [36][ 0/61]	Loss 1.1979e+00 (1.1979e+00)
Epoch: [36][25/61]	Loss 1.3074e+00 (1.1485e+00)
Epoch: [36][50/61]	Loss 1.0912e+00 (1.1394e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.47
Checkpoint ...
[33mEpoch 37/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00016
Train ...
Epoch: [37][ 0/61]	Loss 1.0948e+00 (1.0948e+00)
Epoch: [37][25/61]	Loss 1.2333e+00 (1.1525e+00)
Epoch: [37][50/61]	Loss 1.2223e+00 (1.1575e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.42
Checkpoint ...
[33mEpoch 38/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00014
Train ...
Epoch: [38][ 0/61]	Loss 1.0290e+00 (1.0290e+00)
Epoch: [38][25/61]	Loss 1.1959e+00 (1.1392e+00)
Epoch: [38][50/61]	Loss 1.0184e+00 (1.1540e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.15
Checkpoint ...
[33mEpoch 39/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00012
Train ...
Epoch: [39][ 0/61]	Loss 1.0517e+00 (1.0517e+00)
Epoch: [39][25/61]	Loss 1.1844e+00 (1.1227e+00)
Epoch: [39][50/61]	Loss 1.0817e+00 (1.1418e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.15
Checkpoint ...
[33mEpoch 40/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [40][ 0/61]	Loss 1.2005e+00 (1.2005e+00)
Epoch: [40][25/61]	Loss 1.1441e+00 (1.1528e+00)
Epoch: [40][50/61]	Loss 1.0915e+00 (1.1456e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.34
Checkpoint ...
[33mEpoch 41/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00008
Train ...
Epoch: [41][ 0/61]	Loss 1.1250e+00 (1.1250e+00)
Epoch: [41][25/61]	Loss 1.0573e+00 (1.1326e+00)
Epoch: [41][50/61]	Loss 1.0956e+00 (1.1413e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.40
Checkpoint ...
[33mEpoch 42/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00006
Train ...
Epoch: [42][ 0/61]	Loss 1.2492e+00 (1.2492e+00)
Epoch: [42][25/61]	Loss 1.1416e+00 (1.1528e+00)
Epoch: [42][50/61]	Loss 1.0786e+00 (1.1504e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.42
Checkpoint ...
[33mEpoch 43/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00005
Train ...
Epoch: [43][ 0/61]	Loss 1.0460e+00 (1.0460e+00)
Epoch: [43][25/61]	Loss 1.1059e+00 (1.1176e+00)
Epoch: [43][50/61]	Loss 1.2261e+00 (1.1299e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.78
Checkpoint ...
[33mEpoch 44/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00004
Train ...
Epoch: [44][ 0/61]	Loss 1.1888e+00 (1.1888e+00)
Epoch: [44][25/61]	Loss 1.1331e+00 (1.1377e+00)
Epoch: [44][50/61]	Loss 1.2568e+00 (1.1443e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.73
Checkpoint ...
[33mEpoch 45/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00003
Train ...
Epoch: [45][ 0/61]	Loss 1.1652e+00 (1.1652e+00)
Epoch: [45][25/61]	Loss 1.0713e+00 (1.1363e+00)
Epoch: [45][50/61]	Loss 1.0414e+00 (1.1301e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.59
Checkpoint ...
[33mEpoch 46/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00002
Train ...
Epoch: [46][ 0/61]	Loss 1.1190e+00 (1.1190e+00)
Epoch: [46][25/61]	Loss 1.1287e+00 (1.1426e+00)
Epoch: [46][50/61]	Loss 1.1080e+00 (1.1445e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.77
Checkpoint ...
[33mEpoch 47/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00001
Train ...
Epoch: [47][ 0/61]	Loss 1.3359e+00 (1.3359e+00)
Epoch: [47][25/61]	Loss 1.1282e+00 (1.1455e+00)
Epoch: [47][50/61]	Loss 1.1475e+00 (1.1411e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.67
Checkpoint ...
[33mEpoch 48/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00000
Train ...
Epoch: [48][ 0/61]	Loss 1.1296e+00 (1.1296e+00)
Epoch: [48][25/61]	Loss 1.0712e+00 (1.1390e+00)
Epoch: [48][50/61]	Loss 1.2276e+00 (1.1406e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.62
Checkpoint ...
[33mEpoch 49/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00000
Train ...
Epoch: [49][ 0/61]	Loss 1.1482e+00 (1.1482e+00)
Epoch: [49][25/61]	Loss 1.0692e+00 (1.1578e+00)
Epoch: [49][50/61]	Loss 1.2981e+00 (1.1487e+00)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 90.61
Checkpoint ...
[34mFill memory bank for mining the nearest neighbors (train) ...[0m
Fill Memory Bank [0/62]
Mine the nearest neighbors (Top-20)
Accuracy of top-20 nearest neighbors on train set is 38.45
[34mFill memory bank for mining the nearest neighbors (val) ...[0m
Fill Memory Bank [0/62]
Mine the nearest neighbors (Top-5)
Accuracy of top-5 nearest neighbors on val set is 42.87
