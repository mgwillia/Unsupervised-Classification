vulcan14.umiacs.umd.edu
[31m{'setup': 'scan', 'criterion': 'scan', 'criterion_kwargs': {'entropy_weight': 5.0}, 'update_cluster_head_only': False, 'num_heads': 1, 'backbone': 'resnet50', 'train_db_name': 'pascal-pretrained-112', 'val_db_name': 'pascal-pretrained-112', 'num_classes': 20, 'num_neighbors': 20, 'augmentation_strategy': 'ours', 'augmentation_kwargs': {'crop_size': 112, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, 'num_strong_augs': 4, 'cutout_kwargs': {'n_holes': 1, 'length': 16, 'random': True}}, 'transformation_kwargs': {'crop_size': 112, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'optimizer': 'adam', 'optimizer_kwargs': {'lr': 0.0001, 'weight_decay': 0.0001}, 'epochs': 50, 'batch_size': 128, 'num_workers': 8, 'scheduler': 'constant', 'pretext_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext', 'pretext_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/checkpoint.pth.tar', 'pretext_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/model.pth.tar', 'topk_neighbors_train_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/topk-val-neighbors.npy', 'scan_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan', 'scan_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan/checkpoint.pth.tar', 'scan_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan/model.pth.tar', 'selflabel_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/selflabel', 'selflabel_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/selflabel/checkpoint.pth.tar', 'selflabel_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/selflabel/model.pth.tar'}[0m
[34mGet dataset and dataloaders[0m
Train transforms: Compose(
    RandomHorizontalFlip(p=0.5)
    RandomCrop(size=(112, 112), padding=None)
    <data.augment.Augment object at 0x7fbe62933ac8>
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    <data.augment.Cutout object at 0x7fbe62933c18>
)
Validation transforms: Compose(
    CenterCrop(size=(112, 112))
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
Train samples 15774 - Val samples 15774
[34mGet model[0m
{'setup': 'scan', 'criterion': 'scan', 'criterion_kwargs': {'entropy_weight': 5.0}, 'update_cluster_head_only': False, 'num_heads': 1, 'backbone': 'resnet50', 'train_db_name': 'pascal-pretrained-112', 'val_db_name': 'pascal-pretrained-112', 'num_classes': 20, 'num_neighbors': 20, 'augmentation_strategy': 'ours', 'augmentation_kwargs': {'crop_size': 112, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, 'num_strong_augs': 4, 'cutout_kwargs': {'n_holes': 1, 'length': 16, 'random': True}}, 'transformation_kwargs': {'crop_size': 112, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'optimizer': 'adam', 'optimizer_kwargs': {'lr': 0.0001, 'weight_decay': 0.0001}, 'epochs': 50, 'batch_size': 128, 'num_workers': 8, 'scheduler': 'constant', 'pretext_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext', 'pretext_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/checkpoint.pth.tar', 'pretext_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/model.pth.tar', 'topk_neighbors_train_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/topk-val-neighbors.npy', 'scan_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan', 'scan_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan/checkpoint.pth.tar', 'scan_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan/model.pth.tar', 'selflabel_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/selflabel', 'selflabel_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/selflabel/checkpoint.pth.tar', 'selflabel_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/selflabel/model.pth.tar'}
loading pretrained
ClusteringModel(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
  (cluster_head): ModuleList(
    (0): Linear(in_features=2048, out_features=20, bias=True)
  )
)
[34mGet optimizer[0m
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0001
)
[34mGet loss[0m
SCANLoss(
  (softmax): Softmax(dim=1)
  (bce): BCELoss()
)
[34mNo checkpoint file at /cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan/checkpoint.pth.tar[0m
[34mStarting main loop[0m
[33mEpoch 1/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [0][  0/123]	Total Loss -1.1978e+01 (-1.1978e+01)	Consistency Loss 2.9916e+00 (2.9916e+00)	Entropy 2.9938e+00 (2.9938e+00)
Epoch: [0][ 25/123]	Total Loss -1.1984e+01 (-1.1982e+01)	Consistency Loss 2.9948e+00 (2.9945e+00)	Entropy 2.9957e+00 (2.9954e+00)
Epoch: [0][ 50/123]	Total Loss -1.1988e+01 (-1.1984e+01)	Consistency Loss 2.9904e+00 (2.9940e+00)	Entropy 2.9956e+00 (2.9955e+00)
Epoch: [0][ 75/123]	Total Loss -1.2021e+01 (-1.1989e+01)	Consistency Loss 2.9531e+00 (2.9878e+00)	Entropy 2.9949e+00 (2.9954e+00)
Epoch: [0][100/123]	Total Loss -1.2049e+01 (-1.2000e+01)	Consistency Loss 2.9276e+00 (2.9767e+00)	Entropy 2.9953e+00 (2.9954e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.8337337970733643, 'consistency': 2.4418349266052246, 'total_loss': -0.39189887046813965}], 'lowest_loss_head': 0, 'lowest_loss': -0.39189887046813965}
New lowest loss on validation set: 10000.0000 -> -0.3919
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.18695321414986688, 'ARI': 0.04773723674392969, 'NMI': 0.13123254028937026, 'ACC Top-5': 0.45486243184987957, 'hungarian_match': [(0, 18), (1, 6), (2, 8), (3, 5), (4, 7), (5, 3), (6, 13), (7, 12), (8, 4), (9, 16), (10, 1), (11, 10), (12, 11), (13, 19), (14, 0), (15, 2), (16, 9), (17, 17), (18, 15), (19, 14)]}
Checkpoint ...
[33mEpoch 2/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [1][  0/123]	Total Loss -1.2089e+01 (-1.2089e+01)	Consistency Loss 2.8821e+00 (2.8821e+00)	Entropy 2.9942e+00 (2.9942e+00)
Epoch: [1][ 25/123]	Total Loss -1.2040e+01 (-1.2054e+01)	Consistency Loss 2.9345e+00 (2.9217e+00)	Entropy 2.9950e+00 (2.9952e+00)
Epoch: [1][ 50/123]	Total Loss -1.2085e+01 (-1.2059e+01)	Consistency Loss 2.8812e+00 (2.9165e+00)	Entropy 2.9932e+00 (2.9951e+00)
Epoch: [1][ 75/123]	Total Loss -1.2036e+01 (-1.2063e+01)	Consistency Loss 2.9396e+00 (2.9119e+00)	Entropy 2.9951e+00 (2.9950e+00)
Epoch: [1][100/123]	Total Loss -1.2081e+01 (-1.2065e+01)	Consistency Loss 2.8919e+00 (2.9094e+00)	Entropy 2.9946e+00 (2.9950e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9242799282073975, 'consistency': 2.2466752529144287, 'total_loss': -0.6776046752929688}], 'lowest_loss_head': 0, 'lowest_loss': -0.6776046752929688}
New lowest loss on validation set: -0.3919 -> -0.6776
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.1721820717636617, 'ARI': 0.038819783613763384, 'NMI': 0.14041455275658574, 'ACC Top-5': 0.4717890199061747, 'hungarian_match': [(0, 1), (1, 5), (2, 17), (3, 6), (4, 3), (5, 18), (6, 14), (7, 19), (8, 9), (9, 16), (10, 8), (11, 10), (12, 7), (13, 2), (14, 0), (15, 4), (16, 13), (17, 12), (18, 15), (19, 11)]}
Checkpoint ...
[33mEpoch 3/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [2][  0/123]	Total Loss -1.2111e+01 (-1.2111e+01)	Consistency Loss 2.8644e+00 (2.8644e+00)	Entropy 2.9952e+00 (2.9952e+00)
Epoch: [2][ 25/123]	Total Loss -1.2005e+01 (-1.2084e+01)	Consistency Loss 2.9613e+00 (2.8896e+00)	Entropy 2.9932e+00 (2.9947e+00)
Epoch: [2][ 50/123]	Total Loss -1.2071e+01 (-1.2078e+01)	Consistency Loss 2.9020e+00 (2.8953e+00)	Entropy 2.9945e+00 (2.9947e+00)
Epoch: [2][ 75/123]	Total Loss -1.2103e+01 (-1.2083e+01)	Consistency Loss 2.8724e+00 (2.8910e+00)	Entropy 2.9951e+00 (2.9948e+00)
Epoch: [2][100/123]	Total Loss -1.2049e+01 (-1.2085e+01)	Consistency Loss 2.9239e+00 (2.8890e+00)	Entropy 2.9947e+00 (2.9947e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9253809452056885, 'consistency': 2.043187379837036, 'total_loss': -0.8821935653686523}], 'lowest_loss_head': 0, 'lowest_loss': -0.8821935653686523}
New lowest loss on validation set: -0.6776 -> -0.8822
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.19823760618739697, 'ARI': 0.07577461208121414, 'NMI': 0.16638715268390872, 'ACC Top-5': 0.4833269937872448, 'hungarian_match': [(0, 9), (1, 6), (2, 10), (3, 1), (4, 3), (5, 12), (6, 14), (7, 19), (8, 5), (9, 16), (10, 8), (11, 17), (12, 7), (13, 2), (14, 0), (15, 4), (16, 18), (17, 13), (18, 15), (19, 11)]}
Checkpoint ...
[33mEpoch 4/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [3][  0/123]	Total Loss -1.2127e+01 (-1.2127e+01)	Consistency Loss 2.8486e+00 (2.8486e+00)	Entropy 2.9950e+00 (2.9950e+00)
Epoch: [3][ 25/123]	Total Loss -1.2066e+01 (-1.2099e+01)	Consistency Loss 2.9098e+00 (2.8756e+00)	Entropy 2.9951e+00 (2.9948e+00)
Epoch: [3][ 50/123]	Total Loss -1.2060e+01 (-1.2098e+01)	Consistency Loss 2.9139e+00 (2.8750e+00)	Entropy 2.9949e+00 (2.9946e+00)
Epoch: [3][ 75/123]	Total Loss -1.2071e+01 (-1.2099e+01)	Consistency Loss 2.9048e+00 (2.8746e+00)	Entropy 2.9951e+00 (2.9947e+00)
Epoch: [3][100/123]	Total Loss -1.2144e+01 (-1.2101e+01)	Consistency Loss 2.8298e+00 (2.8722e+00)	Entropy 2.9947e+00 (2.9947e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9421603679656982, 'consistency': 1.976013422012329, 'total_loss': -0.9661469459533691}], 'lowest_loss_head': 0, 'lowest_loss': -0.9661469459533691}
New lowest loss on validation set: -0.8822 -> -0.9661
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.20673259794598706, 'ARI': 0.08880984901798797, 'NMI': 0.18292732964254801, 'ACC Top-5': 0.42284772410295424, 'hungarian_match': [(0, 12), (1, 5), (2, 2), (3, 6), (4, 3), (5, 19), (6, 15), (7, 4), (8, 10), (9, 18), (10, 13), (11, 17), (12, 7), (13, 8), (14, 0), (15, 14), (16, 9), (17, 1), (18, 16), (19, 11)]}
Checkpoint ...
[33mEpoch 5/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [4][  0/123]	Total Loss -1.2067e+01 (-1.2067e+01)	Consistency Loss 2.9068e+00 (2.9068e+00)	Entropy 2.9948e+00 (2.9948e+00)
Epoch: [4][ 25/123]	Total Loss -1.2084e+01 (-1.2094e+01)	Consistency Loss 2.8914e+00 (2.8791e+00)	Entropy 2.9951e+00 (2.9947e+00)
Epoch: [4][ 50/123]	Total Loss -1.2161e+01 (-1.2101e+01)	Consistency Loss 2.8022e+00 (2.8722e+00)	Entropy 2.9927e+00 (2.9946e+00)
Epoch: [4][ 75/123]	Total Loss -1.2180e+01 (-1.2100e+01)	Consistency Loss 2.7924e+00 (2.8729e+00)	Entropy 2.9944e+00 (2.9945e+00)
Epoch: [4][100/123]	Total Loss -1.2049e+01 (-1.2102e+01)	Consistency Loss 2.9273e+00 (2.8710e+00)	Entropy 2.9952e+00 (2.9945e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.918191909790039, 'consistency': 1.8312815427780151, 'total_loss': -1.086910367012024}], 'lowest_loss_head': 0, 'lowest_loss': -1.086910367012024}
New lowest loss on validation set: -0.9661 -> -1.0869
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21459363509572715, 'ARI': 0.09061018831065978, 'NMI': 0.18942096805670428, 'ACC Top-5': 0.4916951946240649, 'hungarian_match': [(0, 10), (1, 5), (2, 8), (3, 3), (4, 6), (5, 2), (6, 15), (7, 19), (8, 9), (9, 18), (10, 1), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 13), (17, 12), (18, 16), (19, 11)]}
Checkpoint ...
[33mEpoch 6/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [5][  0/123]	Total Loss -1.2154e+01 (-1.2154e+01)	Consistency Loss 2.8193e+00 (2.8193e+00)	Entropy 2.9947e+00 (2.9947e+00)
Epoch: [5][ 25/123]	Total Loss -1.2161e+01 (-1.2123e+01)	Consistency Loss 2.8147e+00 (2.8484e+00)	Entropy 2.9950e+00 (2.9942e+00)
Epoch: [5][ 50/123]	Total Loss -1.2060e+01 (-1.2113e+01)	Consistency Loss 2.9123e+00 (2.8572e+00)	Entropy 2.9945e+00 (2.9941e+00)
Epoch: [5][ 75/123]	Total Loss -1.2094e+01 (-1.2111e+01)	Consistency Loss 2.8789e+00 (2.8600e+00)	Entropy 2.9945e+00 (2.9942e+00)
Epoch: [5][100/123]	Total Loss -1.2090e+01 (-1.2110e+01)	Consistency Loss 2.8844e+00 (2.8618e+00)	Entropy 2.9948e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.940338134765625, 'consistency': 1.830793857574463, 'total_loss': -1.109544277191162}], 'lowest_loss_head': 0, 'lowest_loss': -1.109544277191162}
New lowest loss on validation set: -1.0869 -> -1.1095
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.23272473690883733, 'ARI': 0.09917925036327925, 'NMI': 0.19358283176026286, 'ACC Top-5': 0.5157220742994801, 'hungarian_match': [(0, 1), (1, 5), (2, 10), (3, 19), (4, 6), (5, 8), (6, 15), (7, 2), (8, 3), (9, 18), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 9), (17, 16), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 7/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [6][  0/123]	Total Loss -1.2067e+01 (-1.2067e+01)	Consistency Loss 2.9069e+00 (2.9069e+00)	Entropy 2.9948e+00 (2.9948e+00)
Epoch: [6][ 25/123]	Total Loss -1.2044e+01 (-1.2106e+01)	Consistency Loss 2.9322e+00 (2.8654e+00)	Entropy 2.9952e+00 (2.9942e+00)
Epoch: [6][ 50/123]	Total Loss -1.2153e+01 (-1.2112e+01)	Consistency Loss 2.8231e+00 (2.8594e+00)	Entropy 2.9952e+00 (2.9943e+00)
Epoch: [6][ 75/123]	Total Loss -1.2145e+01 (-1.2113e+01)	Consistency Loss 2.8288e+00 (2.8594e+00)	Entropy 2.9947e+00 (2.9944e+00)
Epoch: [6][100/123]	Total Loss -1.2200e+01 (-1.2114e+01)	Consistency Loss 2.7770e+00 (2.8584e+00)	Entropy 2.9955e+00 (2.9945e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9378163814544678, 'consistency': 1.8168853521347046, 'total_loss': -1.1209310293197632}], 'lowest_loss_head': 0, 'lowest_loss': -1.1209310293197632}
New lowest loss on validation set: -1.1095 -> -1.1209
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2379865601622924, 'ARI': 0.10464704496921232, 'NMI': 0.1923537341858481, 'ACC Top-5': 0.5025358184354001, 'hungarian_match': [(0, 18), (1, 5), (2, 10), (3, 1), (4, 6), (5, 8), (6, 15), (7, 2), (8, 19), (9, 12), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 3), (17, 9), (18, 16), (19, 11)]}
Checkpoint ...
[33mEpoch 8/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [7][  0/123]	Total Loss -1.2173e+01 (-1.2173e+01)	Consistency Loss 2.7990e+00 (2.7990e+00)	Entropy 2.9944e+00 (2.9944e+00)
Epoch: [7][ 25/123]	Total Loss -1.2159e+01 (-1.2111e+01)	Consistency Loss 2.8153e+00 (2.8602e+00)	Entropy 2.9948e+00 (2.9942e+00)
Epoch: [7][ 50/123]	Total Loss -1.2114e+01 (-1.2117e+01)	Consistency Loss 2.8590e+00 (2.8540e+00)	Entropy 2.9946e+00 (2.9943e+00)
Epoch: [7][ 75/123]	Total Loss -1.2147e+01 (-1.2123e+01)	Consistency Loss 2.8220e+00 (2.8494e+00)	Entropy 2.9938e+00 (2.9944e+00)
Epoch: [7][100/123]	Total Loss -1.2080e+01 (-1.2123e+01)	Consistency Loss 2.8818e+00 (2.8481e+00)	Entropy 2.9924e+00 (2.9942e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.917556047439575, 'consistency': 1.7735283374786377, 'total_loss': -1.1440277099609375}], 'lowest_loss_head': 0, 'lowest_loss': -1.1440277099609375}
New lowest loss on validation set: -1.1209 -> -1.1440
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2306326866996323, 'ARI': 0.09079011496076245, 'NMI': 0.19423169437242263, 'ACC Top-5': 0.504501077722835, 'hungarian_match': [(0, 18), (1, 5), (2, 8), (3, 9), (4, 6), (5, 12), (6, 2), (7, 19), (8, 3), (9, 10), (10, 1), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 13), (17, 16), (18, 15), (19, 11)]}
Checkpoint ...
[33mEpoch 9/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [8][  0/123]	Total Loss -1.2130e+01 (-1.2130e+01)	Consistency Loss 2.8456e+00 (2.8456e+00)	Entropy 2.9950e+00 (2.9950e+00)
Epoch: [8][ 25/123]	Total Loss -1.2140e+01 (-1.2125e+01)	Consistency Loss 2.8340e+00 (2.8477e+00)	Entropy 2.9949e+00 (2.9944e+00)
Epoch: [8][ 50/123]	Total Loss -1.2071e+01 (-1.2122e+01)	Consistency Loss 2.8973e+00 (2.8506e+00)	Entropy 2.9936e+00 (2.9945e+00)
Epoch: [8][ 75/123]	Total Loss -1.2183e+01 (-1.2121e+01)	Consistency Loss 2.7889e+00 (2.8509e+00)	Entropy 2.9943e+00 (2.9945e+00)
Epoch: [8][100/123]	Total Loss -1.2098e+01 (-1.2121e+01)	Consistency Loss 2.8734e+00 (2.8511e+00)	Entropy 2.9942e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.944932460784912, 'consistency': 1.8320659399032593, 'total_loss': -1.1128665208816528}], 'lowest_loss_head': 0, 'lowest_loss': -1.1128665208816528}
No new lowest loss on validation set: -1.1440 -> -1.1129
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21484721693926714, 'ARI': 0.08538643357952595, 'NMI': 0.1939475264084238, 'ACC Top-5': 0.4904906808672499, 'hungarian_match': [(0, 18), (1, 5), (2, 10), (3, 1), (4, 6), (5, 2), (6, 15), (7, 8), (8, 19), (9, 16), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 3), (17, 9), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 10/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [9][  0/123]	Total Loss -1.2143e+01 (-1.2143e+01)	Consistency Loss 2.8303e+00 (2.8303e+00)	Entropy 2.9946e+00 (2.9946e+00)
Epoch: [9][ 25/123]	Total Loss -1.2124e+01 (-1.2118e+01)	Consistency Loss 2.8508e+00 (2.8544e+00)	Entropy 2.9950e+00 (2.9945e+00)
Epoch: [9][ 50/123]	Total Loss -1.2084e+01 (-1.2112e+01)	Consistency Loss 2.8886e+00 (2.8609e+00)	Entropy 2.9946e+00 (2.9945e+00)
Epoch: [9][ 75/123]	Total Loss -1.2198e+01 (-1.2112e+01)	Consistency Loss 2.7702e+00 (2.8603e+00)	Entropy 2.9937e+00 (2.9944e+00)
Epoch: [9][100/123]	Total Loss -1.2153e+01 (-1.2116e+01)	Consistency Loss 2.8215e+00 (2.8559e+00)	Entropy 2.9949e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.913757801055908, 'consistency': 1.777164101600647, 'total_loss': -1.1365936994552612}], 'lowest_loss_head': 0, 'lowest_loss': -1.1365936994552612}
No new lowest loss on validation set: -1.1440 -> -1.1366
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2211867630277672, 'ARI': 0.08672748946442094, 'NMI': 0.19711735451469292, 'ACC Top-5': 0.5136934195511601, 'hungarian_match': [(0, 18), (1, 5), (2, 10), (3, 1), (4, 6), (5, 8), (6, 12), (7, 19), (8, 3), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 9), (17, 16), (18, 15), (19, 11)]}
Checkpoint ...
[33mEpoch 11/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [10][  0/123]	Total Loss -1.2027e+01 (-1.2027e+01)	Consistency Loss 2.9488e+00 (2.9488e+00)	Entropy 2.9951e+00 (2.9951e+00)
Epoch: [10][ 25/123]	Total Loss -1.2115e+01 (-1.2118e+01)	Consistency Loss 2.8588e+00 (2.8546e+00)	Entropy 2.9948e+00 (2.9946e+00)
Epoch: [10][ 50/123]	Total Loss -1.2121e+01 (-1.2120e+01)	Consistency Loss 2.8505e+00 (2.8526e+00)	Entropy 2.9944e+00 (2.9945e+00)
Epoch: [10][ 75/123]	Total Loss -1.2085e+01 (-1.2123e+01)	Consistency Loss 2.8910e+00 (2.8500e+00)	Entropy 2.9951e+00 (2.9945e+00)
Epoch: [10][100/123]	Total Loss -1.2151e+01 (-1.2120e+01)	Consistency Loss 2.8214e+00 (2.8527e+00)	Entropy 2.9944e+00 (2.9945e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.925184488296509, 'consistency': 1.7235502004623413, 'total_loss': -1.2016342878341675}], 'lowest_loss_head': 0, 'lowest_loss': -1.2016342878341675}
New lowest loss on validation set: -1.1440 -> -1.2016
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.20717636617218207, 'ARI': 0.08137124641016318, 'NMI': 0.20497140880709036, 'ACC Top-5': 0.5083682008368201, 'hungarian_match': [(0, 18), (1, 5), (2, 10), (3, 3), (4, 6), (5, 8), (6, 15), (7, 16), (8, 19), (9, 2), (10, 1), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 13), (17, 9), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 12/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [11][  0/123]	Total Loss -1.2174e+01 (-1.2174e+01)	Consistency Loss 2.7919e+00 (2.7919e+00)	Entropy 2.9932e+00 (2.9932e+00)
Epoch: [11][ 25/123]	Total Loss -1.2098e+01 (-1.2130e+01)	Consistency Loss 2.8736e+00 (2.8409e+00)	Entropy 2.9943e+00 (2.9942e+00)
Epoch: [11][ 50/123]	Total Loss -1.2088e+01 (-1.2130e+01)	Consistency Loss 2.8849e+00 (2.8415e+00)	Entropy 2.9947e+00 (2.9944e+00)
Epoch: [11][ 75/123]	Total Loss -1.2131e+01 (-1.2131e+01)	Consistency Loss 2.8447e+00 (2.8410e+00)	Entropy 2.9952e+00 (2.9944e+00)
Epoch: [11][100/123]	Total Loss -1.2126e+01 (-1.2127e+01)	Consistency Loss 2.8455e+00 (2.8447e+00)	Entropy 2.9944e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9328489303588867, 'consistency': 1.7286128997802734, 'total_loss': -1.2042360305786133}], 'lowest_loss_head': 0, 'lowest_loss': -1.2042360305786133}
New lowest loss on validation set: -1.2016 -> -1.2042
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.22473690883732725, 'ARI': 0.09727791071048353, 'NMI': 0.20579285194163632, 'ACC Top-5': 0.5110308101939901, 'hungarian_match': [(0, 18), (1, 5), (2, 8), (3, 3), (4, 6), (5, 10), (6, 15), (7, 2), (8, 19), (9, 16), (10, 1), (11, 17), (12, 7), (13, 14), (14, 0), (15, 9), (16, 13), (17, 4), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 13/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [12][  0/123]	Total Loss -1.2122e+01 (-1.2122e+01)	Consistency Loss 2.8503e+00 (2.8503e+00)	Entropy 2.9944e+00 (2.9944e+00)
Epoch: [12][ 25/123]	Total Loss -1.2093e+01 (-1.2137e+01)	Consistency Loss 2.8817e+00 (2.8336e+00)	Entropy 2.9950e+00 (2.9942e+00)
Epoch: [12][ 50/123]	Total Loss -1.2156e+01 (-1.2133e+01)	Consistency Loss 2.8188e+00 (2.8372e+00)	Entropy 2.9950e+00 (2.9940e+00)
Epoch: [12][ 75/123]	Total Loss -1.2117e+01 (-1.2130e+01)	Consistency Loss 2.8544e+00 (2.8402e+00)	Entropy 2.9944e+00 (2.9940e+00)
Epoch: [12][100/123]	Total Loss -1.2084e+01 (-1.2133e+01)	Consistency Loss 2.8740e+00 (2.8378e+00)	Entropy 2.9916e+00 (2.9941e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.928873300552368, 'consistency': 1.7526679039001465, 'total_loss': -1.1762053966522217}], 'lowest_loss_head': 0, 'lowest_loss': -1.1762053966522217}
No new lowest loss on validation set: -1.2042 -> -1.1762
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.22353239508051223, 'ARI': 0.09531700399607347, 'NMI': 0.2011091415377311, 'ACC Top-5': 0.5155952833777101, 'hungarian_match': [(0, 10), (1, 18), (2, 8), (3, 1), (4, 6), (5, 5), (6, 15), (7, 2), (8, 3), (9, 16), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 9), (17, 19), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 14/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [13][  0/123]	Total Loss -1.2110e+01 (-1.2110e+01)	Consistency Loss 2.8616e+00 (2.8616e+00)	Entropy 2.9944e+00 (2.9944e+00)
Epoch: [13][ 25/123]	Total Loss -1.2069e+01 (-1.2113e+01)	Consistency Loss 2.9030e+00 (2.8594e+00)	Entropy 2.9945e+00 (2.9945e+00)
Epoch: [13][ 50/123]	Total Loss -1.2144e+01 (-1.2121e+01)	Consistency Loss 2.8296e+00 (2.8513e+00)	Entropy 2.9946e+00 (2.9944e+00)
Epoch: [13][ 75/123]	Total Loss -1.2163e+01 (-1.2126e+01)	Consistency Loss 2.8132e+00 (2.8461e+00)	Entropy 2.9953e+00 (2.9944e+00)
Epoch: [13][100/123]	Total Loss -1.2115e+01 (-1.2128e+01)	Consistency Loss 2.8584e+00 (2.8436e+00)	Entropy 2.9947e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.908820390701294, 'consistency': 1.6523399353027344, 'total_loss': -1.2564804553985596}], 'lowest_loss_head': 0, 'lowest_loss': -1.2564804553985596}
New lowest loss on validation set: -1.2042 -> -1.2565
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.22480030429821224, 'ARI': 0.08691818215681796, 'NMI': 0.2063218125903444, 'ACC Top-5': 0.5169899835171802, 'hungarian_match': [(0, 18), (1, 5), (2, 10), (3, 3), (4, 6), (5, 8), (6, 15), (7, 16), (8, 19), (9, 2), (10, 1), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 13), (17, 9), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 15/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [14][  0/123]	Total Loss -1.2137e+01 (-1.2137e+01)	Consistency Loss 2.8343e+00 (2.8343e+00)	Entropy 2.9942e+00 (2.9942e+00)
Epoch: [14][ 25/123]	Total Loss -1.2109e+01 (-1.2134e+01)	Consistency Loss 2.8626e+00 (2.8364e+00)	Entropy 2.9943e+00 (2.9940e+00)
Epoch: [14][ 50/123]	Total Loss -1.2104e+01 (-1.2130e+01)	Consistency Loss 2.8678e+00 (2.8401e+00)	Entropy 2.9944e+00 (2.9941e+00)
Epoch: [14][ 75/123]	Total Loss -1.2047e+01 (-1.2126e+01)	Consistency Loss 2.9192e+00 (2.8447e+00)	Entropy 2.9933e+00 (2.9941e+00)
Epoch: [14][100/123]	Total Loss -1.2147e+01 (-1.2126e+01)	Consistency Loss 2.8205e+00 (2.8449e+00)	Entropy 2.9935e+00 (2.9941e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9442217350006104, 'consistency': 1.7070684432983398, 'total_loss': -1.2371532917022705}], 'lowest_loss_head': 0, 'lowest_loss': -1.2371532917022705}
No new lowest loss on validation set: -1.2565 -> -1.2372
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2183339672879422, 'ARI': 0.09443066069080497, 'NMI': 0.20850660164337906, 'ACC Top-5': 0.5214910612400152, 'hungarian_match': [(0, 10), (1, 18), (2, 8), (3, 3), (4, 6), (5, 5), (6, 16), (7, 4), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 9), (16, 15), (17, 1), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 16/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [15][  0/123]	Total Loss -1.2149e+01 (-1.2149e+01)	Consistency Loss 2.8192e+00 (2.8192e+00)	Entropy 2.9936e+00 (2.9936e+00)
Epoch: [15][ 25/123]	Total Loss -1.2226e+01 (-1.2132e+01)	Consistency Loss 2.7379e+00 (2.8382e+00)	Entropy 2.9927e+00 (2.9941e+00)
Epoch: [15][ 50/123]	Total Loss -1.2030e+01 (-1.2129e+01)	Consistency Loss 2.9373e+00 (2.8419e+00)	Entropy 2.9935e+00 (2.9942e+00)
Epoch: [15][ 75/123]	Total Loss -1.2145e+01 (-1.2131e+01)	Consistency Loss 2.8209e+00 (2.8395e+00)	Entropy 2.9933e+00 (2.9942e+00)
Epoch: [15][100/123]	Total Loss -1.2133e+01 (-1.2130e+01)	Consistency Loss 2.8420e+00 (2.8408e+00)	Entropy 2.9951e+00 (2.9942e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9330291748046875, 'consistency': 1.646984577178955, 'total_loss': -1.2860445976257324}], 'lowest_loss_head': 0, 'lowest_loss': -1.2860445976257324}
New lowest loss on validation set: -1.2565 -> -1.2860
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.23646506910105236, 'ARI': 0.11243365475068448, 'NMI': 0.21689176578100355, 'ACC Top-5': 0.50202865474832, 'hungarian_match': [(0, 1), (1, 5), (2, 10), (3, 3), (4, 6), (5, 8), (6, 16), (7, 4), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 9), (16, 18), (17, 12), (18, 15), (19, 11)]}
Checkpoint ...
[33mEpoch 17/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [16][  0/123]	Total Loss -1.2140e+01 (-1.2140e+01)	Consistency Loss 2.8236e+00 (2.8236e+00)	Entropy 2.9926e+00 (2.9926e+00)
Epoch: [16][ 25/123]	Total Loss -1.2078e+01 (-1.2134e+01)	Consistency Loss 2.8926e+00 (2.8364e+00)	Entropy 2.9941e+00 (2.9940e+00)
Epoch: [16][ 50/123]	Total Loss -1.2179e+01 (-1.2130e+01)	Consistency Loss 2.7963e+00 (2.8413e+00)	Entropy 2.9950e+00 (2.9942e+00)
Epoch: [16][ 75/123]	Total Loss -1.2172e+01 (-1.2129e+01)	Consistency Loss 2.8021e+00 (2.8418e+00)	Entropy 2.9948e+00 (2.9942e+00)
Epoch: [16][100/123]	Total Loss -1.2113e+01 (-1.2128e+01)	Consistency Loss 2.8593e+00 (2.8430e+00)	Entropy 2.9946e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.946549654006958, 'consistency': 1.746414065361023, 'total_loss': -1.200135588645935}], 'lowest_loss_head': 0, 'lowest_loss': -1.200135588645935}
No new lowest loss on validation set: -1.2860 -> -1.2001
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.23196399137821733, 'ARI': 0.10361484237696296, 'NMI': 0.21111375689772535, 'ACC Top-5': 0.5129960694814252, 'hungarian_match': [(0, 18), (1, 5), (2, 10), (3, 3), (4, 6), (5, 8), (6, 16), (7, 4), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 9), (16, 15), (17, 1), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 18/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [17][  0/123]	Total Loss -1.2215e+01 (-1.2215e+01)	Consistency Loss 2.7577e+00 (2.7577e+00)	Entropy 2.9946e+00 (2.9946e+00)
Epoch: [17][ 25/123]	Total Loss -1.2120e+01 (-1.2156e+01)	Consistency Loss 2.8559e+00 (2.8165e+00)	Entropy 2.9951e+00 (2.9944e+00)
Epoch: [17][ 50/123]	Total Loss -1.2075e+01 (-1.2140e+01)	Consistency Loss 2.8954e+00 (2.8320e+00)	Entropy 2.9942e+00 (2.9944e+00)
Epoch: [17][ 75/123]	Total Loss -1.2131e+01 (-1.2133e+01)	Consistency Loss 2.8401e+00 (2.8393e+00)	Entropy 2.9942e+00 (2.9944e+00)
Epoch: [17][100/123]	Total Loss -1.2077e+01 (-1.2130e+01)	Consistency Loss 2.8963e+00 (2.8417e+00)	Entropy 2.9946e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9484715461730957, 'consistency': 1.673925757408142, 'total_loss': -1.2745457887649536}], 'lowest_loss_head': 0, 'lowest_loss': -1.2745457887649536}
No new lowest loss on validation set: -1.2860 -> -1.2745
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.22384937238493724, 'ARI': 0.09367972876248752, 'NMI': 0.21302619189628805, 'ACC Top-5': 0.5187016609610752, 'hungarian_match': [(0, 18), (1, 5), (2, 8), (3, 1), (4, 6), (5, 10), (6, 16), (7, 4), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 9), (16, 3), (17, 15), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 19/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [18][  0/123]	Total Loss -1.2132e+01 (-1.2132e+01)	Consistency Loss 2.8388e+00 (2.8388e+00)	Entropy 2.9941e+00 (2.9941e+00)
Epoch: [18][ 25/123]	Total Loss -1.2057e+01 (-1.2124e+01)	Consistency Loss 2.9152e+00 (2.8476e+00)	Entropy 2.9944e+00 (2.9943e+00)
Epoch: [18][ 50/123]	Total Loss -1.2071e+01 (-1.2129e+01)	Consistency Loss 2.9031e+00 (2.8431e+00)	Entropy 2.9948e+00 (2.9944e+00)
Epoch: [18][ 75/123]	Total Loss -1.2227e+01 (-1.2135e+01)	Consistency Loss 2.7466e+00 (2.8375e+00)	Entropy 2.9947e+00 (2.9944e+00)
Epoch: [18][100/123]	Total Loss -1.2156e+01 (-1.2137e+01)	Consistency Loss 2.8162e+00 (2.8351e+00)	Entropy 2.9945e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.940955638885498, 'consistency': 1.6627190113067627, 'total_loss': -1.2782366275787354}], 'lowest_loss_head': 0, 'lowest_loss': -1.2782366275787354}
No new lowest loss on validation set: -1.2860 -> -1.2782
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.20635222518067706, 'ARI': 0.07556311618493042, 'NMI': 0.2084391093951888, 'ACC Top-5': 0.5051984277925701, 'hungarian_match': [(0, 18), (1, 5), (2, 8), (3, 13), (4, 6), (5, 10), (6, 16), (7, 15), (8, 19), (9, 2), (10, 1), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 3), (17, 9), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 20/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [19][  0/123]	Total Loss -1.2201e+01 (-1.2201e+01)	Consistency Loss 2.7736e+00 (2.7736e+00)	Entropy 2.9950e+00 (2.9950e+00)
Epoch: [19][ 25/123]	Total Loss -1.2125e+01 (-1.2137e+01)	Consistency Loss 2.8490e+00 (2.8353e+00)	Entropy 2.9947e+00 (2.9945e+00)
Epoch: [19][ 50/123]	Total Loss -1.2126e+01 (-1.2136e+01)	Consistency Loss 2.8473e+00 (2.8355e+00)	Entropy 2.9946e+00 (2.9943e+00)
Epoch: [19][ 75/123]	Total Loss -1.2089e+01 (-1.2135e+01)	Consistency Loss 2.8852e+00 (2.8363e+00)	Entropy 2.9948e+00 (2.9943e+00)
Epoch: [19][100/123]	Total Loss -1.2199e+01 (-1.2136e+01)	Consistency Loss 2.7751e+00 (2.8357e+00)	Entropy 2.9948e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9276552200317383, 'consistency': 1.6728906631469727, 'total_loss': -1.2547645568847656}], 'lowest_loss_head': 0, 'lowest_loss': -1.2547645568847656}
No new lowest loss on validation set: -1.2860 -> -1.2548
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21180423481678712, 'ARI': 0.07742494366188918, 'NMI': 0.21045089401192463, 'ACC Top-5': 0.5295422847724103, 'hungarian_match': [(0, 5), (1, 18), (2, 10), (3, 3), (4, 6), (5, 8), (6, 16), (7, 2), (8, 19), (9, 12), (10, 1), (11, 17), (12, 7), (13, 14), (14, 0), (15, 9), (16, 15), (17, 4), (18, 13), (19, 11)]}
Checkpoint ...
[33mEpoch 21/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [20][  0/123]	Total Loss -1.2191e+01 (-1.2191e+01)	Consistency Loss 2.7821e+00 (2.7821e+00)	Entropy 2.9945e+00 (2.9945e+00)
Epoch: [20][ 25/123]	Total Loss -1.2113e+01 (-1.2149e+01)	Consistency Loss 2.8604e+00 (2.8221e+00)	Entropy 2.9947e+00 (2.9943e+00)
Epoch: [20][ 50/123]	Total Loss -1.2136e+01 (-1.2143e+01)	Consistency Loss 2.8360e+00 (2.8278e+00)	Entropy 2.9945e+00 (2.9942e+00)
Epoch: [20][ 75/123]	Total Loss -1.2116e+01 (-1.2135e+01)	Consistency Loss 2.8579e+00 (2.8358e+00)	Entropy 2.9947e+00 (2.9943e+00)
Epoch: [20][100/123]	Total Loss -1.2088e+01 (-1.2139e+01)	Consistency Loss 2.8857e+00 (2.8322e+00)	Entropy 2.9947e+00 (2.9942e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.931715726852417, 'consistency': 1.6419358253479004, 'total_loss': -1.2897799015045166}], 'lowest_loss_head': 0, 'lowest_loss': -1.2897799015045166}
New lowest loss on validation set: -1.2860 -> -1.2898
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21605173069608216, 'ARI': 0.08116248071108853, 'NMI': 0.2103622563101446, 'ACC Top-5': 0.496893622416635, 'hungarian_match': [(0, 10), (1, 18), (2, 8), (3, 1), (4, 6), (5, 4), (6, 16), (7, 15), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 9), (16, 3), (17, 5), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 22/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [21][  0/123]	Total Loss -1.2137e+01 (-1.2137e+01)	Consistency Loss 2.8283e+00 (2.8283e+00)	Entropy 2.9930e+00 (2.9930e+00)
Epoch: [21][ 25/123]	Total Loss -1.2229e+01 (-1.2139e+01)	Consistency Loss 2.7443e+00 (2.8330e+00)	Entropy 2.9947e+00 (2.9944e+00)
Epoch: [21][ 50/123]	Total Loss -1.2126e+01 (-1.2141e+01)	Consistency Loss 2.8453e+00 (2.8308e+00)	Entropy 2.9943e+00 (2.9943e+00)
Epoch: [21][ 75/123]	Total Loss -1.2132e+01 (-1.2144e+01)	Consistency Loss 2.8390e+00 (2.8279e+00)	Entropy 2.9942e+00 (2.9944e+00)
Epoch: [21][100/123]	Total Loss -1.2121e+01 (-1.2145e+01)	Consistency Loss 2.8528e+00 (2.8262e+00)	Entropy 2.9948e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9447762966156006, 'consistency': 1.6611628532409668, 'total_loss': -1.2836134433746338}], 'lowest_loss_head': 0, 'lowest_loss': -1.2836134433746338}
No new lowest loss on validation set: -1.2898 -> -1.2836
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21706605807024218, 'ARI': 0.08926408004401218, 'NMI': 0.20973416179640617, 'ACC Top-5': 0.504501077722835, 'hungarian_match': [(0, 9), (1, 5), (2, 10), (3, 1), (4, 6), (5, 8), (6, 16), (7, 15), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 3), (17, 18), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 23/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [22][  0/123]	Total Loss -1.2161e+01 (-1.2161e+01)	Consistency Loss 2.8099e+00 (2.8099e+00)	Entropy 2.9941e+00 (2.9941e+00)
Epoch: [22][ 25/123]	Total Loss -1.2041e+01 (-1.2131e+01)	Consistency Loss 2.9289e+00 (2.8398e+00)	Entropy 2.9939e+00 (2.9941e+00)
Epoch: [22][ 50/123]	Total Loss -1.2079e+01 (-1.2133e+01)	Consistency Loss 2.8930e+00 (2.8374e+00)	Entropy 2.9944e+00 (2.9941e+00)
Epoch: [22][ 75/123]	Total Loss -1.2214e+01 (-1.2133e+01)	Consistency Loss 2.7554e+00 (2.8383e+00)	Entropy 2.9939e+00 (2.9942e+00)
Epoch: [22][100/123]	Total Loss -1.2040e+01 (-1.2135e+01)	Consistency Loss 2.9285e+00 (2.8360e+00)	Entropy 2.9936e+00 (2.9942e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9466969966888428, 'consistency': 1.6744776964187622, 'total_loss': -1.2722193002700806}], 'lowest_loss_head': 0, 'lowest_loss': -1.2722193002700806}
No new lowest loss on validation set: -1.2898 -> -1.2722
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2303157093952073, 'ARI': 0.09231453699193569, 'NMI': 0.2164972097153149, 'ACC Top-5': 0.5165462152909852, 'hungarian_match': [(0, 18), (1, 5), (2, 8), (3, 1), (4, 6), (5, 10), (6, 16), (7, 15), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 3), (17, 9), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 24/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [23][  0/123]	Total Loss -1.2139e+01 (-1.2139e+01)	Consistency Loss 2.8363e+00 (2.8363e+00)	Entropy 2.9950e+00 (2.9950e+00)
Epoch: [23][ 25/123]	Total Loss -1.2145e+01 (-1.2143e+01)	Consistency Loss 2.8201e+00 (2.8268e+00)	Entropy 2.9931e+00 (2.9940e+00)
Epoch: [23][ 50/123]	Total Loss -1.2182e+01 (-1.2139e+01)	Consistency Loss 2.7916e+00 (2.8318e+00)	Entropy 2.9947e+00 (2.9941e+00)
Epoch: [23][ 75/123]	Total Loss -1.2079e+01 (-1.2141e+01)	Consistency Loss 2.8894e+00 (2.8300e+00)	Entropy 2.9937e+00 (2.9941e+00)
Epoch: [23][100/123]	Total Loss -1.2182e+01 (-1.2136e+01)	Consistency Loss 2.7881e+00 (2.8343e+00)	Entropy 2.9940e+00 (2.9942e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9456679821014404, 'consistency': 1.6729154586791992, 'total_loss': -1.2727525234222412}], 'lowest_loss_head': 0, 'lowest_loss': -1.2727525234222412}
No new lowest loss on validation set: -1.2898 -> -1.2728
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21256498034740712, 'ARI': 0.08175602302371036, 'NMI': 0.2112368484953269, 'ACC Top-5': 0.495752504120705, 'hungarian_match': [(0, 18), (1, 5), (2, 8), (3, 3), (4, 6), (5, 10), (6, 16), (7, 4), (8, 19), (9, 2), (10, 1), (11, 17), (12, 7), (13, 14), (14, 0), (15, 15), (16, 13), (17, 9), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 25/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [24][  0/123]	Total Loss -1.2105e+01 (-1.2105e+01)	Consistency Loss 2.8672e+00 (2.8672e+00)	Entropy 2.9945e+00 (2.9945e+00)
Epoch: [24][ 25/123]	Total Loss -1.2095e+01 (-1.2126e+01)	Consistency Loss 2.8745e+00 (2.8453e+00)	Entropy 2.9939e+00 (2.9942e+00)
Epoch: [24][ 50/123]	Total Loss -1.2120e+01 (-1.2128e+01)	Consistency Loss 2.8505e+00 (2.8431e+00)	Entropy 2.9942e+00 (2.9942e+00)
Epoch: [24][ 75/123]	Total Loss -1.2088e+01 (-1.2138e+01)	Consistency Loss 2.8841e+00 (2.8326e+00)	Entropy 2.9943e+00 (2.9942e+00)
Epoch: [24][100/123]	Total Loss -1.2124e+01 (-1.2139e+01)	Consistency Loss 2.8476e+00 (2.8317e+00)	Entropy 2.9944e+00 (2.9942e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9227402210235596, 'consistency': 1.6350679397583008, 'total_loss': -1.2876722812652588}], 'lowest_loss_head': 0, 'lowest_loss': -1.2876722812652588}
No new lowest loss on validation set: -1.2898 -> -1.2877
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2296183593254723, 'ARI': 0.0860949194147408, 'NMI': 0.2138740637985133, 'ACC Top-5': 0.5077976416888551, 'hungarian_match': [(0, 10), (1, 5), (2, 8), (3, 3), (4, 6), (5, 18), (6, 16), (7, 15), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 1), (17, 9), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 26/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [25][  0/123]	Total Loss -1.2154e+01 (-1.2154e+01)	Consistency Loss 2.8196e+00 (2.8196e+00)	Entropy 2.9946e+00 (2.9946e+00)
Epoch: [25][ 25/123]	Total Loss -1.2105e+01 (-1.2137e+01)	Consistency Loss 2.8677e+00 (2.8359e+00)	Entropy 2.9945e+00 (2.9945e+00)
Epoch: [25][ 50/123]	Total Loss -1.2150e+01 (-1.2135e+01)	Consistency Loss 2.8246e+00 (2.8373e+00)	Entropy 2.9950e+00 (2.9944e+00)
Epoch: [25][ 75/123]	Total Loss -1.2124e+01 (-1.2139e+01)	Consistency Loss 2.8494e+00 (2.8331e+00)	Entropy 2.9947e+00 (2.9944e+00)
Epoch: [25][100/123]	Total Loss -1.2085e+01 (-1.2142e+01)	Consistency Loss 2.8810e+00 (2.8303e+00)	Entropy 2.9933e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.932551145553589, 'consistency': 1.626869797706604, 'total_loss': -1.3056813478469849}], 'lowest_loss_head': 0, 'lowest_loss': -1.3056813478469849}
New lowest loss on validation set: -1.2898 -> -1.3057
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2199188538100672, 'ARI': 0.08809098696160131, 'NMI': 0.21819311497605115, 'ACC Top-5': 0.5119817421072651, 'hungarian_match': [(0, 18), (1, 5), (2, 8), (3, 3), (4, 6), (5, 10), (6, 16), (7, 4), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 9), (16, 1), (17, 15), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 27/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [26][  0/123]	Total Loss -1.2083e+01 (-1.2083e+01)	Consistency Loss 2.8853e+00 (2.8853e+00)	Entropy 2.9937e+00 (2.9937e+00)
Epoch: [26][ 25/123]	Total Loss -1.2154e+01 (-1.2165e+01)	Consistency Loss 2.8150e+00 (2.8058e+00)	Entropy 2.9938e+00 (2.9942e+00)
Epoch: [26][ 50/123]	Total Loss -1.2170e+01 (-1.2157e+01)	Consistency Loss 2.8019e+00 (2.8143e+00)	Entropy 2.9944e+00 (2.9942e+00)
Epoch: [26][ 75/123]	Total Loss -1.2149e+01 (-1.2154e+01)	Consistency Loss 2.8192e+00 (2.8161e+00)	Entropy 2.9936e+00 (2.9941e+00)
Epoch: [26][100/123]	Total Loss -1.2182e+01 (-1.2155e+01)	Consistency Loss 2.7914e+00 (2.8153e+00)	Entropy 2.9947e+00 (2.9941e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.941906213760376, 'consistency': 1.625784158706665, 'total_loss': -1.316122055053711}], 'lowest_loss_head': 0, 'lowest_loss': -1.316122055053711}
New lowest loss on validation set: -1.3057 -> -1.3161
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2184607582097122, 'ARI': 0.08956786754727418, 'NMI': 0.21862796390805286, 'ACC Top-5': 0.5086217826803601, 'hungarian_match': [(0, 13), (1, 5), (2, 8), (3, 3), (4, 6), (5, 10), (6, 16), (7, 4), (8, 19), (9, 2), (10, 1), (11, 17), (12, 7), (13, 14), (14, 0), (15, 18), (16, 15), (17, 9), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 28/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [27][  0/123]	Total Loss -1.2202e+01 (-1.2202e+01)	Consistency Loss 2.7661e+00 (2.7661e+00)	Entropy 2.9936e+00 (2.9936e+00)
Epoch: [27][ 25/123]	Total Loss -1.2120e+01 (-1.2152e+01)	Consistency Loss 2.8528e+00 (2.8199e+00)	Entropy 2.9945e+00 (2.9943e+00)
Epoch: [27][ 50/123]	Total Loss -1.2112e+01 (-1.2140e+01)	Consistency Loss 2.8588e+00 (2.8313e+00)	Entropy 2.9942e+00 (2.9943e+00)
Epoch: [27][ 75/123]	Total Loss -1.2058e+01 (-1.2136e+01)	Consistency Loss 2.9173e+00 (2.8353e+00)	Entropy 2.9950e+00 (2.9943e+00)
Epoch: [27][100/123]	Total Loss -1.2122e+01 (-1.2137e+01)	Consistency Loss 2.8400e+00 (2.8341e+00)	Entropy 2.9925e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.943155288696289, 'consistency': 1.6249237060546875, 'total_loss': -1.3182315826416016}], 'lowest_loss_head': 0, 'lowest_loss': -1.3182315826416016}
New lowest loss on validation set: -1.3161 -> -1.3182
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.23430962343096234, 'ARI': 0.09354416777858594, 'NMI': 0.22570868563952382, 'ACC Top-5': 0.5067199188538101, 'hungarian_match': [(0, 18), (1, 5), (2, 10), (3, 3), (4, 6), (5, 8), (6, 16), (7, 15), (8, 19), (9, 2), (10, 1), (11, 17), (12, 7), (13, 14), (14, 0), (15, 9), (16, 13), (17, 4), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 29/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [28][  0/123]	Total Loss -1.2153e+01 (-1.2153e+01)	Consistency Loss 2.8209e+00 (2.8209e+00)	Entropy 2.9949e+00 (2.9949e+00)
Epoch: [28][ 25/123]	Total Loss -1.2056e+01 (-1.2135e+01)	Consistency Loss 2.9184e+00 (2.8368e+00)	Entropy 2.9949e+00 (2.9944e+00)
Epoch: [28][ 50/123]	Total Loss -1.2120e+01 (-1.2140e+01)	Consistency Loss 2.8525e+00 (2.8324e+00)	Entropy 2.9944e+00 (2.9944e+00)
Epoch: [28][ 75/123]	Total Loss -1.2240e+01 (-1.2147e+01)	Consistency Loss 2.7327e+00 (2.8252e+00)	Entropy 2.9945e+00 (2.9944e+00)
Epoch: [28][100/123]	Total Loss -1.2125e+01 (-1.2145e+01)	Consistency Loss 2.8448e+00 (2.8268e+00)	Entropy 2.9940e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9480695724487305, 'consistency': 1.6537266969680786, 'total_loss': -1.2943428754806519}], 'lowest_loss_head': 0, 'lowest_loss': -1.2943428754806519}
No new lowest loss on validation set: -1.3182 -> -1.2943
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2296817547863573, 'ARI': 0.09457028671855525, 'NMI': 0.22512697916523974, 'ACC Top-5': 0.5126790921770001, 'hungarian_match': [(0, 5), (1, 18), (2, 8), (3, 3), (4, 6), (5, 10), (6, 16), (7, 4), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 9), (16, 15), (17, 1), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 30/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [29][  0/123]	Total Loss -1.2145e+01 (-1.2145e+01)	Consistency Loss 2.8258e+00 (2.8258e+00)	Entropy 2.9942e+00 (2.9942e+00)
Epoch: [29][ 25/123]	Total Loss -1.2141e+01 (-1.2141e+01)	Consistency Loss 2.8257e+00 (2.8309e+00)	Entropy 2.9933e+00 (2.9943e+00)
Epoch: [29][ 50/123]	Total Loss -1.2154e+01 (-1.2139e+01)	Consistency Loss 2.8144e+00 (2.8330e+00)	Entropy 2.9937e+00 (2.9943e+00)
Epoch: [29][ 75/123]	Total Loss -1.2240e+01 (-1.2147e+01)	Consistency Loss 2.7231e+00 (2.8248e+00)	Entropy 2.9926e+00 (2.9943e+00)
Epoch: [29][100/123]	Total Loss -1.2071e+01 (-1.2147e+01)	Consistency Loss 2.9005e+00 (2.8239e+00)	Entropy 2.9944e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.939178466796875, 'consistency': 1.628029227256775, 'total_loss': -1.3111492395401}], 'lowest_loss_head': 0, 'lowest_loss': -1.3111492395401}
No new lowest loss on validation set: -1.3182 -> -1.3111
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.22410295422847723, 'ARI': 0.09022941754046028, 'NMI': 0.22139166611905456, 'ACC Top-5': 0.5064663370102701, 'hungarian_match': [(0, 5), (1, 18), (2, 8), (3, 3), (4, 6), (5, 10), (6, 16), (7, 15), (8, 19), (9, 2), (10, 1), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 13), (17, 9), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 31/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [30][  0/123]	Total Loss -1.2060e+01 (-1.2060e+01)	Consistency Loss 2.9059e+00 (2.9059e+00)	Entropy 2.9933e+00 (2.9933e+00)
Epoch: [30][ 25/123]	Total Loss -1.2180e+01 (-1.2160e+01)	Consistency Loss 2.7952e+00 (2.8119e+00)	Entropy 2.9951e+00 (2.9943e+00)
Epoch: [30][ 50/123]	Total Loss -1.2117e+01 (-1.2150e+01)	Consistency Loss 2.8582e+00 (2.8219e+00)	Entropy 2.9950e+00 (2.9943e+00)
Epoch: [30][ 75/123]	Total Loss -1.2124e+01 (-1.2147e+01)	Consistency Loss 2.8462e+00 (2.8244e+00)	Entropy 2.9941e+00 (2.9943e+00)
Epoch: [30][100/123]	Total Loss -1.2113e+01 (-1.2150e+01)	Consistency Loss 2.8598e+00 (2.8211e+00)	Entropy 2.9946e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9431755542755127, 'consistency': 1.6279538869857788, 'total_loss': -1.3152216672897339}], 'lowest_loss_head': 0, 'lowest_loss': -1.3152216672897339}
No new lowest loss on validation set: -1.3182 -> -1.3152
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2219475085583872, 'ARI': 0.08295544041321752, 'NMI': 0.21724894650492163, 'ACC Top-5': 0.5150881196906302, 'hungarian_match': [(0, 1), (1, 18), (2, 8), (3, 3), (4, 6), (5, 10), (6, 16), (7, 9), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 5), (16, 15), (17, 4), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 32/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [31][  0/123]	Total Loss -1.2084e+01 (-1.2084e+01)	Consistency Loss 2.8914e+00 (2.8914e+00)	Entropy 2.9952e+00 (2.9952e+00)
Epoch: [31][ 25/123]	Total Loss -1.2210e+01 (-1.2153e+01)	Consistency Loss 2.7572e+00 (2.8184e+00)	Entropy 2.9934e+00 (2.9943e+00)
Epoch: [31][ 50/123]	Total Loss -1.2114e+01 (-1.2150e+01)	Consistency Loss 2.8598e+00 (2.8213e+00)	Entropy 2.9947e+00 (2.9942e+00)
Epoch: [31][ 75/123]	Total Loss -1.2095e+01 (-1.2148e+01)	Consistency Loss 2.8792e+00 (2.8228e+00)	Entropy 2.9948e+00 (2.9942e+00)
Epoch: [31][100/123]	Total Loss -1.2109e+01 (-1.2147e+01)	Consistency Loss 2.8651e+00 (2.8240e+00)	Entropy 2.9948e+00 (2.9942e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.917097806930542, 'consistency': 1.5913389921188354, 'total_loss': -1.3257588148117065}], 'lowest_loss_head': 0, 'lowest_loss': -1.3257588148117065}
New lowest loss on validation set: -1.3182 -> -1.3258
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.23900088753645238, 'ARI': 0.10738926198482328, 'NMI': 0.22340306754867242, 'ACC Top-5': 0.5292887029288703, 'hungarian_match': [(0, 18), (1, 5), (2, 8), (3, 1), (4, 3), (5, 10), (6, 16), (7, 9), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 15), (17, 6), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 33/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [32][  0/123]	Total Loss -1.2171e+01 (-1.2171e+01)	Consistency Loss 2.8007e+00 (2.8007e+00)	Entropy 2.9943e+00 (2.9943e+00)
Epoch: [32][ 25/123]	Total Loss -1.2242e+01 (-1.2163e+01)	Consistency Loss 2.7270e+00 (2.8078e+00)	Entropy 2.9938e+00 (2.9941e+00)
Epoch: [32][ 50/123]	Total Loss -1.2150e+01 (-1.2153e+01)	Consistency Loss 2.8199e+00 (2.8174e+00)	Entropy 2.9939e+00 (2.9940e+00)
Epoch: [32][ 75/123]	Total Loss -1.2184e+01 (-1.2148e+01)	Consistency Loss 2.7892e+00 (2.8222e+00)	Entropy 2.9947e+00 (2.9941e+00)
Epoch: [32][100/123]	Total Loss -1.2169e+01 (-1.2148e+01)	Consistency Loss 2.7979e+00 (2.8227e+00)	Entropy 2.9935e+00 (2.9942e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9326987266540527, 'consistency': 1.609177827835083, 'total_loss': -1.3235208988189697}], 'lowest_loss_head': 0, 'lowest_loss': -1.3235208988189697}
No new lowest loss on validation set: -1.3258 -> -1.3235
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21503740332192214, 'ARI': 0.07677878958363492, 'NMI': 0.2179135616278702, 'ACC Top-5': 0.5081780144541651, 'hungarian_match': [(0, 18), (1, 5), (2, 8), (3, 3), (4, 6), (5, 10), (6, 16), (7, 4), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 9), (16, 15), (17, 1), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 34/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [33][  0/123]	Total Loss -1.2176e+01 (-1.2176e+01)	Consistency Loss 2.7930e+00 (2.7930e+00)	Entropy 2.9938e+00 (2.9938e+00)
Epoch: [33][ 25/123]	Total Loss -1.2096e+01 (-1.2141e+01)	Consistency Loss 2.8727e+00 (2.8300e+00)	Entropy 2.9938e+00 (2.9942e+00)
Epoch: [33][ 50/123]	Total Loss -1.2101e+01 (-1.2139e+01)	Consistency Loss 2.8705e+00 (2.8330e+00)	Entropy 2.9943e+00 (2.9944e+00)
Epoch: [33][ 75/123]	Total Loss -1.2127e+01 (-1.2144e+01)	Consistency Loss 2.8381e+00 (2.8274e+00)	Entropy 2.9930e+00 (2.9943e+00)
Epoch: [33][100/123]	Total Loss -1.2124e+01 (-1.2142e+01)	Consistency Loss 2.8419e+00 (2.8294e+00)	Entropy 2.9933e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9284093379974365, 'consistency': 1.575222373008728, 'total_loss': -1.3531869649887085}], 'lowest_loss_head': 0, 'lowest_loss': -1.3531869649887085}
New lowest loss on validation set: -1.3258 -> -1.3532
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.22378597692405225, 'ARI': 0.08550698164501165, 'NMI': 0.22297988120216142, 'ACC Top-5': 0.5091923418283251, 'hungarian_match': [(0, 5), (1, 18), (2, 8), (3, 3), (4, 6), (5, 10), (6, 16), (7, 15), (8, 19), (9, 2), (10, 1), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 13), (17, 9), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 35/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [34][  0/123]	Total Loss -1.2175e+01 (-1.2175e+01)	Consistency Loss 2.7981e+00 (2.7981e+00)	Entropy 2.9946e+00 (2.9946e+00)
Epoch: [34][ 25/123]	Total Loss -1.2252e+01 (-1.2148e+01)	Consistency Loss 2.7148e+00 (2.8237e+00)	Entropy 2.9934e+00 (2.9944e+00)
Epoch: [34][ 50/123]	Total Loss -1.2185e+01 (-1.2145e+01)	Consistency Loss 2.7883e+00 (2.8272e+00)	Entropy 2.9947e+00 (2.9945e+00)
Epoch: [34][ 75/123]	Total Loss -1.2177e+01 (-1.2150e+01)	Consistency Loss 2.7935e+00 (2.8227e+00)	Entropy 2.9941e+00 (2.9945e+00)
Epoch: [34][100/123]	Total Loss -1.2165e+01 (-1.2149e+01)	Consistency Loss 2.8092e+00 (2.8234e+00)	Entropy 2.9949e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.936842203140259, 'consistency': 1.59658944606781, 'total_loss': -1.3402527570724487}], 'lowest_loss_head': 0, 'lowest_loss': -1.3402527570724487}
No new lowest loss on validation set: -1.3532 -> -1.3403
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.23500697350069735, 'ARI': 0.09334735892241973, 'NMI': 0.22225633967587144, 'ACC Top-5': 0.5170533789780651, 'hungarian_match': [(0, 18), (1, 5), (2, 10), (3, 3), (4, 6), (5, 8), (6, 16), (7, 15), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 1), (17, 9), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 36/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [35][  0/123]	Total Loss -1.2061e+01 (-1.2061e+01)	Consistency Loss 2.9133e+00 (2.9133e+00)	Entropy 2.9949e+00 (2.9949e+00)
Epoch: [35][ 25/123]	Total Loss -1.2142e+01 (-1.2133e+01)	Consistency Loss 2.8313e+00 (2.8400e+00)	Entropy 2.9947e+00 (2.9946e+00)
Epoch: [35][ 50/123]	Total Loss -1.2150e+01 (-1.2153e+01)	Consistency Loss 2.8169e+00 (2.8191e+00)	Entropy 2.9933e+00 (2.9944e+00)
Epoch: [35][ 75/123]	Total Loss -1.2141e+01 (-1.2149e+01)	Consistency Loss 2.8332e+00 (2.8228e+00)	Entropy 2.9948e+00 (2.9944e+00)
Epoch: [35][100/123]	Total Loss -1.2216e+01 (-1.2150e+01)	Consistency Loss 2.7583e+00 (2.8216e+00)	Entropy 2.9949e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9187145233154297, 'consistency': 1.5728849172592163, 'total_loss': -1.3458296060562134}], 'lowest_loss_head': 0, 'lowest_loss': -1.3458296060562134}
No new lowest loss on validation set: -1.3532 -> -1.3458
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2304425003169773, 'ARI': 0.0950597536016506, 'NMI': 0.2205509690374406, 'ACC Top-5': 0.5124889057943451, 'hungarian_match': [(0, 1), (1, 18), (2, 8), (3, 6), (4, 3), (5, 10), (6, 16), (7, 9), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 15), (17, 5), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 37/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [36][  0/123]	Total Loss -1.2223e+01 (-1.2223e+01)	Consistency Loss 2.7479e+00 (2.7479e+00)	Entropy 2.9942e+00 (2.9942e+00)
Epoch: [36][ 25/123]	Total Loss -1.2191e+01 (-1.2166e+01)	Consistency Loss 2.7830e+00 (2.8051e+00)	Entropy 2.9948e+00 (2.9941e+00)
Epoch: [36][ 50/123]	Total Loss -1.2086e+01 (-1.2155e+01)	Consistency Loss 2.8867e+00 (2.8157e+00)	Entropy 2.9946e+00 (2.9942e+00)
Epoch: [36][ 75/123]	Total Loss -1.2122e+01 (-1.2150e+01)	Consistency Loss 2.8516e+00 (2.8214e+00)	Entropy 2.9947e+00 (2.9943e+00)
Epoch: [36][100/123]	Total Loss -1.2066e+01 (-1.2146e+01)	Consistency Loss 2.9085e+00 (2.8253e+00)	Entropy 2.9948e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9213314056396484, 'consistency': 1.5446170568466187, 'total_loss': -1.3767143487930298}], 'lowest_loss_head': 0, 'lowest_loss': -1.3767143487930298}
New lowest loss on validation set: -1.3532 -> -1.3767
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2289210092557373, 'ARI': 0.08713502456870205, 'NMI': 0.2181517113466862, 'ACC Top-5': 0.5378470901483454, 'hungarian_match': [(0, 5), (1, 18), (2, 8), (3, 3), (4, 6), (5, 10), (6, 12), (7, 16), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 15), (17, 9), (18, 1), (19, 11)]}
Checkpoint ...
[33mEpoch 38/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [37][  0/123]	Total Loss -1.2145e+01 (-1.2145e+01)	Consistency Loss 2.8254e+00 (2.8254e+00)	Entropy 2.9941e+00 (2.9941e+00)
Epoch: [37][ 25/123]	Total Loss -1.2139e+01 (-1.2142e+01)	Consistency Loss 2.8310e+00 (2.8286e+00)	Entropy 2.9941e+00 (2.9942e+00)
Epoch: [37][ 50/123]	Total Loss -1.2215e+01 (-1.2145e+01)	Consistency Loss 2.7580e+00 (2.8262e+00)	Entropy 2.9946e+00 (2.9942e+00)
Epoch: [37][ 75/123]	Total Loss -1.2152e+01 (-1.2148e+01)	Consistency Loss 2.8185e+00 (2.8233e+00)	Entropy 2.9941e+00 (2.9942e+00)
Epoch: [37][100/123]	Total Loss -1.2073e+01 (-1.2143e+01)	Consistency Loss 2.8995e+00 (2.8284e+00)	Entropy 2.9945e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.927656650543213, 'consistency': 1.5834449529647827, 'total_loss': -1.3442116975784302}], 'lowest_loss_head': 0, 'lowest_loss': -1.3442116975784302}
No new lowest loss on validation set: -1.3767 -> -1.3442
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.23158361861290733, 'ARI': 0.09773245180653248, 'NMI': 0.22476201640923255, 'ACC Top-5': 0.5424749587929504, 'hungarian_match': [(0, 5), (1, 18), (2, 8), (3, 3), (4, 6), (5, 10), (6, 12), (7, 16), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 9), (17, 15), (18, 1), (19, 11)]}
Checkpoint ...
[33mEpoch 39/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [38][  0/123]	Total Loss -1.2182e+01 (-1.2182e+01)	Consistency Loss 2.7835e+00 (2.7835e+00)	Entropy 2.9931e+00 (2.9931e+00)
Epoch: [38][ 25/123]	Total Loss -1.2201e+01 (-1.2169e+01)	Consistency Loss 2.7724e+00 (2.8023e+00)	Entropy 2.9946e+00 (2.9943e+00)
Epoch: [38][ 50/123]	Total Loss -1.2161e+01 (-1.2164e+01)	Consistency Loss 2.8112e+00 (2.8077e+00)	Entropy 2.9944e+00 (2.9942e+00)
Epoch: [38][ 75/123]	Total Loss -1.2118e+01 (-1.2157e+01)	Consistency Loss 2.8587e+00 (2.8144e+00)	Entropy 2.9953e+00 (2.9942e+00)
Epoch: [38][100/123]	Total Loss -1.2215e+01 (-1.2154e+01)	Consistency Loss 2.7564e+00 (2.8171e+00)	Entropy 2.9943e+00 (2.9942e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.930182695388794, 'consistency': 1.5674270391464233, 'total_loss': -1.3627556562423706}], 'lowest_loss_head': 0, 'lowest_loss': -1.3627556562423706}
No new lowest loss on validation set: -1.3767 -> -1.3628
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.22441993153290224, 'ARI': 0.08800424849717464, 'NMI': 0.22396969965860344, 'ACC Top-5': 0.5254849752757702, 'hungarian_match': [(0, 18), (1, 5), (2, 8), (3, 3), (4, 6), (5, 10), (6, 12), (7, 16), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 15), (17, 9), (18, 1), (19, 11)]}
Checkpoint ...
[33mEpoch 40/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [39][  0/123]	Total Loss -1.2083e+01 (-1.2083e+01)	Consistency Loss 2.8889e+00 (2.8889e+00)	Entropy 2.9944e+00 (2.9944e+00)
Epoch: [39][ 25/123]	Total Loss -1.2162e+01 (-1.2144e+01)	Consistency Loss 2.8048e+00 (2.8283e+00)	Entropy 2.9935e+00 (2.9944e+00)
Epoch: [39][ 50/123]	Total Loss -1.2052e+01 (-1.2146e+01)	Consistency Loss 2.9215e+00 (2.8256e+00)	Entropy 2.9947e+00 (2.9944e+00)
Epoch: [39][ 75/123]	Total Loss -1.2128e+01 (-1.2146e+01)	Consistency Loss 2.8390e+00 (2.8264e+00)	Entropy 2.9935e+00 (2.9944e+00)
Epoch: [39][100/123]	Total Loss -1.2213e+01 (-1.2145e+01)	Consistency Loss 2.7626e+00 (2.8271e+00)	Entropy 2.9950e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.924205780029297, 'consistency': 1.581221342086792, 'total_loss': -1.3429844379425049}], 'lowest_loss_head': 0, 'lowest_loss': -1.3429844379425049}
No new lowest loss on validation set: -1.3767 -> -1.3430
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.24667173830353747, 'ARI': 0.10926521525135933, 'NMI': 0.23152230796757212, 'ACC Top-5': 0.5462152909851654, 'hungarian_match': [(0, 5), (1, 18), (2, 8), (3, 10), (4, 3), (5, 19), (6, 12), (7, 16), (8, 6), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 9), (17, 15), (18, 1), (19, 11)]}
Checkpoint ...
[33mEpoch 41/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [40][  0/123]	Total Loss -1.2152e+01 (-1.2152e+01)	Consistency Loss 2.8186e+00 (2.8186e+00)	Entropy 2.9941e+00 (2.9941e+00)
Epoch: [40][ 25/123]	Total Loss -1.2137e+01 (-1.2153e+01)	Consistency Loss 2.8356e+00 (2.8201e+00)	Entropy 2.9945e+00 (2.9945e+00)
Epoch: [40][ 50/123]	Total Loss -1.2163e+01 (-1.2151e+01)	Consistency Loss 2.8071e+00 (2.8214e+00)	Entropy 2.9940e+00 (2.9945e+00)
Epoch: [40][ 75/123]	Total Loss -1.2101e+01 (-1.2138e+01)	Consistency Loss 2.8722e+00 (2.8348e+00)	Entropy 2.9947e+00 (2.9945e+00)
Epoch: [40][100/123]	Total Loss -1.2140e+01 (-1.2143e+01)	Consistency Loss 2.8321e+00 (2.8297e+00)	Entropy 2.9943e+00 (2.9945e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9405086040496826, 'consistency': 1.5636178255081177, 'total_loss': -1.376890778541565}], 'lowest_loss_head': 0, 'lowest_loss': -1.376890778541565}
New lowest loss on validation set: -1.3767 -> -1.3769
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.22220109040192723, 'ARI': 0.08215058681918995, 'NMI': 0.2283030819335541, 'ACC Top-5': 0.5321414986686953, 'hungarian_match': [(0, 5), (1, 18), (2, 8), (3, 1), (4, 4), (5, 10), (6, 16), (7, 9), (8, 6), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 19), (16, 15), (17, 3), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 42/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [41][  0/123]	Total Loss -1.2148e+01 (-1.2148e+01)	Consistency Loss 2.8260e+00 (2.8260e+00)	Entropy 2.9948e+00 (2.9948e+00)
Epoch: [41][ 25/123]	Total Loss -1.2092e+01 (-1.2133e+01)	Consistency Loss 2.8820e+00 (2.8388e+00)	Entropy 2.9947e+00 (2.9944e+00)
Epoch: [41][ 50/123]	Total Loss -1.2037e+01 (-1.2140e+01)	Consistency Loss 2.9349e+00 (2.8315e+00)	Entropy 2.9945e+00 (2.9944e+00)
Epoch: [41][ 75/123]	Total Loss -1.2129e+01 (-1.2141e+01)	Consistency Loss 2.8443e+00 (2.8310e+00)	Entropy 2.9946e+00 (2.9944e+00)
Epoch: [41][100/123]	Total Loss -1.2094e+01 (-1.2140e+01)	Consistency Loss 2.8760e+00 (2.8327e+00)	Entropy 2.9939e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9505844116210938, 'consistency': 1.6288684606552124, 'total_loss': -1.3217159509658813}], 'lowest_loss_head': 0, 'lowest_loss': -1.3217159509658813}
No new lowest loss on validation set: -1.3769 -> -1.3217
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2289844047166223, 'ARI': 0.09157592287534434, 'NMI': 0.23252473721803757, 'ACC Top-5': 0.5252947888931152, 'hungarian_match': [(0, 5), (1, 18), (2, 10), (3, 3), (4, 6), (5, 8), (6, 16), (7, 9), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 15), (17, 1), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 43/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [42][  0/123]	Total Loss -1.2091e+01 (-1.2091e+01)	Consistency Loss 2.8834e+00 (2.8834e+00)	Entropy 2.9948e+00 (2.9948e+00)
Epoch: [42][ 25/123]	Total Loss -1.2105e+01 (-1.2146e+01)	Consistency Loss 2.8699e+00 (2.8265e+00)	Entropy 2.9949e+00 (2.9945e+00)
Epoch: [42][ 50/123]	Total Loss -1.2137e+01 (-1.2149e+01)	Consistency Loss 2.8364e+00 (2.8234e+00)	Entropy 2.9947e+00 (2.9945e+00)
Epoch: [42][ 75/123]	Total Loss -1.2129e+01 (-1.2150e+01)	Consistency Loss 2.8425e+00 (2.8222e+00)	Entropy 2.9944e+00 (2.9945e+00)
Epoch: [42][100/123]	Total Loss -1.2082e+01 (-1.2146e+01)	Consistency Loss 2.8870e+00 (2.8260e+00)	Entropy 2.9938e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9325642585754395, 'consistency': 1.5912412405014038, 'total_loss': -1.3413230180740356}], 'lowest_loss_head': 0, 'lowest_loss': -1.3413230180740356}
No new lowest loss on validation set: -1.3769 -> -1.3413
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.23456320527450233, 'ARI': 0.10105512302367053, 'NMI': 0.23001089470002942, 'ACC Top-5': 0.5204767338658552, 'hungarian_match': [(0, 1), (1, 5), (2, 10), (3, 3), (4, 6), (5, 8), (6, 16), (7, 9), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 18), (16, 15), (17, 4), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 44/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [43][  0/123]	Total Loss -1.2200e+01 (-1.2200e+01)	Consistency Loss 2.7712e+00 (2.7712e+00)	Entropy 2.9943e+00 (2.9943e+00)
Epoch: [43][ 25/123]	Total Loss -1.2184e+01 (-1.2162e+01)	Consistency Loss 2.7860e+00 (2.8098e+00)	Entropy 2.9939e+00 (2.9945e+00)
Epoch: [43][ 50/123]	Total Loss -1.2125e+01 (-1.2156e+01)	Consistency Loss 2.8440e+00 (2.8158e+00)	Entropy 2.9938e+00 (2.9944e+00)
Epoch: [43][ 75/123]	Total Loss -1.2170e+01 (-1.2158e+01)	Consistency Loss 2.7988e+00 (2.8139e+00)	Entropy 2.9938e+00 (2.9944e+00)
Epoch: [43][100/123]	Total Loss -1.2127e+01 (-1.2155e+01)	Consistency Loss 2.8339e+00 (2.8160e+00)	Entropy 2.9922e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9280645847320557, 'consistency': 1.6086394786834717, 'total_loss': -1.319425106048584}], 'lowest_loss_head': 0, 'lowest_loss': -1.319425106048584}
No new lowest loss on validation set: -1.3769 -> -1.3194
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.23564092810954734, 'ARI': 0.09375028497034224, 'NMI': 0.22519170336330357, 'ACC Top-5': 0.5219982249270952, 'hungarian_match': [(0, 5), (1, 18), (2, 8), (3, 3), (4, 6), (5, 10), (6, 16), (7, 9), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 1), (16, 15), (17, 4), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 45/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [44][  0/123]	Total Loss -1.2164e+01 (-1.2164e+01)	Consistency Loss 2.8062e+00 (2.8062e+00)	Entropy 2.9939e+00 (2.9939e+00)
Epoch: [44][ 25/123]	Total Loss -1.2172e+01 (-1.2152e+01)	Consistency Loss 2.7978e+00 (2.8204e+00)	Entropy 2.9940e+00 (2.9945e+00)
Epoch: [44][ 50/123]	Total Loss -1.2125e+01 (-1.2158e+01)	Consistency Loss 2.8432e+00 (2.8148e+00)	Entropy 2.9937e+00 (2.9945e+00)
Epoch: [44][ 75/123]	Total Loss -1.2128e+01 (-1.2154e+01)	Consistency Loss 2.8409e+00 (2.8181e+00)	Entropy 2.9937e+00 (2.9943e+00)
Epoch: [44][100/123]	Total Loss -1.2138e+01 (-1.2151e+01)	Consistency Loss 2.8340e+00 (2.8210e+00)	Entropy 2.9943e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.947000503540039, 'consistency': 1.6195642948150635, 'total_loss': -1.3274362087249756}], 'lowest_loss_head': 0, 'lowest_loss': -1.3274362087249756}
No new lowest loss on validation set: -1.3769 -> -1.3274
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2302523139343223, 'ARI': 0.08805368780450254, 'NMI': 0.22547558746818902, 'ACC Top-5': 0.5202231520223152, 'hungarian_match': [(0, 1), (1, 18), (2, 10), (3, 3), (4, 6), (5, 8), (6, 2), (7, 16), (8, 19), (9, 9), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 5), (16, 15), (17, 4), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 46/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [45][  0/123]	Total Loss -1.2179e+01 (-1.2179e+01)	Consistency Loss 2.7896e+00 (2.7896e+00)	Entropy 2.9937e+00 (2.9937e+00)
Epoch: [45][ 25/123]	Total Loss -1.2078e+01 (-1.2141e+01)	Consistency Loss 2.8978e+00 (2.8314e+00)	Entropy 2.9952e+00 (2.9944e+00)
Epoch: [45][ 50/123]	Total Loss -1.2168e+01 (-1.2144e+01)	Consistency Loss 2.8040e+00 (2.8285e+00)	Entropy 2.9943e+00 (2.9944e+00)
Epoch: [45][ 75/123]	Total Loss -1.2061e+01 (-1.2146e+01)	Consistency Loss 2.9112e+00 (2.8256e+00)	Entropy 2.9944e+00 (2.9944e+00)
Epoch: [45][100/123]	Total Loss -1.2133e+01 (-1.2141e+01)	Consistency Loss 2.8384e+00 (2.8306e+00)	Entropy 2.9942e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.924501895904541, 'consistency': 1.5728559494018555, 'total_loss': -1.3516459465026855}], 'lowest_loss_head': 0, 'lowest_loss': -1.3516459465026855}
No new lowest loss on validation set: -1.3769 -> -1.3516
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.24261442880689743, 'ARI': 0.10335007436310568, 'NMI': 0.23195242016266435, 'ACC Top-5': 0.5121085330290351, 'hungarian_match': [(0, 18), (1, 5), (2, 10), (3, 3), (4, 6), (5, 8), (6, 16), (7, 9), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 1), (17, 15), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 47/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [46][  0/123]	Total Loss -1.2125e+01 (-1.2125e+01)	Consistency Loss 2.8495e+00 (2.8495e+00)	Entropy 2.9950e+00 (2.9950e+00)
Epoch: [46][ 25/123]	Total Loss -1.2088e+01 (-1.2145e+01)	Consistency Loss 2.8819e+00 (2.8266e+00)	Entropy 2.9939e+00 (2.9943e+00)
Epoch: [46][ 50/123]	Total Loss -1.2080e+01 (-1.2140e+01)	Consistency Loss 2.8953e+00 (2.8312e+00)	Entropy 2.9950e+00 (2.9943e+00)
Epoch: [46][ 75/123]	Total Loss -1.2079e+01 (-1.2146e+01)	Consistency Loss 2.8960e+00 (2.8262e+00)	Entropy 2.9951e+00 (2.9944e+00)
Epoch: [46][100/123]	Total Loss -1.2241e+01 (-1.2148e+01)	Consistency Loss 2.7329e+00 (2.8243e+00)	Entropy 2.9948e+00 (2.9944e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.933067798614502, 'consistency': 1.568259358406067, 'total_loss': -1.364808440208435}], 'lowest_loss_head': 0, 'lowest_loss': -1.364808440208435}
No new lowest loss on validation set: -1.3769 -> -1.3648
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21440344871307215, 'ARI': 0.0860135323894522, 'NMI': 0.2293606412858688, 'ACC Top-5': 0.5268796754152403, 'hungarian_match': [(0, 5), (1, 18), (2, 10), (3, 13), (4, 3), (5, 8), (6, 16), (7, 9), (8, 6), (9, 2), (10, 1), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 15), (17, 19), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 48/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [47][  0/123]	Total Loss -1.2135e+01 (-1.2135e+01)	Consistency Loss 2.8338e+00 (2.8338e+00)	Entropy 2.9938e+00 (2.9938e+00)
Epoch: [47][ 25/123]	Total Loss -1.2118e+01 (-1.2167e+01)	Consistency Loss 2.8532e+00 (2.8038e+00)	Entropy 2.9942e+00 (2.9942e+00)
Epoch: [47][ 50/123]	Total Loss -1.2221e+01 (-1.2164e+01)	Consistency Loss 2.7479e+00 (2.8072e+00)	Entropy 2.9938e+00 (2.9942e+00)
Epoch: [47][ 75/123]	Total Loss -1.2128e+01 (-1.2163e+01)	Consistency Loss 2.8447e+00 (2.8079e+00)	Entropy 2.9945e+00 (2.9941e+00)
Epoch: [47][100/123]	Total Loss -1.2133e+01 (-1.2158e+01)	Consistency Loss 2.8419e+00 (2.8130e+00)	Entropy 2.9950e+00 (2.9941e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9377520084381104, 'consistency': 1.6134077310562134, 'total_loss': -1.324344277381897}], 'lowest_loss_head': 0, 'lowest_loss': -1.324344277381897}
No new lowest loss on validation set: -1.3769 -> -1.3243
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21351591226068214, 'ARI': 0.08811073956838099, 'NMI': 0.22970113893707636, 'ACC Top-5': 0.5194624064916952, 'hungarian_match': [(0, 18), (1, 5), (2, 8), (3, 1), (4, 3), (5, 10), (6, 16), (7, 9), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 6), (16, 15), (17, 4), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 49/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [48][  0/123]	Total Loss -1.2173e+01 (-1.2173e+01)	Consistency Loss 2.7923e+00 (2.7923e+00)	Entropy 2.9931e+00 (2.9931e+00)
Epoch: [48][ 25/123]	Total Loss -1.2162e+01 (-1.2159e+01)	Consistency Loss 2.8109e+00 (2.8130e+00)	Entropy 2.9945e+00 (2.9945e+00)
Epoch: [48][ 50/123]	Total Loss -1.2169e+01 (-1.2159e+01)	Consistency Loss 2.8048e+00 (2.8135e+00)	Entropy 2.9948e+00 (2.9945e+00)
Epoch: [48][ 75/123]	Total Loss -1.2210e+01 (-1.2159e+01)	Consistency Loss 2.7643e+00 (2.8125e+00)	Entropy 2.9948e+00 (2.9944e+00)
Epoch: [48][100/123]	Total Loss -1.2066e+01 (-1.2158e+01)	Consistency Loss 2.9034e+00 (2.8137e+00)	Entropy 2.9938e+00 (2.9943e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9325056076049805, 'consistency': 1.5314401388168335, 'total_loss': -1.401065468788147}], 'lowest_loss_head': 0, 'lowest_loss': -1.401065468788147}
New lowest loss on validation set: -1.3769 -> -1.4011
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2423608469633574, 'ARI': 0.10393410482122424, 'NMI': 0.23398560894655882, 'ACC Top-5': 0.5259921389628502, 'hungarian_match': [(0, 5), (1, 18), (2, 10), (3, 3), (4, 6), (5, 8), (6, 16), (7, 9), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 15), (17, 1), (18, 12), (19, 11)]}
Checkpoint ...
[33mEpoch 50/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [49][  0/123]	Total Loss -1.2088e+01 (-1.2088e+01)	Consistency Loss 2.8881e+00 (2.8881e+00)	Entropy 2.9951e+00 (2.9951e+00)
Epoch: [49][ 25/123]	Total Loss -1.2187e+01 (-1.2158e+01)	Consistency Loss 2.7756e+00 (2.8121e+00)	Entropy 2.9925e+00 (2.9941e+00)
Epoch: [49][ 50/123]	Total Loss -1.2130e+01 (-1.2160e+01)	Consistency Loss 2.8431e+00 (2.8112e+00)	Entropy 2.9946e+00 (2.9942e+00)
Epoch: [49][ 75/123]	Total Loss -1.2221e+01 (-1.2159e+01)	Consistency Loss 2.7486e+00 (2.8121e+00)	Entropy 2.9940e+00 (2.9942e+00)
Epoch: [49][100/123]	Total Loss -1.2111e+01 (-1.2158e+01)	Consistency Loss 2.8653e+00 (2.8128e+00)	Entropy 2.9953e+00 (2.9942e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9450254440307617, 'consistency': 1.5311384201049805, 'total_loss': -1.4138870239257812}], 'lowest_loss_head': 0, 'lowest_loss': -1.4138870239257812}
New lowest loss on validation set: -1.4011 -> -1.4139
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2317104095346773, 'ARI': 0.09358512614238025, 'NMI': 0.23296934988197507, 'ACC Top-5': 0.5250412070495752, 'hungarian_match': [(0, 5), (1, 18), (2, 10), (3, 3), (4, 6), (5, 8), (6, 12), (7, 16), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 15), (17, 9), (18, 1), (19, 11)]}
Checkpoint ...
[34mEvaluate best model based on SCAN metric at the end[0m
torch.Size([15774])
torch.Size([15774])
{'ACC': 0.2317104095346773, 'ARI': 0.09358512614238025, 'NMI': 0.23296934988197507, 'ACC Top-5': 0.5250412070495752, 'hungarian_match': [(0, 5), (1, 18), (2, 10), (3, 3), (4, 6), (5, 8), (6, 12), (7, 16), (8, 19), (9, 2), (10, 13), (11, 17), (12, 7), (13, 14), (14, 0), (15, 4), (16, 15), (17, 9), (18, 1), (19, 11)]}
