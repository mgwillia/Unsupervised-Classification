vulcan02.umiacs.umd.edu
[31m{'setup': 'simclr', 'backbone': 'resnet50', 'model_kwargs': {'head': 'mlp', 'features_dim': 128}, 'train_db_name': 'pascal-large-batches', 'val_db_name': 'pascal-large-batches', 'num_classes': 20, 'criterion': 'simclr', 'criterion_kwargs': {'temperature': 0.1}, 'epochs': 500, 'optimizer': 'sgd', 'optimizer_kwargs': {'nesterov': False, 'weight_decay': 0.0001, 'momentum': 0.9, 'lr': 0.4}, 'scheduler': 'cosine', 'scheduler_kwargs': {'lr_decay_rate': 0.1}, 'batch_size': 256, 'num_workers': 8, 'augmentation_strategy': 'simclr', 'augmentation_kwargs': {'random_resized_crop': {'size': 112, 'scale': [0.2, 1.0]}, 'color_jitter_random_apply': {'p': 0.8}, 'color_jitter': {'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}, 'random_grayscale': {'p': 0.2}, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'transformation_kwargs': {'crop_size': 112, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'pretext_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-large-batches/pretext', 'pretext_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-large-batches/pretext/checkpoint.pth.tar', 'pretext_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-large-batches/pretext/model.pth.tar', 'topk_neighbors_train_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-large-batches/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-large-batches/pretext/topk-val-neighbors.npy'}[0m
[34mRetrieve model[0m
{'setup': 'simclr', 'backbone': 'resnet50', 'model_kwargs': {'head': 'mlp', 'features_dim': 128}, 'train_db_name': 'pascal-large-batches', 'val_db_name': 'pascal-large-batches', 'num_classes': 20, 'criterion': 'simclr', 'criterion_kwargs': {'temperature': 0.1}, 'epochs': 500, 'optimizer': 'sgd', 'optimizer_kwargs': {'nesterov': False, 'weight_decay': 0.0001, 'momentum': 0.9, 'lr': 0.4}, 'scheduler': 'cosine', 'scheduler_kwargs': {'lr_decay_rate': 0.1}, 'batch_size': 256, 'num_workers': 8, 'augmentation_strategy': 'simclr', 'augmentation_kwargs': {'random_resized_crop': {'size': 112, 'scale': [0.2, 1.0]}, 'color_jitter_random_apply': {'p': 0.8}, 'color_jitter': {'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.4, 'hue': 0.1}, 'random_grayscale': {'p': 0.2}, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'transformation_kwargs': {'crop_size': 112, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'pretext_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-large-batches/pretext', 'pretext_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-large-batches/pretext/checkpoint.pth.tar', 'pretext_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-large-batches/pretext/model.pth.tar', 'topk_neighbors_train_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-large-batches/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-large-batches/pretext/topk-val-neighbors.npy'}
Model is ContrastiveModel
Model parameters: 30.02M
ContrastiveModel(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
  (contrastive_head): Sequential(
    (0): Linear(in_features=2048, out_features=2048, bias=True)
    (1): ReLU()
    (2): Linear(in_features=2048, out_features=128, bias=True)
  )
)
[34mSet CuDNN benchmark[0m
[34mRetrieve dataset[0m
Train transforms: Compose(
    RandomResizedCrop(size=(112, 112), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)
    RandomHorizontalFlip(p=0.5)
    RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
)
    RandomGrayscale(p=0.2)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
Validation transforms: Compose(
    CenterCrop(size=(112, 112))
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
Dataset contains 15774/15774 train/val samples
[34mBuild MemoryBank[0m
[34mRetrieve criterion[0m
Criterion is SimCLRLoss
[34mRetrieve optimizer[0m
SGD (
Parameter Group 0
    dampening: 0
    lr: 0.4
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0001
)
[34mRestart from checkpoint /cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-large-batches/pretext/checkpoint.pth.tar[0m
[34mStarting main loop[0m
[33mEpoch 319/500[0m
[33m---------------[0m
Adjusted learning rate to 0.11627
Train ...
Epoch: [319][ 0/61]	Loss 3.8705e-01 (3.8705e-01)
Epoch: [319][25/61]	Loss 4.5214e-01 (4.0877e-01)
Epoch: [319][50/61]	Loss 3.9299e-01 (4.0734e-01)
Checkpoint ...
[33mEpoch 320/500[0m
[33m---------------[0m
Adjusted learning rate to 0.11513
Train ...
Epoch: [320][ 0/61]	Loss 4.2711e-01 (4.2711e-01)
Epoch: [320][25/61]	Loss 3.8034e-01 (3.9972e-01)
Epoch: [320][50/61]	Loss 4.1191e-01 (4.0890e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 74.84
Checkpoint ...
[33mEpoch 321/500[0m
[33m---------------[0m
Adjusted learning rate to 0.11400
Train ...
Epoch: [321][ 0/61]	Loss 3.6337e-01 (3.6337e-01)
Epoch: [321][25/61]	Loss 4.6287e-01 (3.9671e-01)
Epoch: [321][50/61]	Loss 3.7707e-01 (3.9163e-01)
Checkpoint ...
[33mEpoch 322/500[0m
[33m---------------[0m
Adjusted learning rate to 0.11286
Train ...
Epoch: [322][ 0/61]	Loss 3.9793e-01 (3.9793e-01)
Epoch: [322][25/61]	Loss 3.3345e-01 (4.0914e-01)
Epoch: [322][50/61]	Loss 4.3225e-01 (4.0455e-01)
Checkpoint ...
[33mEpoch 323/500[0m
[33m---------------[0m
Adjusted learning rate to 0.11174
Train ...
Epoch: [323][ 0/61]	Loss 5.0031e-01 (5.0031e-01)
Epoch: [323][25/61]	Loss 3.0139e-01 (4.0232e-01)
Epoch: [323][50/61]	Loss 4.2558e-01 (4.0189e-01)
Checkpoint ...
[33mEpoch 324/500[0m
[33m---------------[0m
Adjusted learning rate to 0.11061
Train ...
Epoch: [324][ 0/61]	Loss 3.0212e-01 (3.0212e-01)
Epoch: [324][25/61]	Loss 4.4658e-01 (4.0139e-01)
Epoch: [324][50/61]	Loss 3.4311e-01 (4.0462e-01)
Checkpoint ...
[33mEpoch 325/500[0m
[33m---------------[0m
Adjusted learning rate to 0.10949
Train ...
Epoch: [325][ 0/61]	Loss 3.5341e-01 (3.5341e-01)
Epoch: [325][25/61]	Loss 5.0435e-01 (3.8280e-01)
Epoch: [325][50/61]	Loss 3.2417e-01 (3.8546e-01)
Checkpoint ...
[33mEpoch 326/500[0m
[33m---------------[0m
Adjusted learning rate to 0.10838
Train ...
Epoch: [326][ 0/61]	Loss 3.7522e-01 (3.7522e-01)
Epoch: [326][25/61]	Loss 3.9500e-01 (4.0680e-01)
Epoch: [326][50/61]	Loss 3.7775e-01 (3.9918e-01)
Checkpoint ...
[33mEpoch 327/500[0m
[33m---------------[0m
Adjusted learning rate to 0.10726
Train ...
Epoch: [327][ 0/61]	Loss 3.8187e-01 (3.8187e-01)
Epoch: [327][25/61]	Loss 3.5325e-01 (3.8846e-01)
Epoch: [327][50/61]	Loss 4.3061e-01 (3.9385e-01)
Checkpoint ...
[33mEpoch 328/500[0m
[33m---------------[0m
Adjusted learning rate to 0.10615
Train ...
Epoch: [328][ 0/61]	Loss 4.0233e-01 (4.0233e-01)
Epoch: [328][25/61]	Loss 4.2021e-01 (3.8547e-01)
Epoch: [328][50/61]	Loss 4.0363e-01 (3.8842e-01)
Checkpoint ...
[33mEpoch 329/500[0m
[33m---------------[0m
Adjusted learning rate to 0.10505
Train ...
Epoch: [329][ 0/61]	Loss 3.8451e-01 (3.8451e-01)
Epoch: [329][25/61]	Loss 2.9998e-01 (3.8151e-01)
Epoch: [329][50/61]	Loss 3.3932e-01 (3.9621e-01)
Checkpoint ...
[33mEpoch 330/500[0m
[33m---------------[0m
Adjusted learning rate to 0.10395
Train ...
Epoch: [330][ 0/61]	Loss 3.9560e-01 (3.9560e-01)
Epoch: [330][25/61]	Loss 3.6989e-01 (3.8330e-01)
Epoch: [330][50/61]	Loss 3.3462e-01 (3.9072e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 79.68
Checkpoint ...
[33mEpoch 331/500[0m
[33m---------------[0m
Adjusted learning rate to 0.10285
Train ...
Epoch: [331][ 0/61]	Loss 3.7511e-01 (3.7511e-01)
Epoch: [331][25/61]	Loss 3.7661e-01 (3.8441e-01)
Epoch: [331][50/61]	Loss 3.9759e-01 (3.7885e-01)
Checkpoint ...
[33mEpoch 332/500[0m
[33m---------------[0m
Adjusted learning rate to 0.10175
Train ...
Epoch: [332][ 0/61]	Loss 3.3126e-01 (3.3126e-01)
Epoch: [332][25/61]	Loss 5.1948e-01 (3.9078e-01)
Epoch: [332][50/61]	Loss 3.4735e-01 (3.8751e-01)
Checkpoint ...
[33mEpoch 333/500[0m
[33m---------------[0m
Adjusted learning rate to 0.10066
Train ...
Epoch: [333][ 0/61]	Loss 4.4037e-01 (4.4037e-01)
Epoch: [333][25/61]	Loss 3.6306e-01 (3.8915e-01)
Epoch: [333][50/61]	Loss 3.5026e-01 (3.8979e-01)
Checkpoint ...
[33mEpoch 334/500[0m
[33m---------------[0m
Adjusted learning rate to 0.09958
Train ...
Epoch: [334][ 0/61]	Loss 4.1493e-01 (4.1493e-01)
Epoch: [334][25/61]	Loss 4.8783e-01 (3.7782e-01)
Epoch: [334][50/61]	Loss 3.4594e-01 (3.8513e-01)
Checkpoint ...
[33mEpoch 335/500[0m
[33m---------------[0m
Adjusted learning rate to 0.09849
Train ...
Epoch: [335][ 0/61]	Loss 3.8886e-01 (3.8886e-01)
Epoch: [335][25/61]	Loss 4.2768e-01 (3.8198e-01)
Epoch: [335][50/61]	Loss 3.4403e-01 (3.7756e-01)
Checkpoint ...
[33mEpoch 336/500[0m
[33m---------------[0m
Adjusted learning rate to 0.09741
Train ...
Epoch: [336][ 0/61]	Loss 3.5649e-01 (3.5649e-01)
Epoch: [336][25/61]	Loss 3.4375e-01 (3.7155e-01)
Epoch: [336][50/61]	Loss 3.7538e-01 (3.7481e-01)
Checkpoint ...
[33mEpoch 337/500[0m
[33m---------------[0m
Adjusted learning rate to 0.09634
Train ...
Epoch: [337][ 0/61]	Loss 3.8087e-01 (3.8087e-01)
Epoch: [337][25/61]	Loss 3.7325e-01 (3.8935e-01)
Epoch: [337][50/61]	Loss 3.4810e-01 (3.8364e-01)
Checkpoint ...
[33mEpoch 338/500[0m
[33m---------------[0m
Adjusted learning rate to 0.09527
Train ...
Epoch: [338][ 0/61]	Loss 4.4744e-01 (4.4744e-01)
Epoch: [338][25/61]	Loss 3.3914e-01 (3.7722e-01)
Epoch: [338][50/61]	Loss 4.0225e-01 (3.8492e-01)
Checkpoint ...
[33mEpoch 339/500[0m
[33m---------------[0m
Adjusted learning rate to 0.09420
Train ...
Epoch: [339][ 0/61]	Loss 3.3748e-01 (3.3748e-01)
Epoch: [339][25/61]	Loss 3.8745e-01 (3.8008e-01)
Epoch: [339][50/61]	Loss 5.4492e-01 (3.8547e-01)
Checkpoint ...
[33mEpoch 340/500[0m
[33m---------------[0m
Adjusted learning rate to 0.09314
Train ...
Epoch: [340][ 0/61]	Loss 4.4198e-01 (4.4198e-01)
Epoch: [340][25/61]	Loss 4.0068e-01 (3.8573e-01)
Epoch: [340][50/61]	Loss 3.0416e-01 (3.7966e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 67.71
Checkpoint ...
[33mEpoch 341/500[0m
[33m---------------[0m
Adjusted learning rate to 0.09208
Train ...
Epoch: [341][ 0/61]	Loss 3.5553e-01 (3.5553e-01)
Epoch: [341][25/61]	Loss 3.4272e-01 (3.7639e-01)
Epoch: [341][50/61]	Loss 3.8787e-01 (3.7874e-01)
Checkpoint ...
[33mEpoch 342/500[0m
[33m---------------[0m
Adjusted learning rate to 0.09103
Train ...
Epoch: [342][ 0/61]	Loss 4.5873e-01 (4.5873e-01)
Epoch: [342][25/61]	Loss 4.5040e-01 (4.1810e-01)
Epoch: [342][50/61]	Loss 3.3140e-01 (4.0700e-01)
Checkpoint ...
[33mEpoch 343/500[0m
[33m---------------[0m
Adjusted learning rate to 0.08998
Train ...
Epoch: [343][ 0/61]	Loss 3.2902e-01 (3.2902e-01)
Epoch: [343][25/61]	Loss 4.5464e-01 (4.0328e-01)
Epoch: [343][50/61]	Loss 4.0291e-01 (3.9331e-01)
Checkpoint ...
[33mEpoch 344/500[0m
[33m---------------[0m
Adjusted learning rate to 0.08894
Train ...
Epoch: [344][ 0/61]	Loss 4.4914e-01 (4.4914e-01)
Epoch: [344][25/61]	Loss 3.5001e-01 (3.7608e-01)
Epoch: [344][50/61]	Loss 3.7281e-01 (3.8436e-01)
Checkpoint ...
[33mEpoch 345/500[0m
[33m---------------[0m
Adjusted learning rate to 0.08790
Train ...
Epoch: [345][ 0/61]	Loss 4.2639e-01 (4.2639e-01)
Epoch: [345][25/61]	Loss 3.2192e-01 (3.7801e-01)
Epoch: [345][50/61]	Loss 3.9426e-01 (3.7277e-01)
Checkpoint ...
[33mEpoch 346/500[0m
[33m---------------[0m
Adjusted learning rate to 0.08686
Train ...
Epoch: [346][ 0/61]	Loss 3.8335e-01 (3.8335e-01)
Epoch: [346][25/61]	Loss 4.0193e-01 (3.8366e-01)
Epoch: [346][50/61]	Loss 3.4227e-01 (3.8525e-01)
Checkpoint ...
[33mEpoch 347/500[0m
[33m---------------[0m
Adjusted learning rate to 0.08583
Train ...
Epoch: [347][ 0/61]	Loss 3.1826e-01 (3.1826e-01)
Epoch: [347][25/61]	Loss 4.0245e-01 (3.7022e-01)
Epoch: [347][50/61]	Loss 3.6139e-01 (3.6953e-01)
Checkpoint ...
[33mEpoch 348/500[0m
[33m---------------[0m
Adjusted learning rate to 0.08480
Train ...
Epoch: [348][ 0/61]	Loss 3.6306e-01 (3.6306e-01)
Epoch: [348][25/61]	Loss 3.7269e-01 (3.7914e-01)
Epoch: [348][50/61]	Loss 3.7478e-01 (3.8196e-01)
Checkpoint ...
[33mEpoch 349/500[0m
[33m---------------[0m
Adjusted learning rate to 0.08378
Train ...
Epoch: [349][ 0/61]	Loss 3.9579e-01 (3.9579e-01)
Epoch: [349][25/61]	Loss 4.6231e-01 (3.9060e-01)
Epoch: [349][50/61]	Loss 3.1073e-01 (3.7514e-01)
Checkpoint ...
[33mEpoch 350/500[0m
[33m---------------[0m
Adjusted learning rate to 0.08276
Train ...
Epoch: [350][ 0/61]	Loss 3.6440e-01 (3.6440e-01)
Epoch: [350][25/61]	Loss 3.5887e-01 (3.7294e-01)
Epoch: [350][50/61]	Loss 2.5404e-01 (3.6917e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 71.59
Checkpoint ...
[33mEpoch 351/500[0m
[33m---------------[0m
Adjusted learning rate to 0.08175
Train ...
Epoch: [351][ 0/61]	Loss 4.2339e-01 (4.2339e-01)
Epoch: [351][25/61]	Loss 3.3098e-01 (3.7707e-01)
Epoch: [351][50/61]	Loss 3.2636e-01 (3.8008e-01)
Checkpoint ...
[33mEpoch 352/500[0m
[33m---------------[0m
Adjusted learning rate to 0.08074
Train ...
Epoch: [352][ 0/61]	Loss 3.4192e-01 (3.4192e-01)
Epoch: [352][25/61]	Loss 3.7864e-01 (3.5788e-01)
Epoch: [352][50/61]	Loss 4.0770e-01 (3.5823e-01)
Checkpoint ...
[33mEpoch 353/500[0m
[33m---------------[0m
Adjusted learning rate to 0.07973
Train ...
Epoch: [353][ 0/61]	Loss 3.0052e-01 (3.0052e-01)
Epoch: [353][25/61]	Loss 2.7070e-01 (3.5967e-01)
Epoch: [353][50/61]	Loss 3.7264e-01 (3.5452e-01)
Checkpoint ...
[33mEpoch 354/500[0m
[33m---------------[0m
Adjusted learning rate to 0.07874
Train ...
Epoch: [354][ 0/61]	Loss 3.4545e-01 (3.4545e-01)
Epoch: [354][25/61]	Loss 4.2234e-01 (3.6331e-01)
Epoch: [354][50/61]	Loss 3.6366e-01 (3.5584e-01)
Checkpoint ...
[33mEpoch 355/500[0m
[33m---------------[0m
Adjusted learning rate to 0.07774
Train ...
Epoch: [355][ 0/61]	Loss 3.5974e-01 (3.5974e-01)
Epoch: [355][25/61]	Loss 3.9812e-01 (3.6833e-01)
Epoch: [355][50/61]	Loss 4.2488e-01 (3.6418e-01)
Checkpoint ...
[33mEpoch 356/500[0m
[33m---------------[0m
Adjusted learning rate to 0.07675
Train ...
Epoch: [356][ 0/61]	Loss 3.6677e-01 (3.6677e-01)
Epoch: [356][25/61]	Loss 3.7848e-01 (3.7388e-01)
Epoch: [356][50/61]	Loss 3.0565e-01 (3.6824e-01)
Checkpoint ...
[33mEpoch 357/500[0m
[33m---------------[0m
Adjusted learning rate to 0.07577
Train ...
Epoch: [357][ 0/61]	Loss 3.4324e-01 (3.4324e-01)
Epoch: [357][25/61]	Loss 4.2523e-01 (3.5918e-01)
Epoch: [357][50/61]	Loss 4.4691e-01 (3.6310e-01)
Checkpoint ...
[33mEpoch 358/500[0m
[33m---------------[0m
Adjusted learning rate to 0.07479
Train ...
Epoch: [358][ 0/61]	Loss 2.8396e-01 (2.8396e-01)
Epoch: [358][25/61]	Loss 3.3204e-01 (3.6458e-01)
Epoch: [358][50/61]	Loss 2.8485e-01 (3.5419e-01)
Checkpoint ...
[33mEpoch 359/500[0m
[33m---------------[0m
Adjusted learning rate to 0.07381
Train ...
Epoch: [359][ 0/61]	Loss 4.0403e-01 (4.0403e-01)
Epoch: [359][25/61]	Loss 3.5760e-01 (3.6304e-01)
Epoch: [359][50/61]	Loss 3.7877e-01 (3.5862e-01)
Checkpoint ...
[33mEpoch 360/500[0m
[33m---------------[0m
Adjusted learning rate to 0.07284
Train ...
Epoch: [360][ 0/61]	Loss 3.4743e-01 (3.4743e-01)
Epoch: [360][25/61]	Loss 3.8921e-01 (3.5840e-01)
Epoch: [360][50/61]	Loss 4.5106e-01 (3.6738e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 77.01
Checkpoint ...
[33mEpoch 361/500[0m
[33m---------------[0m
Adjusted learning rate to 0.07188
Train ...
Epoch: [361][ 0/61]	Loss 4.5598e-01 (4.5598e-01)
Epoch: [361][25/61]	Loss 4.0032e-01 (3.4746e-01)
Epoch: [361][50/61]	Loss 4.2235e-01 (3.5153e-01)
Checkpoint ...
[33mEpoch 362/500[0m
[33m---------------[0m
Adjusted learning rate to 0.07092
Train ...
Epoch: [362][ 0/61]	Loss 4.1746e-01 (4.1746e-01)
Epoch: [362][25/61]	Loss 4.7511e-01 (3.7343e-01)
Epoch: [362][50/61]	Loss 3.7089e-01 (3.6915e-01)
Checkpoint ...
[33mEpoch 363/500[0m
[33m---------------[0m
Adjusted learning rate to 0.06996
Train ...
Epoch: [363][ 0/61]	Loss 3.0718e-01 (3.0718e-01)
Epoch: [363][25/61]	Loss 3.4873e-01 (3.4660e-01)
Epoch: [363][50/61]	Loss 3.7340e-01 (3.5043e-01)
Checkpoint ...
[33mEpoch 364/500[0m
[33m---------------[0m
Adjusted learning rate to 0.06901
Train ...
Epoch: [364][ 0/61]	Loss 4.7269e-01 (4.7269e-01)
Epoch: [364][25/61]	Loss 4.1136e-01 (3.7741e-01)
Epoch: [364][50/61]	Loss 3.4158e-01 (3.7016e-01)
Checkpoint ...
[33mEpoch 365/500[0m
[33m---------------[0m
Adjusted learning rate to 0.06807
Train ...
Epoch: [365][ 0/61]	Loss 4.0009e-01 (4.0009e-01)
Epoch: [365][25/61]	Loss 3.8914e-01 (3.4944e-01)
Epoch: [365][50/61]	Loss 3.1341e-01 (3.5513e-01)
Checkpoint ...
[33mEpoch 366/500[0m
[33m---------------[0m
Adjusted learning rate to 0.06713
Train ...
Epoch: [366][ 0/61]	Loss 3.2960e-01 (3.2960e-01)
Epoch: [366][25/61]	Loss 4.0709e-01 (3.5349e-01)
Epoch: [366][50/61]	Loss 3.0622e-01 (3.5355e-01)
Checkpoint ...
[33mEpoch 367/500[0m
[33m---------------[0m
Adjusted learning rate to 0.06620
Train ...
Epoch: [367][ 0/61]	Loss 3.2310e-01 (3.2310e-01)
Epoch: [367][25/61]	Loss 3.5326e-01 (3.3378e-01)
Epoch: [367][50/61]	Loss 3.5117e-01 (3.3753e-01)
Checkpoint ...
[33mEpoch 368/500[0m
[33m---------------[0m
Adjusted learning rate to 0.06527
Train ...
Epoch: [368][ 0/61]	Loss 3.1570e-01 (3.1570e-01)
Epoch: [368][25/61]	Loss 3.0791e-01 (3.4213e-01)
Epoch: [368][50/61]	Loss 3.1375e-01 (3.4249e-01)
Checkpoint ...
[33mEpoch 369/500[0m
[33m---------------[0m
Adjusted learning rate to 0.06435
Train ...
Epoch: [369][ 0/61]	Loss 3.2673e-01 (3.2673e-01)
Epoch: [369][25/61]	Loss 3.0346e-01 (3.5680e-01)
Epoch: [369][50/61]	Loss 2.6876e-01 (3.5234e-01)
Checkpoint ...
[33mEpoch 370/500[0m
[33m---------------[0m
Adjusted learning rate to 0.06343
Train ...
Epoch: [370][ 0/61]	Loss 3.8768e-01 (3.8768e-01)
Epoch: [370][25/61]	Loss 3.5019e-01 (3.4808e-01)
Epoch: [370][50/61]	Loss 3.1007e-01 (3.4396e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 85.14
Checkpoint ...
[33mEpoch 371/500[0m
[33m---------------[0m
Adjusted learning rate to 0.06252
Train ...
Epoch: [371][ 0/61]	Loss 2.9512e-01 (2.9512e-01)
Epoch: [371][25/61]	Loss 3.5523e-01 (3.3103e-01)
Epoch: [371][50/61]	Loss 2.9555e-01 (3.4565e-01)
Checkpoint ...
[33mEpoch 372/500[0m
[33m---------------[0m
Adjusted learning rate to 0.06161
Train ...
Epoch: [372][ 0/61]	Loss 2.6304e-01 (2.6304e-01)
Epoch: [372][25/61]	Loss 3.1700e-01 (3.4039e-01)
Epoch: [372][50/61]	Loss 3.5406e-01 (3.3972e-01)
Checkpoint ...
[33mEpoch 373/500[0m
[33m---------------[0m
Adjusted learning rate to 0.06071
Train ...
Epoch: [373][ 0/61]	Loss 3.2188e-01 (3.2188e-01)
Epoch: [373][25/61]	Loss 2.6918e-01 (3.5042e-01)
Epoch: [373][50/61]	Loss 3.8988e-01 (3.4828e-01)
Checkpoint ...
[33mEpoch 374/500[0m
[33m---------------[0m
Adjusted learning rate to 0.05981
Train ...
Epoch: [374][ 0/61]	Loss 3.0099e-01 (3.0099e-01)
Epoch: [374][25/61]	Loss 3.3917e-01 (3.5162e-01)
Epoch: [374][50/61]	Loss 4.2320e-01 (3.4629e-01)
Checkpoint ...
[33mEpoch 375/500[0m
[33m---------------[0m
Adjusted learning rate to 0.05892
Train ...
Epoch: [375][ 0/61]	Loss 2.6826e-01 (2.6826e-01)
Epoch: [375][25/61]	Loss 3.1881e-01 (3.1749e-01)
Epoch: [375][50/61]	Loss 3.1368e-01 (3.2390e-01)
Checkpoint ...
[33mEpoch 376/500[0m
[33m---------------[0m
Adjusted learning rate to 0.05804
Train ...
Epoch: [376][ 0/61]	Loss 3.3395e-01 (3.3395e-01)
Epoch: [376][25/61]	Loss 4.1026e-01 (3.3631e-01)
Epoch: [376][50/61]	Loss 4.1214e-01 (3.4478e-01)
Checkpoint ...
[33mEpoch 377/500[0m
[33m---------------[0m
Adjusted learning rate to 0.05716
Train ...
Epoch: [377][ 0/61]	Loss 2.8518e-01 (2.8518e-01)
Epoch: [377][25/61]	Loss 3.9481e-01 (3.3654e-01)
Epoch: [377][50/61]	Loss 3.9627e-01 (3.3482e-01)
Checkpoint ...
[33mEpoch 378/500[0m
[33m---------------[0m
Adjusted learning rate to 0.05628
Train ...
Epoch: [378][ 0/61]	Loss 3.0121e-01 (3.0121e-01)
Epoch: [378][25/61]	Loss 3.5390e-01 (3.4370e-01)
Epoch: [378][50/61]	Loss 3.4898e-01 (3.4522e-01)
Checkpoint ...
[33mEpoch 379/500[0m
[33m---------------[0m
Adjusted learning rate to 0.05541
Train ...
Epoch: [379][ 0/61]	Loss 3.1959e-01 (3.1959e-01)
Epoch: [379][25/61]	Loss 3.1354e-01 (3.3639e-01)
Epoch: [379][50/61]	Loss 3.5383e-01 (3.3773e-01)
Checkpoint ...
[33mEpoch 380/500[0m
[33m---------------[0m
Adjusted learning rate to 0.05455
Train ...
Epoch: [380][ 0/61]	Loss 2.4902e-01 (2.4902e-01)
Epoch: [380][25/61]	Loss 3.0528e-01 (3.3540e-01)
Epoch: [380][50/61]	Loss 3.1352e-01 (3.3206e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 74.79
Checkpoint ...
[33mEpoch 381/500[0m
[33m---------------[0m
Adjusted learning rate to 0.05370
Train ...
Epoch: [381][ 0/61]	Loss 3.0192e-01 (3.0192e-01)
Epoch: [381][25/61]	Loss 3.0128e-01 (3.3808e-01)
Epoch: [381][50/61]	Loss 3.5075e-01 (3.3490e-01)
Checkpoint ...
[33mEpoch 382/500[0m
[33m---------------[0m
Adjusted learning rate to 0.05284
Train ...
Epoch: [382][ 0/61]	Loss 3.7065e-01 (3.7065e-01)
Epoch: [382][25/61]	Loss 3.3788e-01 (3.3742e-01)
Epoch: [382][50/61]	Loss 2.5018e-01 (3.3557e-01)
Checkpoint ...
[33mEpoch 383/500[0m
[33m---------------[0m
Adjusted learning rate to 0.05200
Train ...
Epoch: [383][ 0/61]	Loss 3.7861e-01 (3.7861e-01)
Epoch: [383][25/61]	Loss 2.8631e-01 (3.2313e-01)
Epoch: [383][50/61]	Loss 3.3791e-01 (3.2389e-01)
Checkpoint ...
[33mEpoch 384/500[0m
[33m---------------[0m
Adjusted learning rate to 0.05116
Train ...
Epoch: [384][ 0/61]	Loss 3.0286e-01 (3.0286e-01)
Epoch: [384][25/61]	Loss 2.9000e-01 (3.2364e-01)
Epoch: [384][50/61]	Loss 4.3940e-01 (3.2617e-01)
Checkpoint ...
[33mEpoch 385/500[0m
[33m---------------[0m
Adjusted learning rate to 0.05033
Train ...
Epoch: [385][ 0/61]	Loss 3.3191e-01 (3.3191e-01)
Epoch: [385][25/61]	Loss 4.4081e-01 (3.3219e-01)
Epoch: [385][50/61]	Loss 3.0900e-01 (3.2812e-01)
Checkpoint ...
[33mEpoch 386/500[0m
[33m---------------[0m
Adjusted learning rate to 0.04950
Train ...
Epoch: [386][ 0/61]	Loss 3.2354e-01 (3.2354e-01)
Epoch: [386][25/61]	Loss 3.9993e-01 (3.2122e-01)
Epoch: [386][50/61]	Loss 3.1217e-01 (3.2192e-01)
Checkpoint ...
[33mEpoch 387/500[0m
[33m---------------[0m
Adjusted learning rate to 0.04868
Train ...
Epoch: [387][ 0/61]	Loss 3.4701e-01 (3.4701e-01)
Epoch: [387][25/61]	Loss 3.1494e-01 (3.2193e-01)
Epoch: [387][50/61]	Loss 2.3270e-01 (3.1890e-01)
Checkpoint ...
[33mEpoch 388/500[0m
[33m---------------[0m
Adjusted learning rate to 0.04786
Train ...
Epoch: [388][ 0/61]	Loss 3.1746e-01 (3.1746e-01)
Epoch: [388][25/61]	Loss 3.6175e-01 (3.2778e-01)
Epoch: [388][50/61]	Loss 3.0337e-01 (3.2742e-01)
Checkpoint ...
[33mEpoch 389/500[0m
[33m---------------[0m
Adjusted learning rate to 0.04705
Train ...
Epoch: [389][ 0/61]	Loss 2.7601e-01 (2.7601e-01)
Epoch: [389][25/61]	Loss 3.8419e-01 (3.1435e-01)
Epoch: [389][50/61]	Loss 3.3356e-01 (3.1905e-01)
Checkpoint ...
[33mEpoch 390/500[0m
[33m---------------[0m
Adjusted learning rate to 0.04625
Train ...
Epoch: [390][ 0/61]	Loss 3.5728e-01 (3.5728e-01)
Epoch: [390][25/61]	Loss 4.0207e-01 (3.1021e-01)
Epoch: [390][50/61]	Loss 3.2291e-01 (3.2667e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 65.66
Checkpoint ...
[33mEpoch 391/500[0m
[33m---------------[0m
Adjusted learning rate to 0.04545
Train ...
Epoch: [391][ 0/61]	Loss 3.2083e-01 (3.2083e-01)
Epoch: [391][25/61]	Loss 3.0868e-01 (3.3071e-01)
Epoch: [391][50/61]	Loss 3.4559e-01 (3.2583e-01)
Checkpoint ...
[33mEpoch 392/500[0m
[33m---------------[0m
Adjusted learning rate to 0.04466
Train ...
Epoch: [392][ 0/61]	Loss 3.7240e-01 (3.7240e-01)
Epoch: [392][25/61]	Loss 3.2779e-01 (3.2093e-01)
Epoch: [392][50/61]	Loss 3.3398e-01 (3.2424e-01)
Checkpoint ...
[33mEpoch 393/500[0m
[33m---------------[0m
Adjusted learning rate to 0.04388
Train ...
Epoch: [393][ 0/61]	Loss 3.5370e-01 (3.5370e-01)
Epoch: [393][25/61]	Loss 3.7015e-01 (3.2330e-01)
Epoch: [393][50/61]	Loss 3.7717e-01 (3.2087e-01)
Checkpoint ...
[33mEpoch 394/500[0m
[33m---------------[0m
Adjusted learning rate to 0.04310
Train ...
Epoch: [394][ 0/61]	Loss 3.1518e-01 (3.1518e-01)
Epoch: [394][25/61]	Loss 3.1753e-01 (3.0365e-01)
Epoch: [394][50/61]	Loss 2.8108e-01 (3.0619e-01)
Checkpoint ...
[33mEpoch 395/500[0m
[33m---------------[0m
Adjusted learning rate to 0.04233
Train ...
Epoch: [395][ 0/61]	Loss 3.0071e-01 (3.0071e-01)
Epoch: [395][25/61]	Loss 3.5212e-01 (3.0358e-01)
Epoch: [395][50/61]	Loss 2.9338e-01 (3.1029e-01)
Checkpoint ...
[33mEpoch 396/500[0m
[33m---------------[0m
Adjusted learning rate to 0.04156
Train ...
Epoch: [396][ 0/61]	Loss 3.3527e-01 (3.3527e-01)
Epoch: [396][25/61]	Loss 2.8665e-01 (3.1337e-01)
Epoch: [396][50/61]	Loss 4.0570e-01 (3.1724e-01)
Checkpoint ...
[33mEpoch 397/500[0m
[33m---------------[0m
Adjusted learning rate to 0.04080
Train ...
Epoch: [397][ 0/61]	Loss 3.6960e-01 (3.6960e-01)
Epoch: [397][25/61]	Loss 2.8484e-01 (3.1313e-01)
Epoch: [397][50/61]	Loss 2.9447e-01 (3.0836e-01)
Checkpoint ...
[33mEpoch 398/500[0m
[33m---------------[0m
Adjusted learning rate to 0.04005
Train ...
Epoch: [398][ 0/61]	Loss 3.4560e-01 (3.4560e-01)
Epoch: [398][25/61]	Loss 3.2679e-01 (3.1258e-01)
Epoch: [398][50/61]	Loss 2.9104e-01 (3.0893e-01)
Checkpoint ...
[33mEpoch 399/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03930
Train ...
Epoch: [399][ 0/61]	Loss 3.3745e-01 (3.3745e-01)
Epoch: [399][25/61]	Loss 3.2346e-01 (3.2543e-01)
Epoch: [399][50/61]	Loss 3.7414e-01 (3.1849e-01)
Checkpoint ...
[33mEpoch 400/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03856
Train ...
Epoch: [400][ 0/61]	Loss 3.3046e-01 (3.3046e-01)
Epoch: [400][25/61]	Loss 4.1183e-01 (3.0757e-01)
Epoch: [400][50/61]	Loss 3.1018e-01 (3.0560e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 68.07
Checkpoint ...
[33mEpoch 401/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03782
Train ...
Epoch: [401][ 0/61]	Loss 3.0672e-01 (3.0672e-01)
Epoch: [401][25/61]	Loss 3.0135e-01 (3.0903e-01)
Epoch: [401][50/61]	Loss 2.8538e-01 (3.0001e-01)
Checkpoint ...
[33mEpoch 402/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03710
Train ...
Epoch: [402][ 0/61]	Loss 3.0322e-01 (3.0322e-01)
Epoch: [402][25/61]	Loss 2.8423e-01 (3.1159e-01)
Epoch: [402][50/61]	Loss 4.3472e-01 (3.0184e-01)
Checkpoint ...
[33mEpoch 403/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03637
Train ...
Epoch: [403][ 0/61]	Loss 3.6165e-01 (3.6165e-01)
Epoch: [403][25/61]	Loss 3.1107e-01 (3.2085e-01)
Epoch: [403][50/61]	Loss 3.4180e-01 (3.1931e-01)
Checkpoint ...
[33mEpoch 404/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03566
Train ...
Epoch: [404][ 0/61]	Loss 2.9949e-01 (2.9949e-01)
Epoch: [404][25/61]	Loss 2.3459e-01 (3.0085e-01)
Epoch: [404][50/61]	Loss 3.2721e-01 (3.0540e-01)
Checkpoint ...
[33mEpoch 405/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03495
Train ...
Epoch: [405][ 0/61]	Loss 3.8073e-01 (3.8073e-01)
Epoch: [405][25/61]	Loss 2.5236e-01 (3.0618e-01)
Epoch: [405][50/61]	Loss 2.9868e-01 (3.0647e-01)
Checkpoint ...
[33mEpoch 406/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03425
Train ...
Epoch: [406][ 0/61]	Loss 2.6803e-01 (2.6803e-01)
Epoch: [406][25/61]	Loss 3.1768e-01 (2.9951e-01)
Epoch: [406][50/61]	Loss 3.1824e-01 (3.0362e-01)
Checkpoint ...
[33mEpoch 407/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03355
Train ...
Epoch: [407][ 0/61]	Loss 2.7503e-01 (2.7503e-01)
Epoch: [407][25/61]	Loss 2.9346e-01 (3.1665e-01)
Epoch: [407][50/61]	Loss 2.5683e-01 (3.1094e-01)
Checkpoint ...
[33mEpoch 408/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03286
Train ...
Epoch: [408][ 0/61]	Loss 2.9292e-01 (2.9292e-01)
Epoch: [408][25/61]	Loss 2.5496e-01 (3.0739e-01)
Epoch: [408][50/61]	Loss 3.1615e-01 (3.0146e-01)
Checkpoint ...
[33mEpoch 409/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03218
Train ...
Epoch: [409][ 0/61]	Loss 3.8597e-01 (3.8597e-01)
Epoch: [409][25/61]	Loss 2.8275e-01 (2.9470e-01)
Epoch: [409][50/61]	Loss 2.9246e-01 (2.9721e-01)
Checkpoint ...
[33mEpoch 410/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03150
Train ...
Epoch: [410][ 0/61]	Loss 3.0331e-01 (3.0331e-01)
Epoch: [410][25/61]	Loss 2.7709e-01 (2.9196e-01)
Epoch: [410][50/61]	Loss 3.0942e-01 (2.9404e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 76.42
Checkpoint ...
[33mEpoch 411/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03083
Train ...
Epoch: [411][ 0/61]	Loss 2.8419e-01 (2.8419e-01)
Epoch: [411][25/61]	Loss 2.5589e-01 (3.0565e-01)
Epoch: [411][50/61]	Loss 3.5706e-01 (3.0801e-01)
Checkpoint ...
[33mEpoch 412/500[0m
[33m---------------[0m
Adjusted learning rate to 0.03017
Train ...
Epoch: [412][ 0/61]	Loss 3.8696e-01 (3.8696e-01)
Epoch: [412][25/61]	Loss 2.8862e-01 (3.1611e-01)
Epoch: [412][50/61]	Loss 2.4486e-01 (3.0181e-01)
Checkpoint ...
[33mEpoch 413/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02952
Train ...
Epoch: [413][ 0/61]	Loss 2.8413e-01 (2.8413e-01)
Epoch: [413][25/61]	Loss 2.2907e-01 (2.9341e-01)
Epoch: [413][50/61]	Loss 2.6323e-01 (2.9160e-01)
Checkpoint ...
[33mEpoch 414/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02887
Train ...
Epoch: [414][ 0/61]	Loss 3.3559e-01 (3.3559e-01)
Epoch: [414][25/61]	Loss 3.0849e-01 (2.9194e-01)
Epoch: [414][50/61]	Loss 3.7238e-01 (2.9200e-01)
Checkpoint ...
[33mEpoch 415/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02822
Train ...
Epoch: [415][ 0/61]	Loss 4.1050e-01 (4.1050e-01)
Epoch: [415][25/61]	Loss 2.6874e-01 (2.9702e-01)
Epoch: [415][50/61]	Loss 3.8345e-01 (2.9702e-01)
Checkpoint ...
[33mEpoch 416/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02759
Train ...
Epoch: [416][ 0/61]	Loss 3.3880e-01 (3.3880e-01)
Epoch: [416][25/61]	Loss 2.9731e-01 (2.8034e-01)
Epoch: [416][50/61]	Loss 2.6624e-01 (2.8404e-01)
Checkpoint ...
[33mEpoch 417/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02696
Train ...
Epoch: [417][ 0/61]	Loss 2.4319e-01 (2.4319e-01)
Epoch: [417][25/61]	Loss 2.5088e-01 (2.8985e-01)
Epoch: [417][50/61]	Loss 2.8020e-01 (2.9668e-01)
Checkpoint ...
[33mEpoch 418/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02634
Train ...
Epoch: [418][ 0/61]	Loss 3.2843e-01 (3.2843e-01)
Epoch: [418][25/61]	Loss 2.7872e-01 (3.0043e-01)
Epoch: [418][50/61]	Loss 3.1027e-01 (2.9297e-01)
Checkpoint ...
[33mEpoch 419/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02572
Train ...
Epoch: [419][ 0/61]	Loss 2.2527e-01 (2.2527e-01)
Epoch: [419][25/61]	Loss 3.2473e-01 (2.7770e-01)
Epoch: [419][50/61]	Loss 2.4252e-01 (2.8169e-01)
Checkpoint ...
[33mEpoch 420/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02511
Train ...
Epoch: [420][ 0/61]	Loss 3.1217e-01 (3.1217e-01)
Epoch: [420][25/61]	Loss 3.5582e-01 (3.1608e-01)
Epoch: [420][50/61]	Loss 2.6521e-01 (2.8994e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 84.77
Checkpoint ...
[33mEpoch 421/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02451
Train ...
Epoch: [421][ 0/61]	Loss 3.4370e-01 (3.4370e-01)
Epoch: [421][25/61]	Loss 2.5508e-01 (2.8634e-01)
Epoch: [421][50/61]	Loss 2.9675e-01 (2.8981e-01)
Checkpoint ...
[33mEpoch 422/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02392
Train ...
Epoch: [422][ 0/61]	Loss 2.9881e-01 (2.9881e-01)
Epoch: [422][25/61]	Loss 3.3440e-01 (2.9222e-01)
Epoch: [422][50/61]	Loss 3.3211e-01 (2.9107e-01)
Checkpoint ...
[33mEpoch 423/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02333
Train ...
Epoch: [423][ 0/61]	Loss 2.9950e-01 (2.9950e-01)
Epoch: [423][25/61]	Loss 2.5089e-01 (2.8172e-01)
Epoch: [423][50/61]	Loss 2.7145e-01 (2.9039e-01)
Checkpoint ...
[33mEpoch 424/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02275
Train ...
Epoch: [424][ 0/61]	Loss 3.1700e-01 (3.1700e-01)
Epoch: [424][25/61]	Loss 3.4661e-01 (2.8008e-01)
Epoch: [424][50/61]	Loss 3.0301e-01 (2.7744e-01)
Checkpoint ...
[33mEpoch 425/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02218
Train ...
Epoch: [425][ 0/61]	Loss 2.6175e-01 (2.6175e-01)
Epoch: [425][25/61]	Loss 3.3542e-01 (2.9068e-01)
Epoch: [425][50/61]	Loss 3.0652e-01 (2.8452e-01)
Checkpoint ...
[33mEpoch 426/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02161
Train ...
Epoch: [426][ 0/61]	Loss 2.4153e-01 (2.4153e-01)
Epoch: [426][25/61]	Loss 2.8040e-01 (2.7831e-01)
Epoch: [426][50/61]	Loss 3.1733e-01 (2.7545e-01)
Checkpoint ...
[33mEpoch 427/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02105
Train ...
Epoch: [427][ 0/61]	Loss 3.1579e-01 (3.1579e-01)
Epoch: [427][25/61]	Loss 2.9002e-01 (2.8048e-01)
Epoch: [427][50/61]	Loss 2.8496e-01 (2.8075e-01)
Checkpoint ...
[33mEpoch 428/500[0m
[33m---------------[0m
Adjusted learning rate to 0.02050
Train ...
Epoch: [428][ 0/61]	Loss 3.0884e-01 (3.0884e-01)
Epoch: [428][25/61]	Loss 2.6665e-01 (2.7700e-01)
Epoch: [428][50/61]	Loss 3.2769e-01 (2.7570e-01)
Checkpoint ...
[33mEpoch 429/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01995
Train ...
Epoch: [429][ 0/61]	Loss 2.9655e-01 (2.9655e-01)
Epoch: [429][25/61]	Loss 2.3983e-01 (2.8659e-01)
Epoch: [429][50/61]	Loss 2.7713e-01 (2.7720e-01)
Checkpoint ...
[33mEpoch 430/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01942
Train ...
Epoch: [430][ 0/61]	Loss 2.8529e-01 (2.8529e-01)
Epoch: [430][25/61]	Loss 2.5280e-01 (2.7855e-01)
Epoch: [430][50/61]	Loss 2.6288e-01 (2.8252e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 88.83
Checkpoint ...
[33mEpoch 431/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01888
Train ...
Epoch: [431][ 0/61]	Loss 2.2441e-01 (2.2441e-01)
Epoch: [431][25/61]	Loss 3.6087e-01 (2.8810e-01)
Epoch: [431][50/61]	Loss 3.8821e-01 (2.8139e-01)
Checkpoint ...
[33mEpoch 432/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01836
Train ...
Epoch: [432][ 0/61]	Loss 2.8913e-01 (2.8913e-01)
Epoch: [432][25/61]	Loss 3.2500e-01 (2.8105e-01)
Epoch: [432][50/61]	Loss 3.5198e-01 (2.8150e-01)
Checkpoint ...
[33mEpoch 433/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01784
Train ...
Epoch: [433][ 0/61]	Loss 2.8989e-01 (2.8989e-01)
Epoch: [433][25/61]	Loss 2.2880e-01 (2.9048e-01)
Epoch: [433][50/61]	Loss 3.4814e-01 (2.8909e-01)
Checkpoint ...
[33mEpoch 434/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01733
Train ...
Epoch: [434][ 0/61]	Loss 2.6331e-01 (2.6331e-01)
Epoch: [434][25/61]	Loss 3.6634e-01 (2.7725e-01)
Epoch: [434][50/61]	Loss 3.2432e-01 (2.7300e-01)
Checkpoint ...
[33mEpoch 435/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01683
Train ...
Epoch: [435][ 0/61]	Loss 2.4315e-01 (2.4315e-01)
Epoch: [435][25/61]	Loss 3.0637e-01 (2.7999e-01)
Epoch: [435][50/61]	Loss 2.6292e-01 (2.7808e-01)
Checkpoint ...
[33mEpoch 436/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01634
Train ...
Epoch: [436][ 0/61]	Loss 2.7516e-01 (2.7516e-01)
Epoch: [436][25/61]	Loss 2.7722e-01 (2.8595e-01)
Epoch: [436][50/61]	Loss 2.9175e-01 (2.7537e-01)
Checkpoint ...
[33mEpoch 437/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01585
Train ...
Epoch: [437][ 0/61]	Loss 2.9261e-01 (2.9261e-01)
Epoch: [437][25/61]	Loss 2.6319e-01 (2.7263e-01)
Epoch: [437][50/61]	Loss 2.8917e-01 (2.7769e-01)
Checkpoint ...
[33mEpoch 438/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01537
Train ...
Epoch: [438][ 0/61]	Loss 2.6430e-01 (2.6430e-01)
Epoch: [438][25/61]	Loss 2.5131e-01 (2.6837e-01)
Epoch: [438][50/61]	Loss 3.0284e-01 (2.7717e-01)
Checkpoint ...
[33mEpoch 439/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01490
Train ...
Epoch: [439][ 0/61]	Loss 2.5179e-01 (2.5179e-01)
Epoch: [439][25/61]	Loss 2.4825e-01 (2.6866e-01)
Epoch: [439][50/61]	Loss 3.0230e-01 (2.7606e-01)
Checkpoint ...
[33mEpoch 440/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01443
Train ...
Epoch: [440][ 0/61]	Loss 2.8255e-01 (2.8255e-01)
Epoch: [440][25/61]	Loss 2.8679e-01 (2.7662e-01)
Epoch: [440][50/61]	Loss 2.8473e-01 (2.7034e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 81.20
Checkpoint ...
[33mEpoch 441/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01397
Train ...
Epoch: [441][ 0/61]	Loss 2.9253e-01 (2.9253e-01)
Epoch: [441][25/61]	Loss 2.6339e-01 (2.6404e-01)
Epoch: [441][50/61]	Loss 3.0493e-01 (2.6944e-01)
Checkpoint ...
[33mEpoch 442/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01352
Train ...
Epoch: [442][ 0/61]	Loss 2.9650e-01 (2.9650e-01)
Epoch: [442][25/61]	Loss 2.6123e-01 (2.8691e-01)
Epoch: [442][50/61]	Loss 2.3869e-01 (2.8103e-01)
Checkpoint ...
[33mEpoch 443/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01308
Train ...
Epoch: [443][ 0/61]	Loss 2.7030e-01 (2.7030e-01)
Epoch: [443][25/61]	Loss 3.1102e-01 (2.8231e-01)
Epoch: [443][50/61]	Loss 2.2990e-01 (2.7844e-01)
Checkpoint ...
[33mEpoch 444/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01264
Train ...
Epoch: [444][ 0/61]	Loss 2.4871e-01 (2.4871e-01)
Epoch: [444][25/61]	Loss 3.1035e-01 (2.6713e-01)
Epoch: [444][50/61]	Loss 2.4794e-01 (2.6542e-01)
Checkpoint ...
[33mEpoch 445/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01221
Train ...
Epoch: [445][ 0/61]	Loss 2.8726e-01 (2.8726e-01)
Epoch: [445][25/61]	Loss 2.7632e-01 (2.6683e-01)
Epoch: [445][50/61]	Loss 2.5209e-01 (2.7189e-01)
Checkpoint ...
[33mEpoch 446/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01179
Train ...
Epoch: [446][ 0/61]	Loss 2.8561e-01 (2.8561e-01)
Epoch: [446][25/61]	Loss 2.6783e-01 (2.5843e-01)
Epoch: [446][50/61]	Loss 2.8451e-01 (2.6651e-01)
Checkpoint ...
[33mEpoch 447/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01138
Train ...
Epoch: [447][ 0/61]	Loss 3.3003e-01 (3.3003e-01)
Epoch: [447][25/61]	Loss 2.8005e-01 (2.8019e-01)
Epoch: [447][50/61]	Loss 2.2142e-01 (2.7529e-01)
Checkpoint ...
[33mEpoch 448/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01097
Train ...
Epoch: [448][ 0/61]	Loss 2.6724e-01 (2.6724e-01)
Epoch: [448][25/61]	Loss 2.7731e-01 (2.7130e-01)
Epoch: [448][50/61]	Loss 2.4383e-01 (2.6397e-01)
Checkpoint ...
[33mEpoch 449/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01057
Train ...
Epoch: [449][ 0/61]	Loss 2.7026e-01 (2.7026e-01)
Epoch: [449][25/61]	Loss 2.8277e-01 (2.7087e-01)
Epoch: [449][50/61]	Loss 3.0033e-01 (2.6882e-01)
Checkpoint ...
[33mEpoch 450/500[0m
[33m---------------[0m
Adjusted learning rate to 0.01018
Train ...
Epoch: [450][ 0/61]	Loss 2.0542e-01 (2.0542e-01)
Epoch: [450][25/61]	Loss 2.8825e-01 (2.6572e-01)
Epoch: [450][50/61]	Loss 2.0909e-01 (2.6470e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 85.18
Checkpoint ...
[33mEpoch 451/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00979
Train ...
Epoch: [451][ 0/61]	Loss 3.6192e-01 (3.6192e-01)
Epoch: [451][25/61]	Loss 2.1536e-01 (2.6978e-01)
Epoch: [451][50/61]	Loss 2.1661e-01 (2.6960e-01)
Checkpoint ...
[33mEpoch 452/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00942
Train ...
Epoch: [452][ 0/61]	Loss 3.0826e-01 (3.0826e-01)
Epoch: [452][25/61]	Loss 3.1235e-01 (2.5880e-01)
Epoch: [452][50/61]	Loss 2.1397e-01 (2.6516e-01)
Checkpoint ...
[33mEpoch 453/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00905
Train ...
Epoch: [453][ 0/61]	Loss 2.4242e-01 (2.4242e-01)
Epoch: [453][25/61]	Loss 2.1850e-01 (2.6979e-01)
Epoch: [453][50/61]	Loss 2.6640e-01 (2.7071e-01)
Checkpoint ...
[33mEpoch 454/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00869
Train ...
Epoch: [454][ 0/61]	Loss 3.1490e-01 (3.1490e-01)
Epoch: [454][25/61]	Loss 3.1473e-01 (2.7360e-01)
Epoch: [454][50/61]	Loss 2.6294e-01 (2.7015e-01)
Checkpoint ...
[33mEpoch 455/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00833
Train ...
Epoch: [455][ 0/61]	Loss 2.5564e-01 (2.5564e-01)
Epoch: [455][25/61]	Loss 2.9486e-01 (2.6581e-01)
Epoch: [455][50/61]	Loss 2.6492e-01 (2.6806e-01)
Checkpoint ...
[33mEpoch 456/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00799
Train ...
Epoch: [456][ 0/61]	Loss 2.6603e-01 (2.6603e-01)
Epoch: [456][25/61]	Loss 3.2654e-01 (2.6814e-01)
Epoch: [456][50/61]	Loss 3.4869e-01 (2.7004e-01)
Checkpoint ...
[33mEpoch 457/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00765
Train ...
Epoch: [457][ 0/61]	Loss 2.6338e-01 (2.6338e-01)
Epoch: [457][25/61]	Loss 2.2667e-01 (2.5892e-01)
Epoch: [457][50/61]	Loss 2.7131e-01 (2.6094e-01)
Checkpoint ...
[33mEpoch 458/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00732
Train ...
Epoch: [458][ 0/61]	Loss 2.4561e-01 (2.4561e-01)
Epoch: [458][25/61]	Loss 3.1556e-01 (2.6434e-01)
Epoch: [458][50/61]	Loss 2.3442e-01 (2.6881e-01)
Checkpoint ...
[33mEpoch 459/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00699
Train ...
Epoch: [459][ 0/61]	Loss 2.8465e-01 (2.8465e-01)
Epoch: [459][25/61]	Loss 2.7254e-01 (2.5958e-01)
Epoch: [459][50/61]	Loss 3.4708e-01 (2.5974e-01)
Checkpoint ...
[33mEpoch 460/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00668
Train ...
Epoch: [460][ 0/61]	Loss 2.0025e-01 (2.0025e-01)
Epoch: [460][25/61]	Loss 2.3435e-01 (2.6613e-01)
Epoch: [460][50/61]	Loss 2.6355e-01 (2.6241e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 76.01
Checkpoint ...
[33mEpoch 461/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00637
Train ...
Epoch: [461][ 0/61]	Loss 3.3300e-01 (3.3300e-01)
Epoch: [461][25/61]	Loss 2.4505e-01 (2.7621e-01)
Epoch: [461][50/61]	Loss 2.4235e-01 (2.7422e-01)
Checkpoint ...
[33mEpoch 462/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00607
Train ...
Epoch: [462][ 0/61]	Loss 2.3612e-01 (2.3612e-01)
Epoch: [462][25/61]	Loss 2.8089e-01 (2.5919e-01)
Epoch: [462][50/61]	Loss 2.2741e-01 (2.6545e-01)
Checkpoint ...
[33mEpoch 463/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00577
Train ...
Epoch: [463][ 0/61]	Loss 2.7770e-01 (2.7770e-01)
Epoch: [463][25/61]	Loss 1.9943e-01 (2.7858e-01)
Epoch: [463][50/61]	Loss 2.5161e-01 (2.7545e-01)
Checkpoint ...
[33mEpoch 464/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00549
Train ...
Epoch: [464][ 0/61]	Loss 2.6610e-01 (2.6610e-01)
Epoch: [464][25/61]	Loss 3.0543e-01 (2.6403e-01)
Epoch: [464][50/61]	Loss 2.5097e-01 (2.6724e-01)
Checkpoint ...
[33mEpoch 465/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00521
Train ...
Epoch: [465][ 0/61]	Loss 3.3742e-01 (3.3742e-01)
Epoch: [465][25/61]	Loss 3.0311e-01 (2.6797e-01)
Epoch: [465][50/61]	Loss 2.2027e-01 (2.6083e-01)
Checkpoint ...
[33mEpoch 466/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00494
Train ...
Epoch: [466][ 0/61]	Loss 2.7282e-01 (2.7282e-01)
Epoch: [466][25/61]	Loss 2.4902e-01 (2.4806e-01)
Epoch: [466][50/61]	Loss 1.9966e-01 (2.4946e-01)
Checkpoint ...
[33mEpoch 467/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00468
Train ...
Epoch: [467][ 0/61]	Loss 2.1858e-01 (2.1858e-01)
Epoch: [467][25/61]	Loss 2.7588e-01 (2.4429e-01)
Epoch: [467][50/61]	Loss 2.7411e-01 (2.5335e-01)
Checkpoint ...
[33mEpoch 468/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00442
Train ...
Epoch: [468][ 0/61]	Loss 3.1525e-01 (3.1525e-01)
Epoch: [468][25/61]	Loss 2.1443e-01 (2.5676e-01)
Epoch: [468][50/61]	Loss 2.3600e-01 (2.6174e-01)
Checkpoint ...
[33mEpoch 469/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00418
Train ...
Epoch: [469][ 0/61]	Loss 2.7701e-01 (2.7701e-01)
Epoch: [469][25/61]	Loss 2.2691e-01 (2.4703e-01)
Epoch: [469][50/61]	Loss 2.3185e-01 (2.5018e-01)
Checkpoint ...
[33mEpoch 470/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00394
Train ...
Epoch: [470][ 0/61]	Loss 3.0367e-01 (3.0367e-01)
Epoch: [470][25/61]	Loss 2.2777e-01 (2.5913e-01)
Epoch: [470][50/61]	Loss 2.1432e-01 (2.5804e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 83.40
Checkpoint ...
[33mEpoch 471/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00371
Train ...
Epoch: [471][ 0/61]	Loss 2.6579e-01 (2.6579e-01)
Epoch: [471][25/61]	Loss 2.4236e-01 (2.5590e-01)
Epoch: [471][50/61]	Loss 2.3477e-01 (2.5577e-01)
Checkpoint ...
[33mEpoch 472/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00348
Train ...
Epoch: [472][ 0/61]	Loss 3.2112e-01 (3.2112e-01)
Epoch: [472][25/61]	Loss 2.1661e-01 (2.6534e-01)
Epoch: [472][50/61]	Loss 2.7978e-01 (2.5888e-01)
Checkpoint ...
[33mEpoch 473/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00327
Train ...
Epoch: [473][ 0/61]	Loss 2.5219e-01 (2.5219e-01)
Epoch: [473][25/61]	Loss 2.4763e-01 (2.5518e-01)
Epoch: [473][50/61]	Loss 2.5196e-01 (2.5127e-01)
Checkpoint ...
[33mEpoch 474/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00306
Train ...
Epoch: [474][ 0/61]	Loss 3.6409e-01 (3.6409e-01)
Epoch: [474][25/61]	Loss 2.1508e-01 (2.5373e-01)
Epoch: [474][50/61]	Loss 2.8144e-01 (2.5971e-01)
Checkpoint ...
[33mEpoch 475/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00286
Train ...
Epoch: [475][ 0/61]	Loss 1.7502e-01 (1.7502e-01)
Epoch: [475][25/61]	Loss 2.7049e-01 (2.5723e-01)
Epoch: [475][50/61]	Loss 2.4000e-01 (2.5315e-01)
Checkpoint ...
[33mEpoch 476/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00267
Train ...
Epoch: [476][ 0/61]	Loss 3.0704e-01 (3.0704e-01)
Epoch: [476][25/61]	Loss 2.5153e-01 (2.6534e-01)
Epoch: [476][50/61]	Loss 1.9145e-01 (2.5590e-01)
Checkpoint ...
[33mEpoch 477/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00248
Train ...
Epoch: [477][ 0/61]	Loss 2.6447e-01 (2.6447e-01)
Epoch: [477][25/61]	Loss 3.3815e-01 (2.6091e-01)
Epoch: [477][50/61]	Loss 3.0285e-01 (2.6229e-01)
Checkpoint ...
[33mEpoch 478/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00231
Train ...
Epoch: [478][ 0/61]	Loss 2.6806e-01 (2.6806e-01)
Epoch: [478][25/61]	Loss 3.3524e-01 (2.3490e-01)
Epoch: [478][50/61]	Loss 2.7269e-01 (2.4388e-01)
Checkpoint ...
[33mEpoch 479/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00214
Train ...
Epoch: [479][ 0/61]	Loss 2.1067e-01 (2.1067e-01)
Epoch: [479][25/61]	Loss 3.1028e-01 (2.5955e-01)
Epoch: [479][50/61]	Loss 2.0790e-01 (2.5776e-01)
Checkpoint ...
[33mEpoch 480/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00198
Train ...
Epoch: [480][ 0/61]	Loss 2.5834e-01 (2.5834e-01)
Epoch: [480][25/61]	Loss 1.8474e-01 (2.3684e-01)
Epoch: [480][50/61]	Loss 2.3213e-01 (2.4610e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 91.89
Checkpoint ...
[33mEpoch 481/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00182
Train ...
Epoch: [481][ 0/61]	Loss 2.7446e-01 (2.7446e-01)
Epoch: [481][25/61]	Loss 2.6741e-01 (2.6263e-01)
Epoch: [481][50/61]	Loss 2.0994e-01 (2.5810e-01)
Checkpoint ...
[33mEpoch 482/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00168
Train ...
Epoch: [482][ 0/61]	Loss 2.7385e-01 (2.7385e-01)
Epoch: [482][25/61]	Loss 2.5224e-01 (2.6034e-01)
Epoch: [482][50/61]	Loss 2.3459e-01 (2.5564e-01)
Checkpoint ...
[33mEpoch 483/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00154
Train ...
Epoch: [483][ 0/61]	Loss 2.2917e-01 (2.2917e-01)
Epoch: [483][25/61]	Loss 2.3456e-01 (2.6152e-01)
Epoch: [483][50/61]	Loss 2.9918e-01 (2.5671e-01)
Checkpoint ...
[33mEpoch 484/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00141
Train ...
Epoch: [484][ 0/61]	Loss 1.9855e-01 (1.9855e-01)
Epoch: [484][25/61]	Loss 2.2262e-01 (2.4552e-01)
Epoch: [484][50/61]	Loss 2.2749e-01 (2.4992e-01)
Checkpoint ...
[33mEpoch 485/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00129
Train ...
Epoch: [485][ 0/61]	Loss 1.9568e-01 (1.9568e-01)
Epoch: [485][25/61]	Loss 2.6314e-01 (2.4474e-01)
Epoch: [485][50/61]	Loss 2.7694e-01 (2.4576e-01)
Checkpoint ...
[33mEpoch 486/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00117
Train ...
Epoch: [486][ 0/61]	Loss 3.1856e-01 (3.1856e-01)
Epoch: [486][25/61]	Loss 3.0578e-01 (2.7727e-01)
Epoch: [486][50/61]	Loss 2.6692e-01 (2.6677e-01)
Checkpoint ...
[33mEpoch 487/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00107
Train ...
Epoch: [487][ 0/61]	Loss 2.5784e-01 (2.5784e-01)
Epoch: [487][25/61]	Loss 3.3938e-01 (2.5090e-01)
Epoch: [487][50/61]	Loss 2.2924e-01 (2.4506e-01)
Checkpoint ...
[33mEpoch 488/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00097
Train ...
Epoch: [488][ 0/61]	Loss 2.3451e-01 (2.3451e-01)
Epoch: [488][25/61]	Loss 2.3057e-01 (2.4757e-01)
Epoch: [488][50/61]	Loss 2.2128e-01 (2.4648e-01)
Checkpoint ...
[33mEpoch 489/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00088
Train ...
Epoch: [489][ 0/61]	Loss 2.0877e-01 (2.0877e-01)
Epoch: [489][25/61]	Loss 2.5023e-01 (2.6073e-01)
Epoch: [489][50/61]	Loss 2.3770e-01 (2.5497e-01)
Checkpoint ...
[33mEpoch 490/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00079
Train ...
Epoch: [490][ 0/61]	Loss 2.7772e-01 (2.7772e-01)
Epoch: [490][25/61]	Loss 2.7675e-01 (2.5775e-01)
Epoch: [490][50/61]	Loss 1.9793e-01 (2.5950e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 91.80
Checkpoint ...
[33mEpoch 491/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00072
Train ...
Epoch: [491][ 0/61]	Loss 3.0671e-01 (3.0671e-01)
Epoch: [491][25/61]	Loss 2.4809e-01 (2.6416e-01)
Epoch: [491][50/61]	Loss 3.3538e-01 (2.5783e-01)
Checkpoint ...
[33mEpoch 492/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00065
Train ...
Epoch: [492][ 0/61]	Loss 3.0991e-01 (3.0991e-01)
Epoch: [492][25/61]	Loss 2.6804e-01 (2.5712e-01)
Epoch: [492][50/61]	Loss 3.0679e-01 (2.5758e-01)
Checkpoint ...
[33mEpoch 493/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00059
Train ...
Epoch: [493][ 0/61]	Loss 2.4111e-01 (2.4111e-01)
Epoch: [493][25/61]	Loss 2.5435e-01 (2.4806e-01)
Epoch: [493][50/61]	Loss 2.2319e-01 (2.4420e-01)
Checkpoint ...
[33mEpoch 494/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00054
Train ...
Epoch: [494][ 0/61]	Loss 1.9133e-01 (1.9133e-01)
Epoch: [494][25/61]	Loss 2.5350e-01 (2.5339e-01)
Epoch: [494][50/61]	Loss 2.2438e-01 (2.6035e-01)
Checkpoint ...
[33mEpoch 495/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00050
Train ...
Epoch: [495][ 0/61]	Loss 1.7158e-01 (1.7158e-01)
Epoch: [495][25/61]	Loss 3.3793e-01 (2.5632e-01)
Epoch: [495][50/61]	Loss 2.5097e-01 (2.5192e-01)
Checkpoint ...
[33mEpoch 496/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00046
Train ...
Epoch: [496][ 0/61]	Loss 2.4504e-01 (2.4504e-01)
Epoch: [496][25/61]	Loss 2.3851e-01 (2.5809e-01)
Epoch: [496][50/61]	Loss 2.6454e-01 (2.5846e-01)
Checkpoint ...
[33mEpoch 497/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00044
Train ...
Epoch: [497][ 0/61]	Loss 1.9683e-01 (1.9683e-01)
Epoch: [497][25/61]	Loss 3.6619e-01 (2.6367e-01)
Epoch: [497][50/61]	Loss 2.4630e-01 (2.5873e-01)
Checkpoint ...
[33mEpoch 498/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00042
Train ...
Epoch: [498][ 0/61]	Loss 2.2253e-01 (2.2253e-01)
Epoch: [498][25/61]	Loss 1.8370e-01 (2.4755e-01)
Epoch: [498][50/61]	Loss 3.5135e-01 (2.5653e-01)
Checkpoint ...
[33mEpoch 499/500[0m
[33m---------------[0m
Adjusted learning rate to 0.00040
Train ...
Epoch: [499][ 0/61]	Loss 2.0873e-01 (2.0873e-01)
Epoch: [499][25/61]	Loss 2.6325e-01 (2.5245e-01)
Epoch: [499][50/61]	Loss 2.0943e-01 (2.5153e-01)
Fill memory bank for kNN...
Fill Memory Bank [0/62]
Evaluate ...
Result of kNN evaluation is 91.61
Checkpoint ...
[34mFill memory bank for mining the nearest neighbors (train) ...[0m
Fill Memory Bank [0/62]
Mine the nearest neighbors (Top-20)
Accuracy of top-20 nearest neighbors on train set is 35.19
[34mFill memory bank for mining the nearest neighbors (val) ...[0m
Fill Memory Bank [0/62]
Mine the nearest neighbors (Top-5)
Accuracy of top-5 nearest neighbors on val set is 39.45
