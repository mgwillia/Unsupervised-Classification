vulcan19.umiacs.umd.edu
[31m{'setup': 'scan', 'criterion': 'scanf', 'criterion_kwargs': {'entropy_weight': 5.0}, 'update_cluster_head_only': False, 'num_heads': 1, 'backbone': 'resnet18', 'train_db_name': 'cifar-10', 'val_db_name': 'cifar-10', 'num_classes': 10, 'num_neighbors': 20, 'num_strangers': 20, 'augmentation_strategy': 'ours', 'augmentation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}, 'num_strong_augs': 4, 'cutout_kwargs': {'n_holes': 1, 'length': 16, 'random': True}}, 'transformation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}}, 'optimizer': 'adam', 'optimizer_kwargs': {'lr': 0.001, 'weight_decay': 0.0001}, 'epochs': 50, 'batch_size': 128, 'num_workers': 8, 'scheduler': 'constant', 'pretext_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/pretext', 'pretext_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/pretext/checkpoint.pth.tar', 'pretext_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/pretext/model.pth.tar', 'topk_neighbors_train_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/pretext/topk-val-neighbors.npy', 'topk_strangers_train_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/pretext/topk-train-strangers.npy', 'topk_strangers_val_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/pretext/topk-val-strangers.npy', 'scan_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/scan', 'scan_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/scan/checkpoint.pth.tar', 'scan_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/scan/model.pth.tar', 'scanf_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/scanf', 'scanf_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/scanf/checkpoint.pth.tar', 'scanf_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/scanf/model.pth.tar', 'selflabel_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/selflabel', 'selflabel_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/selflabel/checkpoint.pth.tar', 'selflabel_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/selflabel/model.pth.tar'}[0m
[34mGet dataset and dataloaders[0m
Files already downloaded and verified
Train transforms: Compose(
    RandomHorizontalFlip(p=0.5)
    RandomCrop(size=(32, 32), padding=None)
    <data.augment.Augment object at 0x7f6b5b9a3190>
    ToTensor()
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
    <data.augment.Cutout object at 0x7f6b5b9a33d0>
)
Validation transforms: Compose(
    CenterCrop(size=(32, 32))
    ToTensor()
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
Train samples 50000 - Val samples 10000
[34mGet model[0m
ClusteringModel(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (cluster_head): ModuleList(
    (0): Linear(in_features=512, out_features=10, bias=True)
  )
)
[34mGet optimizer[0m
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0001
)
[34mGet loss[0m
SCANFLoss(
  (softmax): Softmax(dim=1)
  (bce): BCELoss()
)
[34mRestart from checkpoint /cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/cifar-10/scanf/checkpoint.pth.tar[0m
[34mStarting main loop[0m
[33mEpoch 30/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [29][  0/390]	Total Loss 8.6046e-01 (8.6046e-01)	Consistency Loss 6.3481e-01 (6.3481e-01)	Stranger Loss 2.2564e-01 (2.2564e-01)
Epoch: [29][ 25/390]	Total Loss 1.1473e+00 (1.1259e+00)	Consistency Loss 7.9456e-01 (7.2743e-01)	Stranger Loss 3.5274e-01 (3.9846e-01)
Epoch: [29][ 50/390]	Total Loss 1.0451e+00 (1.1413e+00)	Consistency Loss 7.2152e-01 (7.3898e-01)	Stranger Loss 3.2353e-01 (4.0230e-01)
Epoch: [29][ 75/390]	Total Loss 1.0792e+00 (1.1427e+00)	Consistency Loss 7.0420e-01 (7.3388e-01)	Stranger Loss 3.7497e-01 (4.0883e-01)
Epoch: [29][100/390]	Total Loss 1.1509e+00 (1.1422e+00)	Consistency Loss 7.0974e-01 (7.3109e-01)	Stranger Loss 4.4113e-01 (4.1111e-01)
Epoch: [29][125/390]	Total Loss 1.1796e+00 (1.1423e+00)	Consistency Loss 7.3959e-01 (7.3064e-01)	Stranger Loss 4.4005e-01 (4.1164e-01)
Epoch: [29][150/390]	Total Loss 1.1560e+00 (1.1384e+00)	Consistency Loss 7.2929e-01 (7.2550e-01)	Stranger Loss 4.2675e-01 (4.1289e-01)
Epoch: [29][175/390]	Total Loss 1.0827e+00 (1.1321e+00)	Consistency Loss 6.5485e-01 (7.1852e-01)	Stranger Loss 4.2782e-01 (4.1360e-01)
Epoch: [29][200/390]	Total Loss 1.1194e+00 (1.1340e+00)	Consistency Loss 6.9387e-01 (7.2043e-01)	Stranger Loss 4.2556e-01 (4.1358e-01)
Epoch: [29][225/390]	Total Loss 1.1656e+00 (1.1304e+00)	Consistency Loss 7.6062e-01 (7.1847e-01)	Stranger Loss 4.0495e-01 (4.1196e-01)
Epoch: [29][250/390]	Total Loss 1.1973e+00 (1.1284e+00)	Consistency Loss 7.5595e-01 (7.1640e-01)	Stranger Loss 4.4133e-01 (4.1203e-01)
Epoch: [29][275/390]	Total Loss 1.1366e+00 (1.1244e+00)	Consistency Loss 6.8507e-01 (7.1254e-01)	Stranger Loss 4.5149e-01 (4.1187e-01)
Epoch: [29][300/390]	Total Loss 9.7683e-01 (1.1213e+00)	Consistency Loss 5.6532e-01 (7.0993e-01)	Stranger Loss 4.1151e-01 (4.1142e-01)
Epoch: [29][325/390]	Total Loss 1.0410e+00 (1.1186e+00)	Consistency Loss 6.3629e-01 (7.0830e-01)	Stranger Loss 4.0476e-01 (4.1026e-01)
Epoch: [29][350/390]	Total Loss 1.0427e+00 (1.1180e+00)	Consistency Loss 6.5680e-01 (7.0655e-01)	Stranger Loss 3.8588e-01 (4.1145e-01)
Epoch: [29][375/390]	Total Loss 1.1152e+00 (1.1154e+00)	Consistency Loss 6.7895e-01 (7.0434e-01)	Stranger Loss 4.3626e-01 (4.1106e-01)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'consistency': 0.5442514419555664, 'stranger': 0.428946316242218, 'total_loss': 0.9731977581977844}], 'lowest_loss_head': 0, 'lowest_loss': 0.9731977581977844}
No new lowest loss on validation set: 0.8369 -> 0.9732
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2144, 'ARI': 0.0883102971938678, 'NMI': 0.17379451716681435, 'ACC Top-5': 0.5681, 'hungarian_match': [(0, 4), (1, 0), (2, 1), (3, 6), (4, 3), (5, 9), (6, 2), (7, 5), (8, 7), (9, 8)]}
Checkpoint ...
[33mEpoch 31/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [30][  0/390]	Total Loss 1.1013e+00 (1.1013e+00)	Consistency Loss 7.1602e-01 (7.1602e-01)	Stranger Loss 3.8530e-01 (3.8530e-01)
Epoch: [30][ 25/390]	Total Loss 1.1310e+00 (1.1144e+00)	Consistency Loss 6.6007e-01 (6.9168e-01)	Stranger Loss 4.7091e-01 (4.2274e-01)
Epoch: [30][ 50/390]	Total Loss 9.9667e-01 (1.0934e+00)	Consistency Loss 6.4372e-01 (6.8074e-01)	Stranger Loss 3.5294e-01 (4.1268e-01)
Epoch: [30][ 75/390]	Total Loss 1.0393e+00 (1.0937e+00)	Consistency Loss 6.7012e-01 (6.8176e-01)	Stranger Loss 3.6921e-01 (4.1194e-01)
Epoch: [30][100/390]	Total Loss 1.1257e+00 (1.0937e+00)	Consistency Loss 7.3347e-01 (6.7754e-01)	Stranger Loss 3.9220e-01 (4.1620e-01)
Epoch: [30][125/390]	Total Loss 1.0534e+00 (1.0929e+00)	Consistency Loss 6.8968e-01 (6.7943e-01)	Stranger Loss 3.6371e-01 (4.1345e-01)
Epoch: [30][150/390]	Total Loss 1.0724e+00 (1.0914e+00)	Consistency Loss 6.3540e-01 (6.7868e-01)	Stranger Loss 4.3704e-01 (4.1277e-01)
Epoch: [30][175/390]	Total Loss 1.0587e+00 (1.0868e+00)	Consistency Loss 6.0376e-01 (6.7355e-01)	Stranger Loss 4.5490e-01 (4.1321e-01)
Epoch: [30][200/390]	Total Loss 1.0877e+00 (1.0895e+00)	Consistency Loss 7.0135e-01 (6.7749e-01)	Stranger Loss 3.8630e-01 (4.1205e-01)
Epoch: [30][225/390]	Total Loss 9.8294e-01 (1.0889e+00)	Consistency Loss 6.3748e-01 (6.7764e-01)	Stranger Loss 3.4546e-01 (4.1131e-01)
Epoch: [30][250/390]	Total Loss 9.9345e-01 (1.0879e+00)	Consistency Loss 6.0364e-01 (6.7686e-01)	Stranger Loss 3.8981e-01 (4.1104e-01)
Epoch: [30][275/390]	Total Loss 1.0279e+00 (1.0869e+00)	Consistency Loss 7.0387e-01 (6.7715e-01)	Stranger Loss 3.2404e-01 (4.0972e-01)
Epoch: [30][300/390]	Total Loss 1.2274e+00 (1.0879e+00)	Consistency Loss 7.3111e-01 (6.7818e-01)	Stranger Loss 4.9628e-01 (4.0975e-01)
Epoch: [30][325/390]	Total Loss 1.1916e+00 (1.0891e+00)	Consistency Loss 7.5588e-01 (6.7935e-01)	Stranger Loss 4.3573e-01 (4.0975e-01)
Epoch: [30][350/390]	Total Loss 9.5090e-01 (1.0896e+00)	Consistency Loss 5.8983e-01 (6.8027e-01)	Stranger Loss 3.6108e-01 (4.0936e-01)
Epoch: [30][375/390]	Total Loss 1.1371e+00 (1.0892e+00)	Consistency Loss 7.5634e-01 (6.7984e-01)	Stranger Loss 3.8075e-01 (4.0932e-01)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'consistency': 0.5487865209579468, 'stranger': 0.39130085706710815, 'total_loss': 0.9400873780250549}], 'lowest_loss_head': 0, 'lowest_loss': 0.9400873780250549}
No new lowest loss on validation set: 0.8369 -> 0.9401
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2304, 'ARI': 0.0989979494946665, 'NMI': 0.175346847775052, 'ACC Top-5': 0.579, 'hungarian_match': [(0, 4), (1, 5), (2, 1), (3, 2), (4, 3), (5, 9), (6, 0), (7, 6), (8, 7), (9, 8)]}
Checkpoint ...
[33mEpoch 32/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [31][  0/390]	Total Loss 1.0220e+00 (1.0220e+00)	Consistency Loss 6.4855e-01 (6.4855e-01)	Stranger Loss 3.7341e-01 (3.7341e-01)
Epoch: [31][ 25/390]	Total Loss 1.1635e+00 (1.0980e+00)	Consistency Loss 7.6327e-01 (6.8773e-01)	Stranger Loss 4.0019e-01 (4.1024e-01)
Epoch: [31][ 50/390]	Total Loss 1.1764e+00 (1.0893e+00)	Consistency Loss 7.6534e-01 (6.7937e-01)	Stranger Loss 4.1108e-01 (4.0993e-01)
Epoch: [31][ 75/390]	Total Loss 1.0554e+00 (1.0843e+00)	Consistency Loss 6.4057e-01 (6.7612e-01)	Stranger Loss 4.1486e-01 (4.0823e-01)
Epoch: [31][100/390]	Total Loss 1.0335e+00 (1.0812e+00)	Consistency Loss 6.4208e-01 (6.7508e-01)	Stranger Loss 3.9140e-01 (4.0611e-01)
Epoch: [31][125/390]	Total Loss 1.0568e+00 (1.0830e+00)	Consistency Loss 6.2552e-01 (6.7503e-01)	Stranger Loss 4.3131e-01 (4.0794e-01)
Epoch: [31][150/390]	Total Loss 1.0819e+00 (1.0849e+00)	Consistency Loss 6.8146e-01 (6.7696e-01)	Stranger Loss 4.0040e-01 (4.0794e-01)
Epoch: [31][175/390]	Total Loss 1.0302e+00 (1.0796e+00)	Consistency Loss 6.1673e-01 (6.7308e-01)	Stranger Loss 4.1347e-01 (4.0653e-01)
Epoch: [31][200/390]	Total Loss 1.1850e+00 (1.0798e+00)	Consistency Loss 7.1452e-01 (6.7197e-01)	Stranger Loss 4.7047e-01 (4.0783e-01)
Epoch: [31][225/390]	Total Loss 1.0740e+00 (1.0821e+00)	Consistency Loss 6.7517e-01 (6.7303e-01)	Stranger Loss 3.9879e-01 (4.0907e-01)
Epoch: [31][250/390]	Total Loss 1.0714e+00 (1.0816e+00)	Consistency Loss 6.9431e-01 (6.7318e-01)	Stranger Loss 3.7712e-01 (4.0840e-01)
Epoch: [31][275/390]	Total Loss 1.0282e+00 (1.0813e+00)	Consistency Loss 6.5295e-01 (6.7233e-01)	Stranger Loss 3.7530e-01 (4.0897e-01)
Epoch: [31][300/390]	Total Loss 1.1708e+00 (1.0802e+00)	Consistency Loss 7.4813e-01 (6.7100e-01)	Stranger Loss 4.2264e-01 (4.0922e-01)
Epoch: [31][325/390]	Total Loss 1.2080e+00 (1.0832e+00)	Consistency Loss 7.9934e-01 (6.7362e-01)	Stranger Loss 4.0868e-01 (4.0955e-01)
Epoch: [31][350/390]	Total Loss 1.0292e+00 (1.0833e+00)	Consistency Loss 6.1876e-01 (6.7352e-01)	Stranger Loss 4.1041e-01 (4.0981e-01)
Epoch: [31][375/390]	Total Loss 9.6922e-01 (1.0813e+00)	Consistency Loss 5.9269e-01 (6.7166e-01)	Stranger Loss 3.7653e-01 (4.0967e-01)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'consistency': 0.5153571367263794, 'stranger': 0.4468192160129547, 'total_loss': 0.9621763527393341}], 'lowest_loss_head': 0, 'lowest_loss': 0.9621763527393341}
No new lowest loss on validation set: 0.8369 -> 0.9622
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.23, 'ARI': 0.11238805819491207, 'NMI': 0.19487650195138936, 'ACC Top-5': 0.5602, 'hungarian_match': [(0, 4), (1, 0), (2, 5), (3, 2), (4, 3), (5, 9), (6, 1), (7, 6), (8, 7), (9, 8)]}
Checkpoint ...
[33mEpoch 33/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [32][  0/390]	Total Loss 1.1045e+00 (1.1045e+00)	Consistency Loss 6.5097e-01 (6.5097e-01)	Stranger Loss 4.5356e-01 (4.5356e-01)
Epoch: [32][ 25/390]	Total Loss 1.0642e+00 (1.0895e+00)	Consistency Loss 6.3543e-01 (6.6690e-01)	Stranger Loss 4.2878e-01 (4.2263e-01)
Epoch: [32][ 50/390]	Total Loss 1.1252e+00 (1.0796e+00)	Consistency Loss 7.2262e-01 (6.6389e-01)	Stranger Loss 4.0254e-01 (4.1575e-01)
Epoch: [32][ 75/390]	Total Loss 1.0126e+00 (1.0793e+00)	Consistency Loss 6.1611e-01 (6.6353e-01)	Stranger Loss 3.9650e-01 (4.1579e-01)
Epoch: [32][100/390]	Total Loss 1.0008e+00 (1.0821e+00)	Consistency Loss 5.9945e-01 (6.6819e-01)	Stranger Loss 4.0134e-01 (4.1388e-01)
Epoch: [32][125/390]	Total Loss 1.0790e+00 (1.0822e+00)	Consistency Loss 6.5370e-01 (6.6918e-01)	Stranger Loss 4.2528e-01 (4.1300e-01)
Epoch: [32][150/390]	Total Loss 1.0969e+00 (1.0775e+00)	Consistency Loss 6.5932e-01 (6.6508e-01)	Stranger Loss 4.3754e-01 (4.1240e-01)
Epoch: [32][175/390]	Total Loss 1.1399e+00 (1.0788e+00)	Consistency Loss 7.6637e-01 (6.6684e-01)	Stranger Loss 3.7350e-01 (4.1192e-01)
Epoch: [32][200/390]	Total Loss 1.1359e+00 (1.0811e+00)	Consistency Loss 6.8156e-01 (6.6844e-01)	Stranger Loss 4.5429e-01 (4.1268e-01)
Epoch: [32][225/390]	Total Loss 1.0310e+00 (1.0800e+00)	Consistency Loss 5.8612e-01 (6.6827e-01)	Stranger Loss 4.4485e-01 (4.1172e-01)
Epoch: [32][250/390]	Total Loss 1.0923e+00 (1.0811e+00)	Consistency Loss 6.3849e-01 (6.6825e-01)	Stranger Loss 4.5382e-01 (4.1286e-01)
Epoch: [32][275/390]	Total Loss 1.1013e+00 (1.0803e+00)	Consistency Loss 7.1264e-01 (6.6787e-01)	Stranger Loss 3.8861e-01 (4.1240e-01)
Epoch: [32][300/390]	Total Loss 1.1005e+00 (1.0790e+00)	Consistency Loss 7.4167e-01 (6.6779e-01)	Stranger Loss 3.5883e-01 (4.1125e-01)
Epoch: [32][325/390]	Total Loss 1.0508e+00 (1.0795e+00)	Consistency Loss 6.4927e-01 (6.6762e-01)	Stranger Loss 4.0157e-01 (4.1189e-01)
Epoch: [32][350/390]	Total Loss 1.2205e+00 (1.0796e+00)	Consistency Loss 7.1108e-01 (6.6876e-01)	Stranger Loss 5.0937e-01 (4.1080e-01)
Epoch: [32][375/390]	Total Loss 1.0728e+00 (1.0801e+00)	Consistency Loss 6.5559e-01 (6.6911e-01)	Stranger Loss 4.1720e-01 (4.1101e-01)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'consistency': 0.5151180624961853, 'stranger': 0.40019524097442627, 'total_loss': 0.9153133034706116}], 'lowest_loss_head': 0, 'lowest_loss': 0.9153133034706116}
No new lowest loss on validation set: 0.8369 -> 0.9153
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.225, 'ARI': 0.10235976578887784, 'NMI': 0.17349941755496273, 'ACC Top-5': 0.5758, 'hungarian_match': [(0, 4), (1, 5), (2, 1), (3, 2), (4, 3), (5, 9), (6, 0), (7, 6), (8, 7), (9, 8)]}
Checkpoint ...
[33mEpoch 34/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [33][  0/390]	Total Loss 1.0928e+00 (1.0928e+00)	Consistency Loss 6.7794e-01 (6.7794e-01)	Stranger Loss 4.1483e-01 (4.1483e-01)
Epoch: [33][ 25/390]	Total Loss 1.0225e+00 (1.0725e+00)	Consistency Loss 6.2483e-01 (6.6879e-01)	Stranger Loss 3.9767e-01 (4.0373e-01)
Epoch: [33][ 50/390]	Total Loss 1.1610e+00 (1.0682e+00)	Consistency Loss 7.0286e-01 (6.6307e-01)	Stranger Loss 4.5817e-01 (4.0517e-01)
Epoch: [33][ 75/390]	Total Loss 9.7042e-01 (1.0682e+00)	Consistency Loss 5.8015e-01 (6.6331e-01)	Stranger Loss 3.9026e-01 (4.0485e-01)
Epoch: [33][100/390]	Total Loss 9.6743e-01 (1.0595e+00)	Consistency Loss 6.2327e-01 (6.5540e-01)	Stranger Loss 3.4415e-01 (4.0407e-01)
Epoch: [33][125/390]	Total Loss 1.1016e+00 (1.0573e+00)	Consistency Loss 6.3543e-01 (6.5305e-01)	Stranger Loss 4.6614e-01 (4.0425e-01)
Epoch: [33][150/390]	Total Loss 1.0415e+00 (1.0570e+00)	Consistency Loss 6.3503e-01 (6.5349e-01)	Stranger Loss 4.0649e-01 (4.0348e-01)
Epoch: [33][175/390]	Total Loss 1.0843e+00 (1.0566e+00)	Consistency Loss 7.3087e-01 (6.5379e-01)	Stranger Loss 3.5343e-01 (4.0280e-01)
Epoch: [33][200/390]	Total Loss 1.0910e+00 (1.0578e+00)	Consistency Loss 7.1508e-01 (6.5612e-01)	Stranger Loss 3.7592e-01 (4.0172e-01)
Epoch: [33][225/390]	Total Loss 1.0555e+00 (1.0590e+00)	Consistency Loss 6.0568e-01 (6.5729e-01)	Stranger Loss 4.4978e-01 (4.0170e-01)
Epoch: [33][250/390]	Total Loss 1.1081e+00 (1.0608e+00)	Consistency Loss 6.7122e-01 (6.5816e-01)	Stranger Loss 4.3689e-01 (4.0268e-01)
Epoch: [33][275/390]	Total Loss 1.0987e+00 (1.0639e+00)	Consistency Loss 7.1969e-01 (6.6125e-01)	Stranger Loss 3.7901e-01 (4.0260e-01)
Epoch: [33][300/390]	Total Loss 1.2335e+00 (1.0642e+00)	Consistency Loss 7.8267e-01 (6.6152e-01)	Stranger Loss 4.5085e-01 (4.0269e-01)
Epoch: [33][325/390]	Total Loss 1.0286e+00 (1.0648e+00)	Consistency Loss 6.2655e-01 (6.6126e-01)	Stranger Loss 4.0208e-01 (4.0357e-01)
Epoch: [33][350/390]	Total Loss 1.1495e+00 (1.0677e+00)	Consistency Loss 7.8057e-01 (6.6350e-01)	Stranger Loss 3.6889e-01 (4.0416e-01)
Epoch: [33][375/390]	Total Loss 1.0690e+00 (1.0688e+00)	Consistency Loss 6.7278e-01 (6.6331e-01)	Stranger Loss 3.9621e-01 (4.0549e-01)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'consistency': 0.5130673050880432, 'stranger': 0.4201827645301819, 'total_loss': 0.9332500696182251}], 'lowest_loss_head': 0, 'lowest_loss': 0.9332500696182251}
No new lowest loss on validation set: 0.8369 -> 0.9333
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2253, 'ARI': 0.10248401551010472, 'NMI': 0.17663444880496082, 'ACC Top-5': 0.558, 'hungarian_match': [(0, 4), (1, 0), (2, 1), (3, 5), (4, 3), (5, 9), (6, 2), (7, 6), (8, 7), (9, 8)]}
Checkpoint ...
[33mEpoch 35/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [34][  0/390]	Total Loss 1.0009e+00 (1.0009e+00)	Consistency Loss 6.2710e-01 (6.2710e-01)	Stranger Loss 3.7383e-01 (3.7383e-01)
Epoch: [34][ 25/390]	Total Loss 1.0764e+00 (1.0783e+00)	Consistency Loss 7.2026e-01 (6.6833e-01)	Stranger Loss 3.5610e-01 (4.1001e-01)
Epoch: [34][ 50/390]	Total Loss 1.1275e+00 (1.0637e+00)	Consistency Loss 6.5028e-01 (6.5836e-01)	Stranger Loss 4.7722e-01 (4.0534e-01)
Epoch: [34][ 75/390]	Total Loss 1.0005e+00 (1.0616e+00)	Consistency Loss 6.2080e-01 (6.5710e-01)	Stranger Loss 3.7971e-01 (4.0453e-01)
Epoch: [34][100/390]	Total Loss 1.2295e+00 (1.0656e+00)	Consistency Loss 7.1314e-01 (6.5802e-01)	Stranger Loss 5.1638e-01 (4.0755e-01)
Epoch: [34][125/390]	Total Loss 1.2175e+00 (1.0635e+00)	Consistency Loss 7.6769e-01 (6.5820e-01)	Stranger Loss 4.4978e-01 (4.0527e-01)
Epoch: [34][150/390]	Total Loss 1.1090e+00 (1.0664e+00)	Consistency Loss 7.4546e-01 (6.6059e-01)	Stranger Loss 3.6351e-01 (4.0585e-01)
Epoch: [34][175/390]	Total Loss 1.0711e+00 (1.0694e+00)	Consistency Loss 6.3550e-01 (6.6342e-01)	Stranger Loss 4.3557e-01 (4.0597e-01)
Epoch: [34][200/390]	Total Loss 1.0759e+00 (1.0716e+00)	Consistency Loss 6.0181e-01 (6.6435e-01)	Stranger Loss 4.7408e-01 (4.0729e-01)
Epoch: [34][225/390]	Total Loss 1.1155e+00 (1.0739e+00)	Consistency Loss 6.8655e-01 (6.6549e-01)	Stranger Loss 4.2894e-01 (4.0841e-01)
Epoch: [34][250/390]	Total Loss 1.0231e+00 (1.0737e+00)	Consistency Loss 6.9228e-01 (6.6577e-01)	Stranger Loss 3.3082e-01 (4.0794e-01)
Epoch: [34][275/390]	Total Loss 1.0635e+00 (1.0739e+00)	Consistency Loss 6.8129e-01 (6.6660e-01)	Stranger Loss 3.8217e-01 (4.0728e-01)
Epoch: [34][300/390]	Total Loss 1.0617e+00 (1.0736e+00)	Consistency Loss 6.9803e-01 (6.6541e-01)	Stranger Loss 3.6365e-01 (4.0816e-01)
Epoch: [34][325/390]	Total Loss 1.1769e+00 (1.0736e+00)	Consistency Loss 7.1267e-01 (6.6580e-01)	Stranger Loss 4.6420e-01 (4.0782e-01)
Epoch: [34][350/390]	Total Loss 1.1107e+00 (1.0755e+00)	Consistency Loss 7.0791e-01 (6.6802e-01)	Stranger Loss 4.0280e-01 (4.0751e-01)
Epoch: [34][375/390]	Total Loss 1.1088e+00 (1.0741e+00)	Consistency Loss 7.1473e-01 (6.6695e-01)	Stranger Loss 3.9406e-01 (4.0720e-01)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'consistency': 0.5281323194503784, 'stranger': 0.4027491509914398, 'total_loss': 0.9308814704418182}], 'lowest_loss_head': 0, 'lowest_loss': 0.9308814704418182}
No new lowest loss on validation set: 0.8369 -> 0.9309
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2159, 'ARI': 0.09099025581480728, 'NMI': 0.16776023589775252, 'ACC Top-5': 0.5249, 'hungarian_match': [(0, 4), (1, 0), (2, 1), (3, 5), (4, 3), (5, 9), (6, 2), (7, 6), (8, 7), (9, 8)]}
Checkpoint ...
[33mEpoch 36/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [35][  0/390]	Total Loss 1.0600e+00 (1.0600e+00)	Consistency Loss 6.3445e-01 (6.3445e-01)	Stranger Loss 4.2554e-01 (4.2554e-01)
Epoch: [35][ 25/390]	Total Loss 1.0399e+00 (1.0887e+00)	Consistency Loss 6.3463e-01 (6.7698e-01)	Stranger Loss 4.0527e-01 (4.1170e-01)
Epoch: [35][ 50/390]	Total Loss 1.0922e+00 (1.0711e+00)	Consistency Loss 6.8813e-01 (6.6301e-01)	Stranger Loss 4.0410e-01 (4.0804e-01)
Epoch: [35][ 75/390]	Total Loss 1.0785e+00 (1.0677e+00)	Consistency Loss 6.6897e-01 (6.6157e-01)	Stranger Loss 4.0956e-01 (4.0618e-01)
Epoch: [35][100/390]	Total Loss 1.1740e+00 (1.0677e+00)	Consistency Loss 7.0383e-01 (6.6377e-01)	Stranger Loss 4.7021e-01 (4.0390e-01)
Epoch: [35][125/390]	Total Loss 1.0317e+00 (1.0651e+00)	Consistency Loss 5.7221e-01 (6.6126e-01)	Stranger Loss 4.5949e-01 (4.0383e-01)
Epoch: [35][150/390]	Total Loss 1.0962e+00 (1.0652e+00)	Consistency Loss 6.4441e-01 (6.6160e-01)	Stranger Loss 4.5182e-01 (4.0355e-01)
Epoch: [35][175/390]	Total Loss 1.0733e+00 (1.0651e+00)	Consistency Loss 6.6119e-01 (6.6046e-01)	Stranger Loss 4.1208e-01 (4.0468e-01)
Epoch: [35][200/390]	Total Loss 9.8409e-01 (1.0624e+00)	Consistency Loss 6.0546e-01 (6.5861e-01)	Stranger Loss 3.7864e-01 (4.0374e-01)
Epoch: [35][225/390]	Total Loss 1.0817e+00 (1.0655e+00)	Consistency Loss 6.6068e-01 (6.6060e-01)	Stranger Loss 4.2104e-01 (4.0495e-01)
Epoch: [35][250/390]	Total Loss 1.0075e+00 (1.0659e+00)	Consistency Loss 5.9604e-01 (6.6109e-01)	Stranger Loss 4.1147e-01 (4.0476e-01)
Epoch: [35][275/390]	Total Loss 9.9182e-01 (1.0664e+00)	Consistency Loss 5.8915e-01 (6.6006e-01)	Stranger Loss 4.0267e-01 (4.0631e-01)
Epoch: [35][300/390]	Total Loss 1.0183e+00 (1.0691e+00)	Consistency Loss 6.3597e-01 (6.6178e-01)	Stranger Loss 3.8231e-01 (4.0731e-01)
Epoch: [35][325/390]	Total Loss 9.9935e-01 (1.0715e+00)	Consistency Loss 6.0442e-01 (6.6347e-01)	Stranger Loss 3.9494e-01 (4.0804e-01)
Epoch: [35][350/390]	Total Loss 1.0185e+00 (1.0695e+00)	Consistency Loss 6.9760e-01 (6.6254e-01)	Stranger Loss 3.2089e-01 (4.0693e-01)
Epoch: [35][375/390]	Total Loss 1.0436e+00 (1.0712e+00)	Consistency Loss 6.4258e-01 (6.6263e-01)	Stranger Loss 4.0099e-01 (4.0860e-01)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'consistency': 0.5164999961853027, 'stranger': 0.40654540061950684, 'total_loss': 0.9230453968048096}], 'lowest_loss_head': 0, 'lowest_loss': 0.9230453968048096}
No new lowest loss on validation set: 0.8369 -> 0.9230
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2192, 'ARI': 0.10077564636117789, 'NMI': 0.17125923665436454, 'ACC Top-5': 0.4902, 'hungarian_match': [(0, 4), (1, 0), (2, 1), (3, 5), (4, 3), (5, 9), (6, 2), (7, 6), (8, 7), (9, 8)]}
Checkpoint ...
[33mEpoch 37/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [36][  0/390]	Total Loss 1.0645e+00 (1.0645e+00)	Consistency Loss 7.1241e-01 (7.1241e-01)	Stranger Loss 3.5214e-01 (3.5214e-01)
Epoch: [36][ 25/390]	Total Loss 1.0301e+00 (1.0728e+00)	Consistency Loss 6.2165e-01 (6.7853e-01)	Stranger Loss 4.0846e-01 (3.9424e-01)
Epoch: [36][ 50/390]	Total Loss 1.1031e+00 (1.0634e+00)	Consistency Loss 6.8637e-01 (6.6738e-01)	Stranger Loss 4.1672e-01 (3.9607e-01)
Epoch: [36][ 75/390]	Total Loss 9.5546e-01 (1.0698e+00)	Consistency Loss 6.1982e-01 (6.6917e-01)	Stranger Loss 3.3563e-01 (4.0062e-01)
Epoch: [36][100/390]	Total Loss 1.1722e+00 (1.0726e+00)	Consistency Loss 7.5968e-01 (6.6893e-01)	Stranger Loss 4.1255e-01 (4.0371e-01)
Epoch: [36][125/390]	Total Loss 1.0164e+00 (1.0690e+00)	Consistency Loss 7.0876e-01 (6.6687e-01)	Stranger Loss 3.0763e-01 (4.0213e-01)
Epoch: [36][150/390]	Total Loss 1.0661e+00 (1.0697e+00)	Consistency Loss 6.5690e-01 (6.6627e-01)	Stranger Loss 4.0922e-01 (4.0344e-01)
Epoch: [36][175/390]	Total Loss 1.1643e+00 (1.0726e+00)	Consistency Loss 6.9421e-01 (6.6875e-01)	Stranger Loss 4.7010e-01 (4.0383e-01)
Epoch: [36][200/390]	Total Loss 1.1075e+00 (1.0735e+00)	Consistency Loss 6.7707e-01 (6.6958e-01)	Stranger Loss 4.3048e-01 (4.0393e-01)
Epoch: [36][225/390]	Total Loss 1.2137e+00 (1.0763e+00)	Consistency Loss 7.8091e-01 (6.7120e-01)	Stranger Loss 4.3277e-01 (4.0515e-01)
Epoch: [36][250/390]	Total Loss 1.0412e+00 (1.0741e+00)	Consistency Loss 6.1167e-01 (6.6818e-01)	Stranger Loss 4.2955e-01 (4.0597e-01)
Epoch: [36][275/390]	Total Loss 1.1991e+00 (1.0739e+00)	Consistency Loss 6.9492e-01 (6.6711e-01)	Stranger Loss 5.0422e-01 (4.0675e-01)
Epoch: [36][300/390]	Total Loss 1.0806e+00 (1.0744e+00)	Consistency Loss 6.6322e-01 (6.6725e-01)	Stranger Loss 4.1734e-01 (4.0718e-01)
Epoch: [36][325/390]	Total Loss 1.1729e+00 (1.0739e+00)	Consistency Loss 7.4061e-01 (6.6768e-01)	Stranger Loss 4.3233e-01 (4.0619e-01)
Epoch: [36][350/390]	Total Loss 1.0960e+00 (1.0733e+00)	Consistency Loss 7.2181e-01 (6.6752e-01)	Stranger Loss 3.7418e-01 (4.0581e-01)
Epoch: [36][375/390]	Total Loss 1.0702e+00 (1.0736e+00)	Consistency Loss 6.5648e-01 (6.6790e-01)	Stranger Loss 4.1376e-01 (4.0572e-01)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'consistency': 0.5424084067344666, 'stranger': 0.3963613212108612, 'total_loss': 0.9387697279453278}], 'lowest_loss_head': 0, 'lowest_loss': 0.9387697279453278}
No new lowest loss on validation set: 0.8369 -> 0.9388
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2277, 'ARI': 0.10244450944064677, 'NMI': 0.18452494618443394, 'ACC Top-5': 0.5132, 'hungarian_match': [(0, 4), (1, 0), (2, 3), (3, 7), (4, 2), (5, 9), (6, 1), (7, 5), (8, 6), (9, 8)]}
Checkpoint ...
[33mEpoch 38/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [37][  0/390]	Total Loss 1.1364e+00 (1.1364e+00)	Consistency Loss 7.1276e-01 (7.1276e-01)	Stranger Loss 4.2369e-01 (4.2369e-01)
Epoch: [37][ 25/390]	Total Loss 1.0080e+00 (1.0526e+00)	Consistency Loss 6.3029e-01 (6.4506e-01)	Stranger Loss 3.7767e-01 (4.0755e-01)
Epoch: [37][ 50/390]	Total Loss 1.0340e+00 (1.0682e+00)	Consistency Loss 6.6035e-01 (6.5652e-01)	Stranger Loss 3.7365e-01 (4.1169e-01)
Epoch: [37][ 75/390]	Total Loss 1.1188e+00 (1.0743e+00)	Consistency Loss 6.8806e-01 (6.6363e-01)	Stranger Loss 4.3072e-01 (4.1069e-01)
Epoch: [37][100/390]	Total Loss 1.0919e+00 (1.0737e+00)	Consistency Loss 6.3483e-01 (6.6158e-01)	Stranger Loss 4.5707e-01 (4.1208e-01)
Epoch: [37][125/390]	Total Loss 9.4221e-01 (1.0722e+00)	Consistency Loss 5.7401e-01 (6.6043e-01)	Stranger Loss 3.6821e-01 (4.1181e-01)
Epoch: [37][150/390]	Total Loss 1.1205e+00 (1.0756e+00)	Consistency Loss 6.6517e-01 (6.6461e-01)	Stranger Loss 4.5531e-01 (4.1098e-01)
Epoch: [37][175/390]	Total Loss 1.1004e+00 (1.0771e+00)	Consistency Loss 6.9671e-01 (6.6732e-01)	Stranger Loss 4.0373e-01 (4.0978e-01)
Epoch: [37][200/390]	Total Loss 1.2002e+00 (1.0794e+00)	Consistency Loss 7.2709e-01 (6.6969e-01)	Stranger Loss 4.7312e-01 (4.0971e-01)
Epoch: [37][225/390]	Total Loss 1.1328e+00 (1.0773e+00)	Consistency Loss 7.1031e-01 (6.6799e-01)	Stranger Loss 4.2253e-01 (4.0928e-01)
Epoch: [37][250/390]	Total Loss 1.1525e+00 (1.0791e+00)	Consistency Loss 7.0449e-01 (6.6846e-01)	Stranger Loss 4.4798e-01 (4.1065e-01)
Epoch: [37][275/390]	Total Loss 1.1266e+00 (1.0788e+00)	Consistency Loss 6.5307e-01 (6.6808e-01)	Stranger Loss 4.7355e-01 (4.1076e-01)
Epoch: [37][300/390]	Total Loss 1.1135e+00 (1.0782e+00)	Consistency Loss 6.3935e-01 (6.6817e-01)	Stranger Loss 4.7412e-01 (4.1001e-01)
Epoch: [37][325/390]	Total Loss 1.0738e+00 (1.0777e+00)	Consistency Loss 6.4497e-01 (6.6845e-01)	Stranger Loss 4.2884e-01 (4.0929e-01)
Epoch: [37][350/390]	Total Loss 1.0469e+00 (1.0779e+00)	Consistency Loss 6.1137e-01 (6.6863e-01)	Stranger Loss 4.3550e-01 (4.0925e-01)
Epoch: [37][375/390]	Total Loss 9.7144e-01 (1.0770e+00)	Consistency Loss 6.3477e-01 (6.6772e-01)	Stranger Loss 3.3667e-01 (4.0931e-01)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'consistency': 0.5028589367866516, 'stranger': 0.41588979959487915, 'total_loss': 0.9187487363815308}], 'lowest_loss_head': 0, 'lowest_loss': 0.9187487363815308}
No new lowest loss on validation set: 0.8369 -> 0.9187
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2119, 'ARI': 0.09813993047602981, 'NMI': 0.1724235849173389, 'ACC Top-5': 0.5049, 'hungarian_match': [(0, 4), (1, 0), (2, 5), (3, 2), (4, 3), (5, 9), (6, 1), (7, 6), (8, 7), (9, 8)]}
Checkpoint ...
[33mEpoch 39/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [38][  0/390]	Total Loss 1.0587e+00 (1.0587e+00)	Consistency Loss 6.3980e-01 (6.3980e-01)	Stranger Loss 4.1890e-01 (4.1890e-01)
Epoch: [38][ 25/390]	Total Loss 1.0461e+00 (1.0715e+00)	Consistency Loss 6.1967e-01 (6.5933e-01)	Stranger Loss 4.2643e-01 (4.1216e-01)
Epoch: [38][ 50/390]	Total Loss 1.2111e+00 (1.0782e+00)	Consistency Loss 6.8972e-01 (6.6214e-01)	Stranger Loss 5.2137e-01 (4.1602e-01)
Epoch: [38][ 75/390]	Total Loss 1.1935e+00 (1.0773e+00)	Consistency Loss 7.4245e-01 (6.6132e-01)	Stranger Loss 4.5102e-01 (4.1598e-01)
Epoch: [38][100/390]	Total Loss 1.0643e+00 (1.0803e+00)	Consistency Loss 6.5228e-01 (6.6453e-01)	Stranger Loss 4.1201e-01 (4.1572e-01)
Epoch: [38][125/390]	Total Loss 1.1212e+00 (1.0754e+00)	Consistency Loss 7.2110e-01 (6.6260e-01)	Stranger Loss 4.0014e-01 (4.1280e-01)
Epoch: [38][150/390]	Total Loss 1.1053e+00 (1.0745e+00)	Consistency Loss 6.8213e-01 (6.6371e-01)	Stranger Loss 4.2319e-01 (4.1083e-01)
Epoch: [38][175/390]	Total Loss 1.0021e+00 (1.0751e+00)	Consistency Loss 6.3477e-01 (6.6418e-01)	Stranger Loss 3.6730e-01 (4.1089e-01)
Epoch: [38][200/390]	Total Loss 1.0637e+00 (1.0744e+00)	Consistency Loss 6.5884e-01 (6.6471e-01)	Stranger Loss 4.0486e-01 (4.0970e-01)
Epoch: [38][225/390]	Total Loss 1.0353e+00 (1.0736e+00)	Consistency Loss 6.1203e-01 (6.6381e-01)	Stranger Loss 4.2325e-01 (4.0980e-01)
Epoch: [38][250/390]	Total Loss 1.1401e+00 (1.0737e+00)	Consistency Loss 7.0130e-01 (6.6316e-01)	Stranger Loss 4.3879e-01 (4.1051e-01)
Epoch: [38][275/390]	Total Loss 1.0615e+00 (1.0750e+00)	Consistency Loss 6.6757e-01 (6.6499e-01)	Stranger Loss 3.9393e-01 (4.0997e-01)
Epoch: [38][300/390]	Total Loss 1.0542e+00 (1.0760e+00)	Consistency Loss 6.6240e-01 (6.6603e-01)	Stranger Loss 3.9177e-01 (4.0995e-01)
Epoch: [38][325/390]	Total Loss 9.6518e-01 (1.0729e+00)	Consistency Loss 6.2605e-01 (6.6409e-01)	Stranger Loss 3.3913e-01 (4.0881e-01)
Epoch: [38][350/390]	Total Loss 1.1929e+00 (1.0744e+00)	Consistency Loss 7.4086e-01 (6.6464e-01)	Stranger Loss 4.5208e-01 (4.0972e-01)
Epoch: [38][375/390]	Total Loss 1.0820e+00 (1.0761e+00)	Consistency Loss 6.8826e-01 (6.6554e-01)	Stranger Loss 3.9374e-01 (4.1061e-01)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'consistency': 0.5043219327926636, 'stranger': 0.4197371006011963, 'total_loss': 0.9240590333938599}], 'lowest_loss_head': 0, 'lowest_loss': 0.9240590333938599}
No new lowest loss on validation set: 0.8369 -> 0.9241
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2107, 'ARI': 0.09807729466650383, 'NMI': 0.16686363886158803, 'ACC Top-5': 0.5313, 'hungarian_match': [(0, 4), (1, 0), (2, 1), (3, 5), (4, 3), (5, 9), (6, 2), (7, 6), (8, 7), (9, 8)]}
Checkpoint ...
[33mEpoch 40/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
Epoch: [39][  0/390]	Total Loss 1.0625e+00 (1.0625e+00)	Consistency Loss 6.2838e-01 (6.2838e-01)	Stranger Loss 4.3417e-01 (4.3417e-01)
Epoch: [39][ 25/390]	Total Loss 1.0333e+00 (1.0616e+00)	Consistency Loss 6.2741e-01 (6.5534e-01)	Stranger Loss 4.0594e-01 (4.0631e-01)
Epoch: [39][ 50/390]	Total Loss 1.0051e+00 (1.0585e+00)	Consistency Loss 6.0720e-01 (6.5083e-01)	Stranger Loss 3.9793e-01 (4.0771e-01)
Epoch: [39][ 75/390]	Total Loss 1.1029e+00 (1.0647e+00)	Consistency Loss 7.0284e-01 (6.5409e-01)	Stranger Loss 4.0002e-01 (4.1063e-01)
Epoch: [39][100/390]	Total Loss 1.1411e+00 (1.0670e+00)	Consistency Loss 7.3127e-01 (6.5596e-01)	Stranger Loss 4.0983e-01 (4.1109e-01)
Epoch: [39][125/390]	Total Loss 1.0307e+00 (1.0656e+00)	Consistency Loss 7.1388e-01 (6.5685e-01)	Stranger Loss 3.1686e-01 (4.0875e-01)
Epoch: [39][150/390]	Total Loss 1.1278e+00 (1.0670e+00)	Consistency Loss 6.8388e-01 (6.5812e-01)	Stranger Loss 4.4394e-01 (4.0892e-01)
Epoch: [39][175/390]	Total Loss 9.7934e-01 (1.0674e+00)	Consistency Loss 6.3544e-01 (6.5880e-01)	Stranger Loss 3.4390e-01 (4.0859e-01)
Epoch: [39][200/390]	Total Loss 1.0699e+00 (1.0665e+00)	Consistency Loss 6.6266e-01 (6.5857e-01)	Stranger Loss 4.0723e-01 (4.0789e-01)
Epoch: [39][225/390]	Total Loss 1.1171e+00 (1.0665e+00)	Consistency Loss 7.2566e-01 (6.5995e-01)	Stranger Loss 3.9147e-01 (4.0659e-01)
Epoch: [39][250/390]	Total Loss 1.0113e+00 (1.0641e+00)	Consistency Loss 6.4640e-01 (6.5865e-01)	Stranger Loss 3.6489e-01 (4.0549e-01)
Epoch: [39][275/390]	Total Loss 1.0452e+00 (1.0635e+00)	Consistency Loss 6.2854e-01 (6.5796e-01)	Stranger Loss 4.1666e-01 (4.0554e-01)
Epoch: [39][300/390]	Total Loss 1.0736e+00 (1.0646e+00)	Consistency Loss 6.4849e-01 (6.5886e-01)	Stranger Loss 4.2514e-01 (4.0578e-01)
Epoch: [39][325/390]	Total Loss 1.0077e+00 (1.0648e+00)	Consistency Loss 6.4407e-01 (6.5870e-01)	Stranger Loss 3.6362e-01 (4.0614e-01)
Epoch: [39][350/390]	Total Loss 1.0162e+00 (1.0673e+00)	Consistency Loss 6.1782e-01 (6.6002e-01)	Stranger Loss 3.9842e-01 (4.0732e-01)
Epoch: [39][375/390]	Total Loss 1.0548e+00 (1.0671e+00)	Consistency Loss 6.7678e-01 (6.6058e-01)	Stranger Loss 3.7807e-01 (4.0655e-01)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'consistency': 0.4989694356918335, 'stranger': 0.4292301535606384, 'total_loss': 0.9281995892524719}], 'lowest_loss_head': 0, 'lowest_loss': 0.9281995892524719}
No new lowest loss on validation set: 0.8369 -> 0.9282
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2176, 'ARI': 0.10363721472266436, 'NMI': 0.17420687133536725, 'ACC Top-5': 0.5084, 'hungarian_match': [(0, 4), (1, 0), (2, 5), (3, 2), (4, 3), (5, 9), (6, 1), (7, 6), (8, 7), (9, 8)]}
Checkpoint ...
[33mEpoch 41/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00100
Train ...
slurmstepd: error: *** JOB 749781 ON vulcan19 CANCELLED AT 2021-04-07T13:41:46 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 749781.0 ON vulcan19 CANCELLED AT 2021-04-07T13:41:46 ***
