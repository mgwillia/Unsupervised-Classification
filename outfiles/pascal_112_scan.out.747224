vulcan00.umiacs.umd.edu
[31m{'setup': 'scan', 'criterion': 'scan', 'criterion_kwargs': {'entropy_weight': 5.0}, 'update_cluster_head_only': False, 'num_heads': 1, 'backbone': 'resnet50', 'train_db_name': 'pascal-pretrained-112', 'val_db_name': 'pascal-pretrained-112', 'num_classes': 20, 'num_neighbors': 20, 'augmentation_strategy': 'ours', 'augmentation_kwargs': {'crop_size': 112, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, 'num_strong_augs': 4, 'cutout_kwargs': {'n_holes': 1, 'length': 16, 'random': True}}, 'transformation_kwargs': {'crop_size': 112, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'optimizer': 'adam', 'optimizer_kwargs': {'lr': 0.0001, 'weight_decay': 0.0001}, 'epochs': 50, 'batch_size': 128, 'num_workers': 8, 'scheduler': 'constant', 'pretext_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext', 'pretext_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/checkpoint.pth.tar', 'pretext_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/model.pth.tar', 'topk_neighbors_train_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/topk-val-neighbors.npy', 'scan_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan', 'scan_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan/checkpoint.pth.tar', 'scan_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan/model.pth.tar', 'selflabel_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/selflabel', 'selflabel_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/selflabel/checkpoint.pth.tar', 'selflabel_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/selflabel/model.pth.tar'}[0m
[34mGet dataset and dataloaders[0m
Train transforms: Compose(
    RandomHorizontalFlip(p=0.5)
    RandomCrop(size=(112, 112), padding=None)
    <data.augment.Augment object at 0x7f2b51218a90>
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    <data.augment.Cutout object at 0x7f2b51218be0>
)
Validation transforms: Compose(
    CenterCrop(size=(112, 112))
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
Train samples 15774 - Val samples 15774
[34mGet model[0m
{'setup': 'scan', 'criterion': 'scan', 'criterion_kwargs': {'entropy_weight': 5.0}, 'update_cluster_head_only': False, 'num_heads': 1, 'backbone': 'resnet50', 'train_db_name': 'pascal-pretrained-112', 'val_db_name': 'pascal-pretrained-112', 'num_classes': 20, 'num_neighbors': 20, 'augmentation_strategy': 'ours', 'augmentation_kwargs': {'crop_size': 112, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, 'num_strong_augs': 4, 'cutout_kwargs': {'n_holes': 1, 'length': 16, 'random': True}}, 'transformation_kwargs': {'crop_size': 112, 'normalize': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}}, 'optimizer': 'adam', 'optimizer_kwargs': {'lr': 0.0001, 'weight_decay': 0.0001}, 'epochs': 50, 'batch_size': 128, 'num_workers': 8, 'scheduler': 'constant', 'pretext_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext', 'pretext_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/checkpoint.pth.tar', 'pretext_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/model.pth.tar', 'topk_neighbors_train_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/pretext/topk-val-neighbors.npy', 'scan_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan', 'scan_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan/checkpoint.pth.tar', 'scan_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan/model.pth.tar', 'selflabel_dir': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/selflabel', 'selflabel_checkpoint': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/selflabel/checkpoint.pth.tar', 'selflabel_model': '/cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/selflabel/model.pth.tar'}
loading pretrained
ClusteringModel(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=2048, out_features=1000, bias=True)
  )
  (cluster_head): ModuleList(
    (0): Linear(in_features=2048, out_features=20, bias=True)
  )
)
[34mGet optimizer[0m
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0001
)
[34mGet loss[0m
SCANLoss(
  (softmax): Softmax(dim=1)
  (bce): BCELoss()
)
[34mNo checkpoint file at /cfarhomes/mgwillia/scan-adaptation/Unsupervised-Classification/tutorial/pascal-pretrained-112/scan/checkpoint.pth.tar[0m
[34mStarting main loop[0m
[33mEpoch 1/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [0][  0/123]	Total Loss -1.1975e+01 (-1.1975e+01)	Consistency Loss 2.9893e+00 (2.9893e+00)	Entropy 2.9928e+00 (2.9928e+00)
Epoch: [0][ 25/123]	Total Loss -1.1984e+01 (-1.1982e+01)	Consistency Loss 2.9940e+00 (2.9939e+00)	Entropy 2.9956e+00 (2.9953e+00)
Epoch: [0][ 50/123]	Total Loss -1.1988e+01 (-1.1984e+01)	Consistency Loss 2.9908e+00 (2.9935e+00)	Entropy 2.9957e+00 (2.9955e+00)
Epoch: [0][ 75/123]	Total Loss -1.2018e+01 (-1.1989e+01)	Consistency Loss 2.9589e+00 (2.9882e+00)	Entropy 2.9953e+00 (2.9955e+00)
Epoch: [0][100/123]	Total Loss -1.2125e+01 (-1.2014e+01)	Consistency Loss 2.8445e+00 (2.9621e+00)	Entropy 2.9939e+00 (2.9951e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9589288234710693, 'consistency': 2.2040600776672363, 'total_loss': -0.754868745803833}], 'lowest_loss_head': 0, 'lowest_loss': -0.754868745803833}
New lowest loss on validation set: 10000.0000 -> -0.7549
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.1905667554203119, 'ARI': 0.06061692342737121, 'NMI': 0.15283687722277553, 'ACC Top-5': 0.49923925446938, 'hungarian_match': [(0, 15), (1, 18), (2, 19), (3, 3), (4, 14), (5, 0), (6, 7), (7, 1), (8, 12), (9, 9), (10, 8), (11, 4), (12, 10), (13, 2), (14, 13), (15, 16), (16, 5), (17, 6), (18, 11), (19, 17)]}
Checkpoint ...
[33mEpoch 2/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [1][  0/123]	Total Loss -1.2333e+01 (-1.2333e+01)	Consistency Loss 2.6357e+00 (2.6357e+00)	Entropy 2.9937e+00 (2.9937e+00)
Epoch: [1][ 25/123]	Total Loss -1.2431e+01 (-1.2311e+01)	Consistency Loss 2.5370e+00 (2.6573e+00)	Entropy 2.9936e+00 (2.9937e+00)
Epoch: [1][ 50/123]	Total Loss -1.2402e+01 (-1.2343e+01)	Consistency Loss 2.5693e+00 (2.6255e+00)	Entropy 2.9943e+00 (2.9938e+00)
Epoch: [1][ 75/123]	Total Loss -1.2479e+01 (-1.2377e+01)	Consistency Loss 2.4800e+00 (2.5898e+00)	Entropy 2.9918e+00 (2.9934e+00)
Epoch: [1][100/123]	Total Loss -1.2515e+01 (-1.2398e+01)	Consistency Loss 2.4510e+00 (2.5684e+00)	Entropy 2.9933e+00 (2.9933e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9805471897125244, 'consistency': 1.8176918029785156, 'total_loss': -1.1628553867340088}], 'lowest_loss_head': 0, 'lowest_loss': -1.1628553867340088}
New lowest loss on validation set: -0.7549 -> -1.1629
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.20616203879802206, 'ARI': 0.09031193259353212, 'NMI': 0.1820918358276394, 'ACC Top-5': 0.4811715481171548, 'hungarian_match': [(0, 0), (1, 5), (2, 19), (3, 3), (4, 14), (5, 18), (6, 7), (7, 17), (8, 12), (9, 9), (10, 10), (11, 15), (12, 13), (13, 16), (14, 1), (15, 4), (16, 8), (17, 6), (18, 11), (19, 2)]}
Checkpoint ...
[33mEpoch 3/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [2][  0/123]	Total Loss -1.2439e+01 (-1.2439e+01)	Consistency Loss 2.5277e+00 (2.5277e+00)	Entropy 2.9934e+00 (2.9934e+00)
Epoch: [2][ 25/123]	Total Loss -1.2546e+01 (-1.2494e+01)	Consistency Loss 2.4208e+00 (2.4675e+00)	Entropy 2.9934e+00 (2.9924e+00)
Epoch: [2][ 50/123]	Total Loss -1.2605e+01 (-1.2505e+01)	Consistency Loss 2.3571e+00 (2.4559e+00)	Entropy 2.9924e+00 (2.9923e+00)
Epoch: [2][ 75/123]	Total Loss -1.2567e+01 (-1.2507e+01)	Consistency Loss 2.3966e+00 (2.4538e+00)	Entropy 2.9927e+00 (2.9921e+00)
Epoch: [2][100/123]	Total Loss -1.2518e+01 (-1.2515e+01)	Consistency Loss 2.4533e+00 (2.4457e+00)	Entropy 2.9942e+00 (2.9922e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9863338470458984, 'consistency': 1.7359833717346191, 'total_loss': -1.2503504753112793}], 'lowest_loss_head': 0, 'lowest_loss': -1.2503504753112793}
New lowest loss on validation set: -1.1629 -> -1.2504
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21307214403448713, 'ARI': 0.08763865759737585, 'NMI': 0.1883052898878611, 'ACC Top-5': 0.48034740712564983, 'hungarian_match': [(0, 3), (1, 5), (2, 15), (3, 6), (4, 14), (5, 18), (6, 17), (7, 10), (8, 12), (9, 11), (10, 19), (11, 9), (12, 13), (13, 0), (14, 1), (15, 4), (16, 8), (17, 16), (18, 7), (19, 2)]}
Checkpoint ...
[33mEpoch 4/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [3][  0/123]	Total Loss -1.2529e+01 (-1.2529e+01)	Consistency Loss 2.4388e+00 (2.4388e+00)	Entropy 2.9935e+00 (2.9935e+00)
Epoch: [3][ 25/123]	Total Loss -1.2670e+01 (-1.2554e+01)	Consistency Loss 2.2866e+00 (2.4065e+00)	Entropy 2.9914e+00 (2.9921e+00)
Epoch: [3][ 50/123]	Total Loss -1.2663e+01 (-1.2562e+01)	Consistency Loss 2.2956e+00 (2.3985e+00)	Entropy 2.9918e+00 (2.9920e+00)
Epoch: [3][ 75/123]	Total Loss -1.2543e+01 (-1.2555e+01)	Consistency Loss 2.3959e+00 (2.4030e+00)	Entropy 2.9877e+00 (2.9916e+00)
Epoch: [3][100/123]	Total Loss -1.2572e+01 (-1.2552e+01)	Consistency Loss 2.3946e+00 (2.4056e+00)	Entropy 2.9933e+00 (2.9916e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9854941368103027, 'consistency': 1.6723432540893555, 'total_loss': -1.3131508827209473}], 'lowest_loss_head': 0, 'lowest_loss': -1.3131508827209473}
New lowest loss on validation set: -1.2504 -> -1.3132
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21408647140864714, 'ARI': 0.09228831999783443, 'NMI': 0.19817427401420326, 'ACC Top-5': 0.45651071383288955, 'hungarian_match': [(0, 3), (1, 8), (2, 15), (3, 6), (4, 14), (5, 0), (6, 17), (7, 5), (8, 12), (9, 11), (10, 18), (11, 9), (12, 13), (13, 19), (14, 1), (15, 4), (16, 10), (17, 16), (18, 7), (19, 2)]}
Checkpoint ...
[33mEpoch 5/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [4][  0/123]	Total Loss -1.2419e+01 (-1.2419e+01)	Consistency Loss 2.5348e+00 (2.5348e+00)	Entropy 2.9908e+00 (2.9908e+00)
Epoch: [4][ 25/123]	Total Loss -1.2673e+01 (-1.2546e+01)	Consistency Loss 2.2768e+00 (2.4095e+00)	Entropy 2.9899e+00 (2.9910e+00)
Epoch: [4][ 50/123]	Total Loss -1.2638e+01 (-1.2567e+01)	Consistency Loss 2.3220e+00 (2.3888e+00)	Entropy 2.9920e+00 (2.9912e+00)
Epoch: [4][ 75/123]	Total Loss -1.2639e+01 (-1.2576e+01)	Consistency Loss 2.3121e+00 (2.3786e+00)	Entropy 2.9902e+00 (2.9909e+00)
Epoch: [4][100/123]	Total Loss -1.2465e+01 (-1.2573e+01)	Consistency Loss 2.4793e+00 (2.3816e+00)	Entropy 2.9889e+00 (2.9909e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.986006498336792, 'consistency': 1.6449284553527832, 'total_loss': -1.3410780429840088}], 'lowest_loss_head': 0, 'lowest_loss': -1.3410780429840088}
New lowest loss on validation set: -1.3132 -> -1.3411
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2101559528337771, 'ARI': 0.08929843102902166, 'NMI': 0.19771333276116013, 'ACC Top-5': 0.50038037276531, 'hungarian_match': [(0, 0), (1, 5), (2, 15), (3, 6), (4, 14), (5, 18), (6, 11), (7, 17), (8, 12), (9, 2), (10, 10), (11, 9), (12, 13), (13, 19), (14, 1), (15, 4), (16, 8), (17, 3), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 6/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [5][  0/123]	Total Loss -1.2700e+01 (-1.2700e+01)	Consistency Loss 2.2650e+00 (2.2650e+00)	Entropy 2.9929e+00 (2.9929e+00)
Epoch: [5][ 25/123]	Total Loss -1.2613e+01 (-1.2589e+01)	Consistency Loss 2.3457e+00 (2.3679e+00)	Entropy 2.9918e+00 (2.9914e+00)
Epoch: [5][ 50/123]	Total Loss -1.2650e+01 (-1.2604e+01)	Consistency Loss 2.3100e+00 (2.3511e+00)	Entropy 2.9920e+00 (2.9911e+00)
Epoch: [5][ 75/123]	Total Loss -1.2640e+01 (-1.2609e+01)	Consistency Loss 2.3205e+00 (2.3461e+00)	Entropy 2.9922e+00 (2.9911e+00)
Epoch: [5][100/123]	Total Loss -1.2551e+01 (-1.2608e+01)	Consistency Loss 2.3867e+00 (2.3472e+00)	Entropy 2.9875e+00 (2.9911e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9858360290527344, 'consistency': 1.6132333278656006, 'total_loss': -1.3726027011871338}], 'lowest_loss_head': 0, 'lowest_loss': -1.3726027011871338}
New lowest loss on validation set: -1.3411 -> -1.3726
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21497400786103715, 'ARI': 0.09287515088794487, 'NMI': 0.20455914799980562, 'ACC Top-5': 0.5072270825408901, 'hungarian_match': [(0, 0), (1, 5), (2, 15), (3, 6), (4, 14), (5, 18), (6, 11), (7, 17), (8, 12), (9, 19), (10, 10), (11, 9), (12, 13), (13, 2), (14, 1), (15, 4), (16, 8), (17, 3), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 7/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [6][  0/123]	Total Loss -1.2668e+01 (-1.2668e+01)	Consistency Loss 2.2763e+00 (2.2763e+00)	Entropy 2.9888e+00 (2.9888e+00)
Epoch: [6][ 25/123]	Total Loss -1.2612e+01 (-1.2618e+01)	Consistency Loss 2.3471e+00 (2.3384e+00)	Entropy 2.9919e+00 (2.9912e+00)
Epoch: [6][ 50/123]	Total Loss -1.2544e+01 (-1.2616e+01)	Consistency Loss 2.4123e+00 (2.3378e+00)	Entropy 2.9913e+00 (2.9908e+00)
Epoch: [6][ 75/123]	Total Loss -1.2613e+01 (-1.2619e+01)	Consistency Loss 2.3453e+00 (2.3351e+00)	Entropy 2.9918e+00 (2.9908e+00)
Epoch: [6][100/123]	Total Loss -1.2604e+01 (-1.2620e+01)	Consistency Loss 2.3544e+00 (2.3337e+00)	Entropy 2.9918e+00 (2.9908e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.984231948852539, 'consistency': 1.5711419582366943, 'total_loss': -1.4130899906158447}], 'lowest_loss_head': 0, 'lowest_loss': -1.4130899906158447}
New lowest loss on validation set: -1.3726 -> -1.4131
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21161404843413212, 'ARI': 0.08563790544523897, 'NMI': 0.20290910958533795, 'ACC Top-5': 0.5087485736021301, 'hungarian_match': [(0, 0), (1, 5), (2, 15), (3, 6), (4, 14), (5, 18), (6, 11), (7, 17), (8, 12), (9, 2), (10, 10), (11, 9), (12, 13), (13, 19), (14, 1), (15, 4), (16, 8), (17, 3), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 8/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [7][  0/123]	Total Loss -1.2591e+01 (-1.2591e+01)	Consistency Loss 2.3748e+00 (2.3748e+00)	Entropy 2.9931e+00 (2.9931e+00)
Epoch: [7][ 25/123]	Total Loss -1.2741e+01 (-1.2659e+01)	Consistency Loss 2.2188e+00 (2.2972e+00)	Entropy 2.9919e+00 (2.9912e+00)
Epoch: [7][ 50/123]	Total Loss -1.2579e+01 (-1.2634e+01)	Consistency Loss 2.3522e+00 (2.3213e+00)	Entropy 2.9863e+00 (2.9911e+00)
Epoch: [7][ 75/123]	Total Loss -1.2642e+01 (-1.2642e+01)	Consistency Loss 2.3120e+00 (2.3126e+00)	Entropy 2.9907e+00 (2.9909e+00)
Epoch: [7][100/123]	Total Loss -1.2614e+01 (-1.2639e+01)	Consistency Loss 2.3265e+00 (2.3157e+00)	Entropy 2.9882e+00 (2.9909e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.987891435623169, 'consistency': 1.5794974565505981, 'total_loss': -1.4083939790725708}], 'lowest_loss_head': 0, 'lowest_loss': -1.4083939790725708}
No new lowest loss on validation set: -1.4131 -> -1.4084
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.201597565614302, 'ARI': 0.07940470073126901, 'NMI': 0.2060879459706777, 'ACC Top-5': 0.5126790921770001, 'hungarian_match': [(0, 0), (1, 5), (2, 15), (3, 6), (4, 14), (5, 18), (6, 11), (7, 17), (8, 12), (9, 2), (10, 10), (11, 4), (12, 13), (13, 19), (14, 1), (15, 9), (16, 8), (17, 3), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 9/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [8][  0/123]	Total Loss -1.2671e+01 (-1.2671e+01)	Consistency Loss 2.2937e+00 (2.2937e+00)	Entropy 2.9929e+00 (2.9929e+00)
Epoch: [8][ 25/123]	Total Loss -1.2705e+01 (-1.2630e+01)	Consistency Loss 2.2481e+00 (2.3239e+00)	Entropy 2.9906e+00 (2.9908e+00)
Epoch: [8][ 50/123]	Total Loss -1.2580e+01 (-1.2648e+01)	Consistency Loss 2.3702e+00 (2.3046e+00)	Entropy 2.9901e+00 (2.9906e+00)
Epoch: [8][ 75/123]	Total Loss -1.2519e+01 (-1.2643e+01)	Consistency Loss 2.4312e+00 (2.3083e+00)	Entropy 2.9900e+00 (2.9903e+00)
Epoch: [8][100/123]	Total Loss -1.2585e+01 (-1.2638e+01)	Consistency Loss 2.3747e+00 (2.3126e+00)	Entropy 2.9918e+00 (2.9902e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.987416982650757, 'consistency': 1.5570569038391113, 'total_loss': -1.4303600788116455}], 'lowest_loss_head': 0, 'lowest_loss': -1.4303600788116455}
New lowest loss on validation set: -1.4131 -> -1.4304
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.199378724483327, 'ARI': 0.07848754650647376, 'NMI': 0.20668205435941694, 'ACC Top-5': 0.48649676683149484, 'hungarian_match': [(0, 0), (1, 19), (2, 15), (3, 6), (4, 14), (5, 18), (6, 17), (7, 10), (8, 12), (9, 11), (10, 5), (11, 9), (12, 13), (13, 2), (14, 1), (15, 4), (16, 8), (17, 3), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 10/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [9][  0/123]	Total Loss -1.2670e+01 (-1.2670e+01)	Consistency Loss 2.2853e+00 (2.2853e+00)	Entropy 2.9911e+00 (2.9911e+00)
Epoch: [9][ 25/123]	Total Loss -1.2645e+01 (-1.2639e+01)	Consistency Loss 2.3024e+00 (2.3127e+00)	Entropy 2.9895e+00 (2.9904e+00)
Epoch: [9][ 50/123]	Total Loss -1.2574e+01 (-1.2645e+01)	Consistency Loss 2.3826e+00 (2.3081e+00)	Entropy 2.9913e+00 (2.9905e+00)
Epoch: [9][ 75/123]	Total Loss -1.2577e+01 (-1.2644e+01)	Consistency Loss 2.3540e+00 (2.3094e+00)	Entropy 2.9862e+00 (2.9906e+00)
Epoch: [9][100/123]	Total Loss -1.2731e+01 (-1.2647e+01)	Consistency Loss 2.2274e+00 (2.3059e+00)	Entropy 2.9917e+00 (2.9906e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.986593723297119, 'consistency': 1.5284757614135742, 'total_loss': -1.458117961883545}], 'lowest_loss_head': 0, 'lowest_loss': -1.458117961883545}
New lowest loss on validation set: -1.4304 -> -1.4581
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.199251933561557, 'ARI': 0.07921059830927688, 'NMI': 0.21050992021406298, 'ACC Top-5': 0.5135666286293902, 'hungarian_match': [(0, 0), (1, 19), (2, 9), (3, 6), (4, 14), (5, 18), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 15), (12, 13), (13, 4), (14, 1), (15, 5), (16, 8), (17, 3), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 11/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [10][  0/123]	Total Loss -1.2641e+01 (-1.2641e+01)	Consistency Loss 2.3035e+00 (2.3035e+00)	Entropy 2.9890e+00 (2.9890e+00)
Epoch: [10][ 25/123]	Total Loss -1.2786e+01 (-1.2654e+01)	Consistency Loss 2.1540e+00 (2.3004e+00)	Entropy 2.9880e+00 (2.9908e+00)
Epoch: [10][ 50/123]	Total Loss -1.2672e+01 (-1.2666e+01)	Consistency Loss 2.2853e+00 (2.2878e+00)	Entropy 2.9914e+00 (2.9907e+00)
Epoch: [10][ 75/123]	Total Loss -1.2652e+01 (-1.2658e+01)	Consistency Loss 2.3105e+00 (2.2942e+00)	Entropy 2.9926e+00 (2.9905e+00)
Epoch: [10][100/123]	Total Loss -1.2660e+01 (-1.2659e+01)	Consistency Loss 2.2909e+00 (2.2932e+00)	Entropy 2.9901e+00 (2.9905e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.986377477645874, 'consistency': 1.5169109106063843, 'total_loss': -1.4694665670394897}], 'lowest_loss_head': 0, 'lowest_loss': -1.4694665670394897}
New lowest loss on validation set: -1.4581 -> -1.4695
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.19601876505642196, 'ARI': 0.07563053776206743, 'NMI': 0.21098970363634229, 'ACC Top-5': 0.5102066692024851, 'hungarian_match': [(0, 3), (1, 5), (2, 9), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 15), (12, 13), (13, 19), (14, 1), (15, 4), (16, 8), (17, 18), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 12/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [11][  0/123]	Total Loss -1.2595e+01 (-1.2595e+01)	Consistency Loss 2.3503e+00 (2.3503e+00)	Entropy 2.9890e+00 (2.9890e+00)
Epoch: [11][ 25/123]	Total Loss -1.2635e+01 (-1.2665e+01)	Consistency Loss 2.3072e+00 (2.2857e+00)	Entropy 2.9884e+00 (2.9902e+00)
Epoch: [11][ 50/123]	Total Loss -1.2755e+01 (-1.2668e+01)	Consistency Loss 2.2014e+00 (2.2829e+00)	Entropy 2.9912e+00 (2.9901e+00)
Epoch: [11][ 75/123]	Total Loss -1.2539e+01 (-1.2661e+01)	Consistency Loss 2.4022e+00 (2.2892e+00)	Entropy 2.9882e+00 (2.9900e+00)
Epoch: [11][100/123]	Total Loss -1.2470e+01 (-1.2658e+01)	Consistency Loss 2.4910e+00 (2.2923e+00)	Entropy 2.9921e+00 (2.9901e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9871444702148438, 'consistency': 1.5340819358825684, 'total_loss': -1.4530625343322754}], 'lowest_loss_head': 0, 'lowest_loss': -1.4530625343322754}
No new lowest loss on validation set: -1.4695 -> -1.4531
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.20781032078103207, 'ARI': 0.08263836701215795, 'NMI': 0.21193690870210483, 'ACC Top-5': 0.5149613287688601, 'hungarian_match': [(0, 3), (1, 5), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 9), (12, 13), (13, 19), (14, 1), (15, 4), (16, 8), (17, 18), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 13/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [12][  0/123]	Total Loss -1.2523e+01 (-1.2523e+01)	Consistency Loss 2.4433e+00 (2.4433e+00)	Entropy 2.9932e+00 (2.9932e+00)
Epoch: [12][ 25/123]	Total Loss -1.2662e+01 (-1.2658e+01)	Consistency Loss 2.2922e+00 (2.2949e+00)	Entropy 2.9908e+00 (2.9907e+00)
Epoch: [12][ 50/123]	Total Loss -1.2766e+01 (-1.2667e+01)	Consistency Loss 2.1837e+00 (2.2855e+00)	Entropy 2.9899e+00 (2.9905e+00)
Epoch: [12][ 75/123]	Total Loss -1.2678e+01 (-1.2666e+01)	Consistency Loss 2.2712e+00 (2.2885e+00)	Entropy 2.9899e+00 (2.9908e+00)
Epoch: [12][100/123]	Total Loss -1.2668e+01 (-1.2670e+01)	Consistency Loss 2.2820e+00 (2.2836e+00)	Entropy 2.9901e+00 (2.9907e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.985020160675049, 'consistency': 1.514784812927246, 'total_loss': -1.4702353477478027}], 'lowest_loss_head': 0, 'lowest_loss': -1.4702353477478027}
New lowest loss on validation set: -1.4695 -> -1.4702
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21256498034740712, 'ARI': 0.08293319340689634, 'NMI': 0.2130781349758178, 'ACC Top-5': 0.5209838975529352, 'hungarian_match': [(0, 0), (1, 5), (2, 15), (3, 6), (4, 14), (5, 18), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 9), (12, 13), (13, 19), (14, 1), (15, 4), (16, 8), (17, 3), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 14/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [13][  0/123]	Total Loss -1.2728e+01 (-1.2728e+01)	Consistency Loss 2.2347e+00 (2.2347e+00)	Entropy 2.9926e+00 (2.9926e+00)
Epoch: [13][ 25/123]	Total Loss -1.2675e+01 (-1.2658e+01)	Consistency Loss 2.2763e+00 (2.2922e+00)	Entropy 2.9902e+00 (2.9900e+00)
Epoch: [13][ 50/123]	Total Loss -1.2638e+01 (-1.2653e+01)	Consistency Loss 2.3190e+00 (2.2975e+00)	Entropy 2.9915e+00 (2.9901e+00)
Epoch: [13][ 75/123]	Total Loss -1.2760e+01 (-1.2659e+01)	Consistency Loss 2.2002e+00 (2.2917e+00)	Entropy 2.9919e+00 (2.9902e+00)
Epoch: [13][100/123]	Total Loss -1.2699e+01 (-1.2662e+01)	Consistency Loss 2.2441e+00 (2.2891e+00)	Entropy 2.9887e+00 (2.9903e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9890716075897217, 'consistency': 1.510324239730835, 'total_loss': -1.4787473678588867}], 'lowest_loss_head': 0, 'lowest_loss': -1.4787473678588867}
New lowest loss on validation set: -1.4702 -> -1.4787
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.19284899201217193, 'ARI': 0.07216971817813686, 'NMI': 0.21479071797925972, 'ACC Top-5': 0.5212374793964752, 'hungarian_match': [(0, 0), (1, 5), (2, 15), (3, 6), (4, 14), (5, 18), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 19), (12, 13), (13, 4), (14, 1), (15, 9), (16, 8), (17, 3), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 15/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [14][  0/123]	Total Loss -1.2664e+01 (-1.2664e+01)	Consistency Loss 2.2914e+00 (2.2914e+00)	Entropy 2.9911e+00 (2.9911e+00)
Epoch: [14][ 25/123]	Total Loss -1.2622e+01 (-1.2644e+01)	Consistency Loss 2.3185e+00 (2.3078e+00)	Entropy 2.9882e+00 (2.9904e+00)
Epoch: [14][ 50/123]	Total Loss -1.2713e+01 (-1.2669e+01)	Consistency Loss 2.2121e+00 (2.2836e+00)	Entropy 2.9849e+00 (2.9904e+00)
Epoch: [14][ 75/123]	Total Loss -1.2660e+01 (-1.2669e+01)	Consistency Loss 2.3035e+00 (2.2826e+00)	Entropy 2.9927e+00 (2.9904e+00)
Epoch: [14][100/123]	Total Loss -1.2535e+01 (-1.2668e+01)	Consistency Loss 2.4076e+00 (2.2833e+00)	Entropy 2.9885e+00 (2.9903e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9849889278411865, 'consistency': 1.5188133716583252, 'total_loss': -1.4661755561828613}], 'lowest_loss_head': 0, 'lowest_loss': -1.4661755561828613}
No new lowest loss on validation set: -1.4787 -> -1.4662
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.20394319766704705, 'ARI': 0.07767430536271423, 'NMI': 0.21308906457458754, 'ACC Top-5': 0.5109040192722201, 'hungarian_match': [(0, 3), (1, 5), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 9), (12, 13), (13, 19), (14, 1), (15, 18), (16, 8), (17, 4), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 16/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [15][  0/123]	Total Loss -1.2677e+01 (-1.2677e+01)	Consistency Loss 2.2571e+00 (2.2571e+00)	Entropy 2.9869e+00 (2.9869e+00)
Epoch: [15][ 25/123]	Total Loss -1.2719e+01 (-1.2692e+01)	Consistency Loss 2.2476e+00 (2.2582e+00)	Entropy 2.9934e+00 (2.9901e+00)
Epoch: [15][ 50/123]	Total Loss -1.2804e+01 (-1.2693e+01)	Consistency Loss 2.1454e+00 (2.2591e+00)	Entropy 2.9898e+00 (2.9903e+00)
Epoch: [15][ 75/123]	Total Loss -1.2676e+01 (-1.2686e+01)	Consistency Loss 2.2722e+00 (2.2656e+00)	Entropy 2.9897e+00 (2.9903e+00)
Epoch: [15][100/123]	Total Loss -1.2710e+01 (-1.2684e+01)	Consistency Loss 2.2529e+00 (2.2668e+00)	Entropy 2.9925e+00 (2.9902e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9876461029052734, 'consistency': 1.5104538202285767, 'total_loss': -1.4771922826766968}], 'lowest_loss_head': 0, 'lowest_loss': -1.4771922826766968}
No new lowest loss on validation set: -1.4787 -> -1.4772
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2107265119817421, 'ARI': 0.08280362316138977, 'NMI': 0.21621023845575274, 'ACC Top-5': 0.5176873335869152, 'hungarian_match': [(0, 3), (1, 5), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 9), (12, 13), (13, 19), (14, 1), (15, 4), (16, 8), (17, 18), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 17/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [16][  0/123]	Total Loss -1.2793e+01 (-1.2793e+01)	Consistency Loss 2.1713e+00 (2.1713e+00)	Entropy 2.9928e+00 (2.9928e+00)
Epoch: [16][ 25/123]	Total Loss -1.2632e+01 (-1.2706e+01)	Consistency Loss 2.3298e+00 (2.2496e+00)	Entropy 2.9924e+00 (2.9910e+00)
Epoch: [16][ 50/123]	Total Loss -1.2710e+01 (-1.2698e+01)	Consistency Loss 2.2439e+00 (2.2553e+00)	Entropy 2.9907e+00 (2.9907e+00)
Epoch: [16][ 75/123]	Total Loss -1.2838e+01 (-1.2697e+01)	Consistency Loss 2.1132e+00 (2.2563e+00)	Entropy 2.9902e+00 (2.9907e+00)
Epoch: [16][100/123]	Total Loss -1.2614e+01 (-1.2695e+01)	Consistency Loss 2.3523e+00 (2.2585e+00)	Entropy 2.9933e+00 (2.9907e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.983872413635254, 'consistency': 1.4879621267318726, 'total_loss': -1.4959102869033813}], 'lowest_loss_head': 0, 'lowest_loss': -1.4959102869033813}
New lowest loss on validation set: -1.4787 -> -1.4959
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2113604665905921, 'ARI': 0.08917640128651638, 'NMI': 0.22135770590618145, 'ACC Top-5': 0.5248510206669202, 'hungarian_match': [(0, 3), (1, 5), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 9), (12, 13), (13, 19), (14, 1), (15, 4), (16, 8), (17, 18), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 18/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [17][  0/123]	Total Loss -1.2599e+01 (-1.2599e+01)	Consistency Loss 2.3618e+00 (2.3618e+00)	Entropy 2.9921e+00 (2.9921e+00)
Epoch: [17][ 25/123]	Total Loss -1.2768e+01 (-1.2695e+01)	Consistency Loss 2.1846e+00 (2.2569e+00)	Entropy 2.9905e+00 (2.9904e+00)
Epoch: [17][ 50/123]	Total Loss -1.2606e+01 (-1.2697e+01)	Consistency Loss 2.3459e+00 (2.2537e+00)	Entropy 2.9903e+00 (2.9901e+00)
Epoch: [17][ 75/123]	Total Loss -1.2557e+01 (-1.2679e+01)	Consistency Loss 2.3906e+00 (2.2717e+00)	Entropy 2.9895e+00 (2.9901e+00)
Epoch: [17][100/123]	Total Loss -1.2676e+01 (-1.2682e+01)	Consistency Loss 2.2796e+00 (2.2694e+00)	Entropy 2.9912e+00 (2.9903e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9847309589385986, 'consistency': 1.492102026939392, 'total_loss': -1.4926289319992065}], 'lowest_loss_head': 0, 'lowest_loss': -1.4926289319992065}
No new lowest loss on validation set: -1.4959 -> -1.4926
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2213769494104222, 'ARI': 0.09053154037264055, 'NMI': 0.22328671280553875, 'ACC Top-5': 0.5266894890325853, 'hungarian_match': [(0, 3), (1, 5), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 18), (12, 13), (13, 4), (14, 1), (15, 9), (16, 8), (17, 19), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 19/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [18][  0/123]	Total Loss -1.2774e+01 (-1.2774e+01)	Consistency Loss 2.1693e+00 (2.1693e+00)	Entropy 2.9886e+00 (2.9886e+00)
Epoch: [18][ 25/123]	Total Loss -1.2688e+01 (-1.2707e+01)	Consistency Loss 2.2696e+00 (2.2457e+00)	Entropy 2.9915e+00 (2.9904e+00)
Epoch: [18][ 50/123]	Total Loss -1.2653e+01 (-1.2702e+01)	Consistency Loss 2.2812e+00 (2.2501e+00)	Entropy 2.9869e+00 (2.9903e+00)
Epoch: [18][ 75/123]	Total Loss -1.2585e+01 (-1.2696e+01)	Consistency Loss 2.3754e+00 (2.2557e+00)	Entropy 2.9920e+00 (2.9904e+00)
Epoch: [18][100/123]	Total Loss -1.2643e+01 (-1.2698e+01)	Consistency Loss 2.3060e+00 (2.2542e+00)	Entropy 2.9898e+00 (2.9903e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9853439331054688, 'consistency': 1.4887913465499878, 'total_loss': -1.496552586555481}], 'lowest_loss_head': 0, 'lowest_loss': -1.496552586555481}
New lowest loss on validation set: -1.4959 -> -1.4966
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21376949410422214, 'ARI': 0.08779667970060315, 'NMI': 0.22118845461404932, 'ACC Top-5': 0.5147077469253202, 'hungarian_match': [(0, 3), (1, 19), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 5), (12, 13), (13, 4), (14, 1), (15, 9), (16, 8), (17, 18), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 20/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [19][  0/123]	Total Loss -1.2664e+01 (-1.2664e+01)	Consistency Loss 2.2913e+00 (2.2913e+00)	Entropy 2.9911e+00 (2.9911e+00)
Epoch: [19][ 25/123]	Total Loss -1.2612e+01 (-1.2679e+01)	Consistency Loss 2.3320e+00 (2.2736e+00)	Entropy 2.9888e+00 (2.9905e+00)
Epoch: [19][ 50/123]	Total Loss -1.2719e+01 (-1.2687e+01)	Consistency Loss 2.2395e+00 (2.2643e+00)	Entropy 2.9916e+00 (2.9904e+00)
Epoch: [19][ 75/123]	Total Loss -1.2709e+01 (-1.2697e+01)	Consistency Loss 2.2495e+00 (2.2556e+00)	Entropy 2.9916e+00 (2.9905e+00)
Epoch: [19][100/123]	Total Loss -1.2698e+01 (-1.2694e+01)	Consistency Loss 2.2660e+00 (2.2586e+00)	Entropy 2.9928e+00 (2.9905e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.986107587814331, 'consistency': 1.4789550304412842, 'total_loss': -1.5071525573730469}], 'lowest_loss_head': 0, 'lowest_loss': -1.5071525573730469}
New lowest loss on validation set: -1.4966 -> -1.5072
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2105997210599721, 'ARI': 0.08620613288337993, 'NMI': 0.22228095156790093, 'ACC Top-5': 0.5179409154304552, 'hungarian_match': [(0, 3), (1, 5), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 18), (12, 13), (13, 9), (14, 1), (15, 4), (16, 8), (17, 19), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 21/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [20][  0/123]	Total Loss -1.2605e+01 (-1.2605e+01)	Consistency Loss 2.3553e+00 (2.3553e+00)	Entropy 2.9920e+00 (2.9920e+00)
Epoch: [20][ 25/123]	Total Loss -1.2756e+01 (-1.2692e+01)	Consistency Loss 2.2001e+00 (2.2617e+00)	Entropy 2.9913e+00 (2.9907e+00)
Epoch: [20][ 50/123]	Total Loss -1.2729e+01 (-1.2702e+01)	Consistency Loss 2.2267e+00 (2.2486e+00)	Entropy 2.9911e+00 (2.9901e+00)
Epoch: [20][ 75/123]	Total Loss -1.2587e+01 (-1.2697e+01)	Consistency Loss 2.3567e+00 (2.2546e+00)	Entropy 2.9887e+00 (2.9904e+00)
Epoch: [20][100/123]	Total Loss -1.2707e+01 (-1.2698e+01)	Consistency Loss 2.2497e+00 (2.2549e+00)	Entropy 2.9913e+00 (2.9905e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.989506244659424, 'consistency': 1.4923795461654663, 'total_loss': -1.4971266984939575}], 'lowest_loss_head': 0, 'lowest_loss': -1.4971266984939575}
No new lowest loss on validation set: -1.5072 -> -1.4971
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21319893495625714, 'ARI': 0.08731020707913048, 'NMI': 0.22851450226482545, 'ACC Top-5': 0.50431089134018, 'hungarian_match': [(0, 3), (1, 19), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 5), (12, 13), (13, 9), (14, 1), (15, 18), (16, 8), (17, 4), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 22/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [21][  0/123]	Total Loss -1.2623e+01 (-1.2623e+01)	Consistency Loss 2.3178e+00 (2.3178e+00)	Entropy 2.9882e+00 (2.9882e+00)
Epoch: [21][ 25/123]	Total Loss -1.2875e+01 (-1.2702e+01)	Consistency Loss 2.0915e+00 (2.2509e+00)	Entropy 2.9932e+00 (2.9906e+00)
Epoch: [21][ 50/123]	Total Loss -1.2740e+01 (-1.2717e+01)	Consistency Loss 2.2024e+00 (2.2357e+00)	Entropy 2.9886e+00 (2.9905e+00)
Epoch: [21][ 75/123]	Total Loss -1.2728e+01 (-1.2716e+01)	Consistency Loss 2.2188e+00 (2.2375e+00)	Entropy 2.9895e+00 (2.9906e+00)
Epoch: [21][100/123]	Total Loss -1.2788e+01 (-1.2719e+01)	Consistency Loss 2.1644e+00 (2.2339e+00)	Entropy 2.9905e+00 (2.9906e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.98709774017334, 'consistency': 1.4613527059555054, 'total_loss': -1.5257450342178345}], 'lowest_loss_head': 0, 'lowest_loss': -1.5257450342178345}
New lowest loss on validation set: -1.5072 -> -1.5257
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.20869785723342207, 'ARI': 0.09016582916686679, 'NMI': 0.22751923170241478, 'ACC Top-5': 0.5580068467097756, 'hungarian_match': [(0, 3), (1, 19), (2, 15), (3, 6), (4, 17), (5, 0), (6, 12), (7, 10), (8, 11), (9, 2), (10, 14), (11, 5), (12, 13), (13, 9), (14, 1), (15, 18), (16, 8), (17, 4), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 23/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [22][  0/123]	Total Loss -1.2675e+01 (-1.2675e+01)	Consistency Loss 2.2777e+00 (2.2777e+00)	Entropy 2.9906e+00 (2.9906e+00)
Epoch: [22][ 25/123]	Total Loss -1.2805e+01 (-1.2697e+01)	Consistency Loss 2.1586e+00 (2.2565e+00)	Entropy 2.9927e+00 (2.9907e+00)
Epoch: [22][ 50/123]	Total Loss -1.2730e+01 (-1.2708e+01)	Consistency Loss 2.2200e+00 (2.2457e+00)	Entropy 2.9899e+00 (2.9908e+00)
Epoch: [22][ 75/123]	Total Loss -1.2716e+01 (-1.2712e+01)	Consistency Loss 2.2359e+00 (2.2410e+00)	Entropy 2.9904e+00 (2.9906e+00)
Epoch: [22][100/123]	Total Loss -1.2538e+01 (-1.2709e+01)	Consistency Loss 2.4261e+00 (2.2448e+00)	Entropy 2.9929e+00 (2.9907e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.987102508544922, 'consistency': 1.4542791843414307, 'total_loss': -1.5328233242034912}], 'lowest_loss_head': 0, 'lowest_loss': -1.5328233242034912}
New lowest loss on validation set: -1.5257 -> -1.5328
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21541777608723214, 'ARI': 0.09189464042876008, 'NMI': 0.22852454435659444, 'ACC Top-5': 0.5124889057943451, 'hungarian_match': [(0, 6), (1, 10), (2, 15), (3, 3), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 18), (11, 5), (12, 13), (13, 9), (14, 1), (15, 4), (16, 8), (17, 19), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 24/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [23][  0/123]	Total Loss -1.2521e+01 (-1.2521e+01)	Consistency Loss 2.4199e+00 (2.4199e+00)	Entropy 2.9883e+00 (2.9883e+00)
Epoch: [23][ 25/123]	Total Loss -1.2797e+01 (-1.2722e+01)	Consistency Loss 2.1666e+00 (2.2311e+00)	Entropy 2.9926e+00 (2.9905e+00)
Epoch: [23][ 50/123]	Total Loss -1.2584e+01 (-1.2715e+01)	Consistency Loss 2.3712e+00 (2.2359e+00)	Entropy 2.9911e+00 (2.9902e+00)
Epoch: [23][ 75/123]	Total Loss -1.2763e+01 (-1.2713e+01)	Consistency Loss 2.1901e+00 (2.2380e+00)	Entropy 2.9907e+00 (2.9903e+00)
Epoch: [23][100/123]	Total Loss -1.2575e+01 (-1.2710e+01)	Consistency Loss 2.3627e+00 (2.2405e+00)	Entropy 2.9875e+00 (2.9901e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9887194633483887, 'consistency': 1.4782105684280396, 'total_loss': -1.5105088949203491}], 'lowest_loss_head': 0, 'lowest_loss': -1.5105088949203491}
No new lowest loss on validation set: -1.5328 -> -1.5105
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2105363255990871, 'ARI': 0.08785368440965435, 'NMI': 0.22802981885936818, 'ACC Top-5': 0.5105870419677951, 'hungarian_match': [(0, 6), (1, 19), (2, 15), (3, 3), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 5), (12, 13), (13, 4), (14, 1), (15, 18), (16, 8), (17, 9), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 25/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [24][  0/123]	Total Loss -1.2812e+01 (-1.2812e+01)	Consistency Loss 2.1427e+00 (2.1427e+00)	Entropy 2.9909e+00 (2.9909e+00)
Epoch: [24][ 25/123]	Total Loss -1.2753e+01 (-1.2720e+01)	Consistency Loss 2.2067e+00 (2.2327e+00)	Entropy 2.9919e+00 (2.9906e+00)
Epoch: [24][ 50/123]	Total Loss -1.2868e+01 (-1.2717e+01)	Consistency Loss 2.0983e+00 (2.2354e+00)	Entropy 2.9933e+00 (2.9906e+00)
Epoch: [24][ 75/123]	Total Loss -1.2592e+01 (-1.2721e+01)	Consistency Loss 2.3655e+00 (2.2315e+00)	Entropy 2.9915e+00 (2.9905e+00)
Epoch: [24][100/123]	Total Loss -1.2766e+01 (-1.2721e+01)	Consistency Loss 2.1919e+00 (2.2315e+00)	Entropy 2.9915e+00 (2.9905e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9850213527679443, 'consistency': 1.467429757118225, 'total_loss': -1.5175915956497192}], 'lowest_loss_head': 0, 'lowest_loss': -1.5175915956497192}
No new lowest loss on validation set: -1.5328 -> -1.5176
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2209965766451122, 'ARI': 0.09179592767950713, 'NMI': 0.22801518983450542, 'ACC Top-5': 0.5140737923164701, 'hungarian_match': [(0, 3), (1, 10), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 18), (11, 5), (12, 13), (13, 9), (14, 1), (15, 4), (16, 8), (17, 19), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 26/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [25][  0/123]	Total Loss -1.2706e+01 (-1.2706e+01)	Consistency Loss 2.2603e+00 (2.2603e+00)	Entropy 2.9932e+00 (2.9932e+00)
Epoch: [25][ 25/123]	Total Loss -1.2660e+01 (-1.2720e+01)	Consistency Loss 2.2810e+00 (2.2312e+00)	Entropy 2.9882e+00 (2.9903e+00)
Epoch: [25][ 50/123]	Total Loss -1.2789e+01 (-1.2728e+01)	Consistency Loss 2.1691e+00 (2.2247e+00)	Entropy 2.9916e+00 (2.9906e+00)
Epoch: [25][ 75/123]	Total Loss -1.2745e+01 (-1.2718e+01)	Consistency Loss 2.2130e+00 (2.2355e+00)	Entropy 2.9916e+00 (2.9906e+00)
Epoch: [25][100/123]	Total Loss -1.2855e+01 (-1.2714e+01)	Consistency Loss 2.0978e+00 (2.2392e+00)	Entropy 2.9905e+00 (2.9906e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9850494861602783, 'consistency': 1.4557819366455078, 'total_loss': -1.5292675495147705}], 'lowest_loss_head': 0, 'lowest_loss': -1.5292675495147705}
No new lowest loss on validation set: -1.5328 -> -1.5293
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21491061240015216, 'ARI': 0.09632635725533764, 'NMI': 0.22946146465453965, 'ACC Top-5': 0.5128058830987702, 'hungarian_match': [(0, 6), (1, 19), (2, 15), (3, 3), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 5), (12, 13), (13, 9), (14, 1), (15, 18), (16, 8), (17, 4), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 27/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [26][  0/123]	Total Loss -1.2767e+01 (-1.2767e+01)	Consistency Loss 2.1860e+00 (2.1860e+00)	Entropy 2.9907e+00 (2.9907e+00)
Epoch: [26][ 25/123]	Total Loss -1.2833e+01 (-1.2746e+01)	Consistency Loss 2.1174e+00 (2.2042e+00)	Entropy 2.9900e+00 (2.9901e+00)
Epoch: [26][ 50/123]	Total Loss -1.2708e+01 (-1.2731e+01)	Consistency Loss 2.2421e+00 (2.2190e+00)	Entropy 2.9901e+00 (2.9901e+00)
Epoch: [26][ 75/123]	Total Loss -1.2678e+01 (-1.2727e+01)	Consistency Loss 2.2834e+00 (2.2243e+00)	Entropy 2.9923e+00 (2.9902e+00)
Epoch: [26][100/123]	Total Loss -1.2849e+01 (-1.2727e+01)	Consistency Loss 2.0912e+00 (2.2244e+00)	Entropy 2.9880e+00 (2.9902e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.981480360031128, 'consistency': 1.4315667152404785, 'total_loss': -1.5499136447906494}], 'lowest_loss_head': 0, 'lowest_loss': -1.5499136447906494}
New lowest loss on validation set: -1.5328 -> -1.5499
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2185241536705972, 'ARI': 0.09102072320207864, 'NMI': 0.23004282027941167, 'ACC Top-5': 0.5139470013947002, 'hungarian_match': [(0, 3), (1, 10), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 18), (11, 5), (12, 13), (13, 9), (14, 1), (15, 4), (16, 8), (17, 19), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 28/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [27][  0/123]	Total Loss -1.2590e+01 (-1.2590e+01)	Consistency Loss 2.3419e+00 (2.3419e+00)	Entropy 2.9864e+00 (2.9864e+00)
Epoch: [27][ 25/123]	Total Loss -1.2749e+01 (-1.2712e+01)	Consistency Loss 2.2100e+00 (2.2377e+00)	Entropy 2.9919e+00 (2.9900e+00)
Epoch: [27][ 50/123]	Total Loss -1.2765e+01 (-1.2720e+01)	Consistency Loss 2.1913e+00 (2.2316e+00)	Entropy 2.9914e+00 (2.9904e+00)
Epoch: [27][ 75/123]	Total Loss -1.2746e+01 (-1.2725e+01)	Consistency Loss 2.2085e+00 (2.2262e+00)	Entropy 2.9908e+00 (2.9903e+00)
Epoch: [27][100/123]	Total Loss -1.2702e+01 (-1.2726e+01)	Consistency Loss 2.2579e+00 (2.2252e+00)	Entropy 2.9920e+00 (2.9903e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.985445022583008, 'consistency': 1.4340378046035767, 'total_loss': -1.5514072179794312}], 'lowest_loss_head': 0, 'lowest_loss': -1.5514072179794312}
New lowest loss on validation set: -1.5499 -> -1.5514
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2199188538100672, 'ARI': 0.09262985845413689, 'NMI': 0.23121340518720407, 'ACC Top-5': 0.5088119690630151, 'hungarian_match': [(0, 3), (1, 10), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 18), (11, 5), (12, 13), (13, 19), (14, 1), (15, 9), (16, 8), (17, 4), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 29/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [28][  0/123]	Total Loss -1.2577e+01 (-1.2577e+01)	Consistency Loss 2.3823e+00 (2.3823e+00)	Entropy 2.9918e+00 (2.9918e+00)
Epoch: [28][ 25/123]	Total Loss -1.2559e+01 (-1.2718e+01)	Consistency Loss 2.4080e+00 (2.2354e+00)	Entropy 2.9933e+00 (2.9907e+00)
Epoch: [28][ 50/123]	Total Loss -1.2725e+01 (-1.2724e+01)	Consistency Loss 2.2359e+00 (2.2293e+00)	Entropy 2.9921e+00 (2.9906e+00)
Epoch: [28][ 75/123]	Total Loss -1.2519e+01 (-1.2716e+01)	Consistency Loss 2.4269e+00 (2.2357e+00)	Entropy 2.9892e+00 (2.9903e+00)
Epoch: [28][100/123]	Total Loss -1.2720e+01 (-1.2720e+01)	Consistency Loss 2.2304e+00 (2.2325e+00)	Entropy 2.9900e+00 (2.9904e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9877235889434814, 'consistency': 1.4480249881744385, 'total_loss': -1.539698600769043}], 'lowest_loss_head': 0, 'lowest_loss': -1.539698600769043}
No new lowest loss on validation set: -1.5514 -> -1.5397
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21332572587802714, 'ARI': 0.0910485614797055, 'NMI': 0.22921848504248427, 'ACC Top-5': 0.5214276657791302, 'hungarian_match': [(0, 0), (1, 3), (2, 15), (3, 6), (4, 14), (5, 18), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 5), (12, 13), (13, 19), (14, 1), (15, 9), (16, 8), (17, 4), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 30/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [29][  0/123]	Total Loss -1.2707e+01 (-1.2707e+01)	Consistency Loss 2.2512e+00 (2.2512e+00)	Entropy 2.9916e+00 (2.9916e+00)
Epoch: [29][ 25/123]	Total Loss -1.2710e+01 (-1.2719e+01)	Consistency Loss 2.2437e+00 (2.2373e+00)	Entropy 2.9907e+00 (2.9912e+00)
Epoch: [29][ 50/123]	Total Loss -1.2701e+01 (-1.2727e+01)	Consistency Loss 2.2357e+00 (2.2266e+00)	Entropy 2.9873e+00 (2.9907e+00)
Epoch: [29][ 75/123]	Total Loss -1.2766e+01 (-1.2725e+01)	Consistency Loss 2.2043e+00 (2.2288e+00)	Entropy 2.9940e+00 (2.9907e+00)
Epoch: [29][100/123]	Total Loss -1.2648e+01 (-1.2717e+01)	Consistency Loss 2.2976e+00 (2.2358e+00)	Entropy 2.9891e+00 (2.9905e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.986326217651367, 'consistency': 1.4658868312835693, 'total_loss': -1.5204393863677979}], 'lowest_loss_head': 0, 'lowest_loss': -1.5204393863677979}
No new lowest loss on validation set: -1.5514 -> -1.5204
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21465703055661214, 'ARI': 0.09155223265870914, 'NMI': 0.23015279719579396, 'ACC Top-5': 0.5207937111702802, 'hungarian_match': [(0, 3), (1, 18), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 5), (12, 13), (13, 19), (14, 1), (15, 9), (16, 8), (17, 4), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 31/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [30][  0/123]	Total Loss -1.2627e+01 (-1.2627e+01)	Consistency Loss 2.3289e+00 (2.3289e+00)	Entropy 2.9913e+00 (2.9913e+00)
Epoch: [30][ 25/123]	Total Loss -1.2533e+01 (-1.2715e+01)	Consistency Loss 2.4206e+00 (2.2367e+00)	Entropy 2.9908e+00 (2.9904e+00)
Epoch: [30][ 50/123]	Total Loss -1.2718e+01 (-1.2725e+01)	Consistency Loss 2.2432e+00 (2.2267e+00)	Entropy 2.9922e+00 (2.9904e+00)
Epoch: [30][ 75/123]	Total Loss -1.2648e+01 (-1.2726e+01)	Consistency Loss 2.3089e+00 (2.2263e+00)	Entropy 2.9913e+00 (2.9905e+00)
Epoch: [30][100/123]	Total Loss -1.2563e+01 (-1.2726e+01)	Consistency Loss 2.3793e+00 (2.2263e+00)	Entropy 2.9885e+00 (2.9905e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9879465103149414, 'consistency': 1.4512120485305786, 'total_loss': -1.5367344617843628}], 'lowest_loss_head': 0, 'lowest_loss': -1.5367344617843628}
No new lowest loss on validation set: -1.5514 -> -1.5367
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21421326233041715, 'ARI': 0.08895326819836585, 'NMI': 0.22999643470119585, 'ACC Top-5': 0.5086217826803601, 'hungarian_match': [(0, 3), (1, 10), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 18), (11, 5), (12, 13), (13, 19), (14, 1), (15, 4), (16, 8), (17, 9), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 32/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [31][  0/123]	Total Loss -1.2705e+01 (-1.2705e+01)	Consistency Loss 2.2496e+00 (2.2496e+00)	Entropy 2.9909e+00 (2.9909e+00)
Epoch: [31][ 25/123]	Total Loss -1.2853e+01 (-1.2729e+01)	Consistency Loss 2.0923e+00 (2.2255e+00)	Entropy 2.9890e+00 (2.9909e+00)
Epoch: [31][ 50/123]	Total Loss -1.2742e+01 (-1.2738e+01)	Consistency Loss 2.2077e+00 (2.2169e+00)	Entropy 2.9899e+00 (2.9909e+00)
Epoch: [31][ 75/123]	Total Loss -1.2812e+01 (-1.2739e+01)	Consistency Loss 2.1295e+00 (2.2148e+00)	Entropy 2.9883e+00 (2.9908e+00)
Epoch: [31][100/123]	Total Loss -1.2608e+01 (-1.2735e+01)	Consistency Loss 2.3602e+00 (2.2189e+00)	Entropy 2.9936e+00 (2.9909e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.989684581756592, 'consistency': 1.44309663772583, 'total_loss': -1.5465879440307617}], 'lowest_loss_head': 0, 'lowest_loss': -1.5465879440307617}
No new lowest loss on validation set: -1.5514 -> -1.5466
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2087612526943071, 'ARI': 0.08807638172196301, 'NMI': 0.23008225411835964, 'ACC Top-5': 0.5628882971979207, 'hungarian_match': [(0, 3), (1, 10), (2, 15), (3, 6), (4, 17), (5, 0), (6, 12), (7, 18), (8, 11), (9, 2), (10, 14), (11, 5), (12, 13), (13, 19), (14, 1), (15, 4), (16, 8), (17, 9), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 33/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [32][  0/123]	Total Loss -1.2833e+01 (-1.2833e+01)	Consistency Loss 2.1214e+00 (2.1214e+00)	Entropy 2.9910e+00 (2.9910e+00)
Epoch: [32][ 25/123]	Total Loss -1.2802e+01 (-1.2737e+01)	Consistency Loss 2.1476e+00 (2.2140e+00)	Entropy 2.9898e+00 (2.9903e+00)
Epoch: [32][ 50/123]	Total Loss -1.2670e+01 (-1.2743e+01)	Consistency Loss 2.2686e+00 (2.2097e+00)	Entropy 2.9878e+00 (2.9904e+00)
Epoch: [32][ 75/123]	Total Loss -1.2608e+01 (-1.2743e+01)	Consistency Loss 2.3545e+00 (2.2093e+00)	Entropy 2.9924e+00 (2.9905e+00)
Epoch: [32][100/123]	Total Loss -1.2767e+01 (-1.2746e+01)	Consistency Loss 2.2011e+00 (2.2071e+00)	Entropy 2.9936e+00 (2.9906e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.987337112426758, 'consistency': 1.4343901872634888, 'total_loss': -1.552946925163269}], 'lowest_loss_head': 0, 'lowest_loss': -1.552946925163269}
New lowest loss on validation set: -1.5514 -> -1.5529
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21535438062634715, 'ARI': 0.08506076940138604, 'NMI': 0.2281293894189001, 'ACC Top-5': 0.5098262964371751, 'hungarian_match': [(0, 3), (1, 10), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 5), (11, 4), (12, 13), (13, 9), (14, 1), (15, 18), (16, 8), (17, 19), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 34/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [33][  0/123]	Total Loss -1.2787e+01 (-1.2787e+01)	Consistency Loss 2.1771e+00 (2.1771e+00)	Entropy 2.9928e+00 (2.9928e+00)
Epoch: [33][ 25/123]	Total Loss -1.2737e+01 (-1.2756e+01)	Consistency Loss 2.2209e+00 (2.1974e+00)	Entropy 2.9916e+00 (2.9907e+00)
Epoch: [33][ 50/123]	Total Loss -1.2834e+01 (-1.2736e+01)	Consistency Loss 2.1044e+00 (2.2155e+00)	Entropy 2.9876e+00 (2.9903e+00)
Epoch: [33][ 75/123]	Total Loss -1.2744e+01 (-1.2736e+01)	Consistency Loss 2.2177e+00 (2.2163e+00)	Entropy 2.9923e+00 (2.9904e+00)
Epoch: [33][100/123]	Total Loss -1.2779e+01 (-1.2734e+01)	Consistency Loss 2.1653e+00 (2.2175e+00)	Entropy 2.9888e+00 (2.9903e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.991297483444214, 'consistency': 1.4461054801940918, 'total_loss': -1.545192003250122}], 'lowest_loss_head': 0, 'lowest_loss': -1.545192003250122}
No new lowest loss on validation set: -1.5529 -> -1.5452
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21453023963484213, 'ARI': 0.0865152921674777, 'NMI': 0.23159243307615035, 'ACC Top-5': 0.5117281602637251, 'hungarian_match': [(0, 3), (1, 10), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 18), (11, 4), (12, 13), (13, 9), (14, 1), (15, 5), (16, 8), (17, 19), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 35/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [34][  0/123]	Total Loss -1.2778e+01 (-1.2778e+01)	Consistency Loss 2.1901e+00 (2.1901e+00)	Entropy 2.9936e+00 (2.9936e+00)
Epoch: [34][ 25/123]	Total Loss -1.2809e+01 (-1.2755e+01)	Consistency Loss 2.1476e+00 (2.1955e+00)	Entropy 2.9913e+00 (2.9902e+00)
Epoch: [34][ 50/123]	Total Loss -1.2893e+01 (-1.2749e+01)	Consistency Loss 2.0682e+00 (2.2042e+00)	Entropy 2.9923e+00 (2.9906e+00)
Epoch: [34][ 75/123]	Total Loss -1.2772e+01 (-1.2745e+01)	Consistency Loss 2.1896e+00 (2.2083e+00)	Entropy 2.9923e+00 (2.9906e+00)
Epoch: [34][100/123]	Total Loss -1.2572e+01 (-1.2740e+01)	Consistency Loss 2.3848e+00 (2.2141e+00)	Entropy 2.9914e+00 (2.9908e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9879894256591797, 'consistency': 1.4284286499023438, 'total_loss': -1.559560775756836}], 'lowest_loss_head': 0, 'lowest_loss': -1.559560775756836}
New lowest loss on validation set: -1.5529 -> -1.5596
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21224800304298214, 'ARI': 0.08475776439775885, 'NMI': 0.23284265719524755, 'ACC Top-5': 0.5180043108913401, 'hungarian_match': [(0, 3), (1, 10), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 5), (11, 4), (12, 13), (13, 9), (14, 1), (15, 18), (16, 8), (17, 19), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 36/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [35][  0/123]	Total Loss -1.2895e+01 (-1.2895e+01)	Consistency Loss 2.0669e+00 (2.0669e+00)	Entropy 2.9924e+00 (2.9924e+00)
Epoch: [35][ 25/123]	Total Loss -1.2580e+01 (-1.2742e+01)	Consistency Loss 2.3745e+00 (2.2113e+00)	Entropy 2.9909e+00 (2.9907e+00)
Epoch: [35][ 50/123]	Total Loss -1.2767e+01 (-1.2742e+01)	Consistency Loss 2.1693e+00 (2.2102e+00)	Entropy 2.9873e+00 (2.9905e+00)
Epoch: [35][ 75/123]	Total Loss -1.2721e+01 (-1.2745e+01)	Consistency Loss 2.2276e+00 (2.2081e+00)	Entropy 2.9897e+00 (2.9905e+00)
Epoch: [35][100/123]	Total Loss -1.2883e+01 (-1.2741e+01)	Consistency Loss 2.0791e+00 (2.2117e+00)	Entropy 2.9925e+00 (2.9906e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9873456954956055, 'consistency': 1.4341024160385132, 'total_loss': -1.5532432794570923}], 'lowest_loss_head': 0, 'lowest_loss': -1.5532432794570923}
No new lowest loss on validation set: -1.5596 -> -1.5532
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21478382147838215, 'ARI': 0.08692629984761979, 'NMI': 0.23490438702940644, 'ACC Top-5': 0.5199061747178902, 'hungarian_match': [(0, 3), (1, 10), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 5), (11, 4), (12, 13), (13, 9), (14, 1), (15, 18), (16, 8), (17, 19), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 37/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [36][  0/123]	Total Loss -1.2829e+01 (-1.2829e+01)	Consistency Loss 2.1264e+00 (2.1264e+00)	Entropy 2.9911e+00 (2.9911e+00)
Epoch: [36][ 25/123]	Total Loss -1.2626e+01 (-1.2744e+01)	Consistency Loss 2.3351e+00 (2.2112e+00)	Entropy 2.9922e+00 (2.9911e+00)
Epoch: [36][ 50/123]	Total Loss -1.2782e+01 (-1.2742e+01)	Consistency Loss 2.1729e+00 (2.2136e+00)	Entropy 2.9910e+00 (2.9911e+00)
Epoch: [36][ 75/123]	Total Loss -1.2591e+01 (-1.2740e+01)	Consistency Loss 2.3467e+00 (2.2142e+00)	Entropy 2.9876e+00 (2.9908e+00)
Epoch: [36][100/123]	Total Loss -1.2944e+01 (-1.2747e+01)	Consistency Loss 2.0045e+00 (2.2071e+00)	Entropy 2.9897e+00 (2.9908e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.986067533493042, 'consistency': 1.41923189163208, 'total_loss': -1.566835641860962}], 'lowest_loss_head': 0, 'lowest_loss': -1.566835641860962}
New lowest loss on validation set: -1.5596 -> -1.5668
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.22093318118422722, 'ARI': 0.08899527977067279, 'NMI': 0.231217382474747, 'ACC Top-5': 0.5124889057943451, 'hungarian_match': [(0, 3), (1, 10), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 18), (11, 5), (12, 13), (13, 9), (14, 1), (15, 4), (16, 8), (17, 19), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 38/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [37][  0/123]	Total Loss -1.2750e+01 (-1.2750e+01)	Consistency Loss 2.2024e+00 (2.2024e+00)	Entropy 2.9905e+00 (2.9905e+00)
Epoch: [37][ 25/123]	Total Loss -1.2727e+01 (-1.2743e+01)	Consistency Loss 2.2222e+00 (2.2126e+00)	Entropy 2.9898e+00 (2.9911e+00)
Epoch: [37][ 50/123]	Total Loss -1.2884e+01 (-1.2747e+01)	Consistency Loss 2.0807e+00 (2.2065e+00)	Entropy 2.9928e+00 (2.9908e+00)
Epoch: [37][ 75/123]	Total Loss -1.2803e+01 (-1.2747e+01)	Consistency Loss 2.1385e+00 (2.2062e+00)	Entropy 2.9883e+00 (2.9907e+00)
Epoch: [37][100/123]	Total Loss -1.2641e+01 (-1.2742e+01)	Consistency Loss 2.3160e+00 (2.2113e+00)	Entropy 2.9914e+00 (2.9907e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9874534606933594, 'consistency': 1.4138381481170654, 'total_loss': -1.573615312576294}], 'lowest_loss_head': 0, 'lowest_loss': -1.573615312576294}
New lowest loss on validation set: -1.5668 -> -1.5736
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21586154431342716, 'ARI': 0.0906993790297245, 'NMI': 0.23418732539560233, 'ACC Top-5': 0.5155952833777101, 'hungarian_match': [(0, 6), (1, 10), (2, 15), (3, 3), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 18), (11, 5), (12, 13), (13, 9), (14, 1), (15, 4), (16, 8), (17, 19), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 39/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [38][  0/123]	Total Loss -1.2686e+01 (-1.2686e+01)	Consistency Loss 2.2568e+00 (2.2568e+00)	Entropy 2.9886e+00 (2.9886e+00)
Epoch: [38][ 25/123]	Total Loss -1.2685e+01 (-1.2730e+01)	Consistency Loss 2.2799e+00 (2.2239e+00)	Entropy 2.9930e+00 (2.9908e+00)
Epoch: [38][ 50/123]	Total Loss -1.2809e+01 (-1.2734e+01)	Consistency Loss 2.1349e+00 (2.2200e+00)	Entropy 2.9888e+00 (2.9907e+00)
Epoch: [38][ 75/123]	Total Loss -1.2871e+01 (-1.2736e+01)	Consistency Loss 2.0833e+00 (2.2180e+00)	Entropy 2.9909e+00 (2.9909e+00)
Epoch: [38][100/123]	Total Loss -1.2703e+01 (-1.2748e+01)	Consistency Loss 2.2444e+00 (2.2060e+00)	Entropy 2.9895e+00 (2.9909e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9906299114227295, 'consistency': 1.4093948602676392, 'total_loss': -1.5812350511550903}], 'lowest_loss_head': 0, 'lowest_loss': -1.5812350511550903}
New lowest loss on validation set: -1.5736 -> -1.5812
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2089514390769621, 'ARI': 0.08795497669657847, 'NMI': 0.2329730710618586, 'ACC Top-5': 0.5129960694814252, 'hungarian_match': [(0, 6), (1, 10), (2, 15), (3, 3), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 19), (10, 5), (11, 4), (12, 13), (13, 9), (14, 1), (15, 18), (16, 8), (17, 16), (18, 7), (19, 2)]}
Checkpoint ...
[33mEpoch 40/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [39][  0/123]	Total Loss -1.2841e+01 (-1.2841e+01)	Consistency Loss 2.0951e+00 (2.0951e+00)	Entropy 2.9873e+00 (2.9873e+00)
Epoch: [39][ 25/123]	Total Loss -1.2746e+01 (-1.2721e+01)	Consistency Loss 2.2234e+00 (2.2320e+00)	Entropy 2.9940e+00 (2.9905e+00)
Epoch: [39][ 50/123]	Total Loss -1.2798e+01 (-1.2742e+01)	Consistency Loss 2.1577e+00 (2.2116e+00)	Entropy 2.9911e+00 (2.9907e+00)
Epoch: [39][ 75/123]	Total Loss -1.2574e+01 (-1.2745e+01)	Consistency Loss 2.3779e+00 (2.2089e+00)	Entropy 2.9905e+00 (2.9907e+00)
Epoch: [39][100/123]	Total Loss -1.2834e+01 (-1.2752e+01)	Consistency Loss 2.1277e+00 (2.2012e+00)	Entropy 2.9923e+00 (2.9906e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.988389015197754, 'consistency': 1.405131459236145, 'total_loss': -1.5832575559616089}], 'lowest_loss_head': 0, 'lowest_loss': -1.5832575559616089}
New lowest loss on validation set: -1.5812 -> -1.5833
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21567135793077216, 'ARI': 0.08701848833335471, 'NMI': 0.23260084728591088, 'ACC Top-5': 0.5185114745784202, 'hungarian_match': [(0, 0), (1, 10), (2, 15), (3, 6), (4, 14), (5, 18), (6, 12), (7, 17), (8, 11), (9, 2), (10, 19), (11, 5), (12, 13), (13, 9), (14, 1), (15, 4), (16, 8), (17, 3), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 41/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [40][  0/123]	Total Loss -1.2831e+01 (-1.2831e+01)	Consistency Loss 2.1068e+00 (2.1068e+00)	Entropy 2.9875e+00 (2.9875e+00)
Epoch: [40][ 25/123]	Total Loss -1.2796e+01 (-1.2722e+01)	Consistency Loss 2.1581e+00 (2.2260e+00)	Entropy 2.9908e+00 (2.9895e+00)
Epoch: [40][ 50/123]	Total Loss -1.2685e+01 (-1.2729e+01)	Consistency Loss 2.2832e+00 (2.2221e+00)	Entropy 2.9937e+00 (2.9901e+00)
Epoch: [40][ 75/123]	Total Loss -1.2849e+01 (-1.2736e+01)	Consistency Loss 2.1108e+00 (2.2152e+00)	Entropy 2.9920e+00 (2.9902e+00)
Epoch: [40][100/123]	Total Loss -1.2845e+01 (-1.2741e+01)	Consistency Loss 2.1155e+00 (2.2103e+00)	Entropy 2.9921e+00 (2.9903e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9843194484710693, 'consistency': 1.4005932807922363, 'total_loss': -1.583726167678833}], 'lowest_loss_head': 0, 'lowest_loss': -1.583726167678833}
New lowest loss on validation set: -1.5833 -> -1.5837
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21725624445289718, 'ARI': 0.09049810734583279, 'NMI': 0.2354525229539101, 'ACC Top-5': 0.5213642703182452, 'hungarian_match': [(0, 3), (1, 10), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 19), (10, 18), (11, 4), (12, 13), (13, 9), (14, 1), (15, 5), (16, 8), (17, 16), (18, 7), (19, 2)]}
Checkpoint ...
[33mEpoch 42/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [41][  0/123]	Total Loss -1.2816e+01 (-1.2816e+01)	Consistency Loss 2.1241e+00 (2.1241e+00)	Entropy 2.9881e+00 (2.9881e+00)
Epoch: [41][ 25/123]	Total Loss -1.2802e+01 (-1.2770e+01)	Consistency Loss 2.1618e+00 (2.1794e+00)	Entropy 2.9927e+00 (2.9898e+00)
Epoch: [41][ 50/123]	Total Loss -1.2971e+01 (-1.2772e+01)	Consistency Loss 1.9713e+00 (2.1790e+00)	Entropy 2.9885e+00 (2.9902e+00)
Epoch: [41][ 75/123]	Total Loss -1.2637e+01 (-1.2765e+01)	Consistency Loss 2.3238e+00 (2.1850e+00)	Entropy 2.9922e+00 (2.9901e+00)
Epoch: [41][100/123]	Total Loss -1.2773e+01 (-1.2762e+01)	Consistency Loss 2.1885e+00 (2.1893e+00)	Entropy 2.9923e+00 (2.9903e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9836103916168213, 'consistency': 1.4057399034500122, 'total_loss': -1.577870488166809}], 'lowest_loss_head': 0, 'lowest_loss': -1.577870488166809}
No new lowest loss on validation set: -1.5837 -> -1.5779
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21262837580829214, 'ARI': 0.09621950844291033, 'NMI': 0.2360123246649252, 'ACC Top-5': 0.5203499429440852, 'hungarian_match': [(0, 0), (1, 10), (2, 15), (3, 6), (4, 14), (5, 18), (6, 12), (7, 17), (8, 11), (9, 2), (10, 19), (11, 5), (12, 13), (13, 9), (14, 1), (15, 3), (16, 8), (17, 4), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 43/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [42][  0/123]	Total Loss -1.2608e+01 (-1.2608e+01)	Consistency Loss 2.3416e+00 (2.3416e+00)	Entropy 2.9899e+00 (2.9899e+00)
Epoch: [42][ 25/123]	Total Loss -1.2821e+01 (-1.2758e+01)	Consistency Loss 2.1396e+00 (2.1950e+00)	Entropy 2.9921e+00 (2.9907e+00)
Epoch: [42][ 50/123]	Total Loss -1.2797e+01 (-1.2750e+01)	Consistency Loss 2.1542e+00 (2.2021e+00)	Entropy 2.9902e+00 (2.9905e+00)
Epoch: [42][ 75/123]	Total Loss -1.2691e+01 (-1.2744e+01)	Consistency Loss 2.2665e+00 (2.2086e+00)	Entropy 2.9916e+00 (2.9905e+00)
Epoch: [42][100/123]	Total Loss -1.2673e+01 (-1.2748e+01)	Consistency Loss 2.2885e+00 (2.2049e+00)	Entropy 2.9923e+00 (2.9906e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.986440658569336, 'consistency': 1.420336127281189, 'total_loss': -1.566104531288147}], 'lowest_loss_head': 0, 'lowest_loss': -1.566104531288147}
No new lowest loss on validation set: -1.5837 -> -1.5661
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21434005325218713, 'ARI': 0.09014541597778548, 'NMI': 0.23694719625856644, 'ACC Top-5': 0.5137568150120452, 'hungarian_match': [(0, 0), (1, 19), (2, 15), (3, 6), (4, 14), (5, 18), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 4), (12, 13), (13, 9), (14, 1), (15, 5), (16, 8), (17, 3), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 44/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [43][  0/123]	Total Loss -1.2689e+01 (-1.2689e+01)	Consistency Loss 2.2756e+00 (2.2756e+00)	Entropy 2.9928e+00 (2.9928e+00)
Epoch: [43][ 25/123]	Total Loss -1.2900e+01 (-1.2735e+01)	Consistency Loss 2.0633e+00 (2.2190e+00)	Entropy 2.9927e+00 (2.9909e+00)
Epoch: [43][ 50/123]	Total Loss -1.2703e+01 (-1.2770e+01)	Consistency Loss 2.2428e+00 (2.1843e+00)	Entropy 2.9893e+00 (2.9909e+00)
Epoch: [43][ 75/123]	Total Loss -1.2748e+01 (-1.2772e+01)	Consistency Loss 2.2120e+00 (2.1830e+00)	Entropy 2.9919e+00 (2.9909e+00)
Epoch: [43][100/123]	Total Loss -1.2800e+01 (-1.2769e+01)	Consistency Loss 2.1680e+00 (2.1847e+00)	Entropy 2.9935e+00 (2.9908e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9871115684509277, 'consistency': 1.4171125888824463, 'total_loss': -1.5699989795684814}], 'lowest_loss_head': 0, 'lowest_loss': -1.5699989795684814}
No new lowest loss on validation set: -1.5837 -> -1.5700
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2105997210599721, 'ARI': 0.08899757955149129, 'NMI': 0.23525707944964933, 'ACC Top-5': 0.501458095600355, 'hungarian_match': [(0, 3), (1, 10), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 19), (10, 18), (11, 5), (12, 13), (13, 2), (14, 1), (15, 9), (16, 8), (17, 4), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 45/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [44][  0/123]	Total Loss -1.2536e+01 (-1.2536e+01)	Consistency Loss 2.4141e+00 (2.4141e+00)	Entropy 2.9900e+00 (2.9900e+00)
Epoch: [44][ 25/123]	Total Loss -1.2807e+01 (-1.2771e+01)	Consistency Loss 2.1321e+00 (2.1827e+00)	Entropy 2.9878e+00 (2.9907e+00)
Epoch: [44][ 50/123]	Total Loss -1.2915e+01 (-1.2762e+01)	Consistency Loss 2.0310e+00 (2.1920e+00)	Entropy 2.9892e+00 (2.9908e+00)
Epoch: [44][ 75/123]	Total Loss -1.2594e+01 (-1.2764e+01)	Consistency Loss 2.3594e+00 (2.1909e+00)	Entropy 2.9906e+00 (2.9909e+00)
Epoch: [44][100/123]	Total Loss -1.2823e+01 (-1.2771e+01)	Consistency Loss 2.1133e+00 (2.1834e+00)	Entropy 2.9872e+00 (2.9909e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9882071018218994, 'consistency': 1.4077366590499878, 'total_loss': -1.5804704427719116}], 'lowest_loss_head': 0, 'lowest_loss': -1.5804704427719116}
No new lowest loss on validation set: -1.5837 -> -1.5805
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21484721693926714, 'ARI': 0.08918291249192764, 'NMI': 0.237068593575846, 'ACC Top-5': 0.49511854951185497, 'hungarian_match': [(0, 6), (1, 8), (2, 15), (3, 3), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 5), (12, 13), (13, 9), (14, 1), (15, 18), (16, 19), (17, 4), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 46/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [45][  0/123]	Total Loss -1.2805e+01 (-1.2805e+01)	Consistency Loss 2.1573e+00 (2.1573e+00)	Entropy 2.9924e+00 (2.9924e+00)
Epoch: [45][ 25/123]	Total Loss -1.2814e+01 (-1.2763e+01)	Consistency Loss 2.1483e+00 (2.1933e+00)	Entropy 2.9924e+00 (2.9913e+00)
Epoch: [45][ 50/123]	Total Loss -1.2794e+01 (-1.2765e+01)	Consistency Loss 2.1652e+00 (2.1905e+00)	Entropy 2.9918e+00 (2.9910e+00)
Epoch: [45][ 75/123]	Total Loss -1.2894e+01 (-1.2760e+01)	Consistency Loss 2.0611e+00 (2.1954e+00)	Entropy 2.9911e+00 (2.9910e+00)
Epoch: [45][100/123]	Total Loss -1.2792e+01 (-1.2758e+01)	Consistency Loss 2.1744e+00 (2.1962e+00)	Entropy 2.9934e+00 (2.9909e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.9820408821105957, 'consistency': 1.4007880687713623, 'total_loss': -1.5812528133392334}], 'lowest_loss_head': 0, 'lowest_loss': -1.5812528133392334}
No new lowest loss on validation set: -1.5837 -> -1.5813
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21770001267909217, 'ARI': 0.09647350997375223, 'NMI': 0.23813926196826748, 'ACC Top-5': 0.5061493597058451, 'hungarian_match': [(0, 3), (1, 8), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 2), (10, 10), (11, 5), (12, 13), (13, 9), (14, 1), (15, 18), (16, 19), (17, 4), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 47/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [46][  0/123]	Total Loss -1.2734e+01 (-1.2734e+01)	Consistency Loss 2.2261e+00 (2.2261e+00)	Entropy 2.9921e+00 (2.9921e+00)
Epoch: [46][ 25/123]	Total Loss -1.2815e+01 (-1.2767e+01)	Consistency Loss 2.1394e+00 (2.1840e+00)	Entropy 2.9909e+00 (2.9902e+00)
Epoch: [46][ 50/123]	Total Loss -1.2647e+01 (-1.2753e+01)	Consistency Loss 2.3066e+00 (2.1989e+00)	Entropy 2.9907e+00 (2.9904e+00)
Epoch: [46][ 75/123]	Total Loss -1.2748e+01 (-1.2749e+01)	Consistency Loss 2.2035e+00 (2.2046e+00)	Entropy 2.9903e+00 (2.9907e+00)
Epoch: [46][100/123]	Total Loss -1.2828e+01 (-1.2750e+01)	Consistency Loss 2.1352e+00 (2.2038e+00)	Entropy 2.9925e+00 (2.9908e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.981074571609497, 'consistency': 1.395038366317749, 'total_loss': -1.586036205291748}], 'lowest_loss_head': 0, 'lowest_loss': -1.586036205291748}
New lowest loss on validation set: -1.5837 -> -1.5860
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2210599721059972, 'ARI': 0.09775962789348874, 'NMI': 0.2397619946237591, 'ACC Top-5': 0.5227589704577152, 'hungarian_match': [(0, 3), (1, 17), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 18), (8, 11), (9, 2), (10, 10), (11, 5), (12, 13), (13, 9), (14, 1), (15, 4), (16, 8), (17, 19), (18, 7), (19, 16)]}
Checkpoint ...
[33mEpoch 48/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [47][  0/123]	Total Loss -1.2757e+01 (-1.2757e+01)	Consistency Loss 2.2011e+00 (2.2011e+00)	Entropy 2.9916e+00 (2.9916e+00)
Epoch: [47][ 25/123]	Total Loss -1.2870e+01 (-1.2762e+01)	Consistency Loss 2.0843e+00 (2.1942e+00)	Entropy 2.9909e+00 (2.9912e+00)
Epoch: [47][ 50/123]	Total Loss -1.2728e+01 (-1.2771e+01)	Consistency Loss 2.2261e+00 (2.1856e+00)	Entropy 2.9908e+00 (2.9914e+00)
Epoch: [47][ 75/123]	Total Loss -1.2752e+01 (-1.2764e+01)	Consistency Loss 2.1952e+00 (2.1927e+00)	Entropy 2.9895e+00 (2.9913e+00)
Epoch: [47][100/123]	Total Loss -1.2719e+01 (-1.2764e+01)	Consistency Loss 2.2410e+00 (2.1915e+00)	Entropy 2.9921e+00 (2.9912e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.989546775817871, 'consistency': 1.395903468132019, 'total_loss': -1.593643307685852}], 'lowest_loss_head': 0, 'lowest_loss': -1.593643307685852}
New lowest loss on validation set: -1.5860 -> -1.5936
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.21510079878280716, 'ARI': 0.09235346815736473, 'NMI': 0.24146289429120504, 'ACC Top-5': 0.5072270825408901, 'hungarian_match': [(0, 6), (1, 10), (2, 15), (3, 3), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 19), (10, 18), (11, 5), (12, 13), (13, 9), (14, 1), (15, 4), (16, 8), (17, 16), (18, 7), (19, 2)]}
Checkpoint ...
[33mEpoch 49/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [48][  0/123]	Total Loss -1.2756e+01 (-1.2756e+01)	Consistency Loss 2.2022e+00 (2.2022e+00)	Entropy 2.9916e+00 (2.9916e+00)
Epoch: [48][ 25/123]	Total Loss -1.2792e+01 (-1.2765e+01)	Consistency Loss 2.1608e+00 (2.1900e+00)	Entropy 2.9905e+00 (2.9909e+00)
Epoch: [48][ 50/123]	Total Loss -1.2688e+01 (-1.2760e+01)	Consistency Loss 2.2759e+00 (2.1966e+00)	Entropy 2.9927e+00 (2.9913e+00)
Epoch: [48][ 75/123]	Total Loss -1.2604e+01 (-1.2759e+01)	Consistency Loss 2.3564e+00 (2.1979e+00)	Entropy 2.9921e+00 (2.9913e+00)
Epoch: [48][100/123]	Total Loss -1.2727e+01 (-1.2755e+01)	Consistency Loss 2.2300e+00 (2.2011e+00)	Entropy 2.9914e+00 (2.9912e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.985572576522827, 'consistency': 1.4014649391174316, 'total_loss': -1.5841076374053955}], 'lowest_loss_head': 0, 'lowest_loss': -1.5841076374053955}
No new lowest loss on validation set: -1.5936 -> -1.5841
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.2208697857233422, 'ARI': 0.08929414985996952, 'NMI': 0.2371218930635622, 'ACC Top-5': 0.5140737923164701, 'hungarian_match': [(0, 3), (1, 17), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 18), (8, 11), (9, 19), (10, 10), (11, 5), (12, 13), (13, 9), (14, 1), (15, 4), (16, 8), (17, 16), (18, 7), (19, 2)]}
Checkpoint ...
[33mEpoch 50/50[0m
[33m---------------[0m
Adjusted learning rate to 0.00010
Train ...
Epoch: [49][  0/123]	Total Loss -1.2829e+01 (-1.2829e+01)	Consistency Loss 2.1335e+00 (2.1335e+00)	Entropy 2.9924e+00 (2.9924e+00)
Epoch: [49][ 25/123]	Total Loss -1.2743e+01 (-1.2789e+01)	Consistency Loss 2.2200e+00 (2.1652e+00)	Entropy 2.9926e+00 (2.9908e+00)
Epoch: [49][ 50/123]	Total Loss -1.2775e+01 (-1.2778e+01)	Consistency Loss 2.1828e+00 (2.1775e+00)	Entropy 2.9916e+00 (2.9911e+00)
Epoch: [49][ 75/123]	Total Loss -1.2760e+01 (-1.2770e+01)	Consistency Loss 2.1847e+00 (2.1842e+00)	Entropy 2.9890e+00 (2.9909e+00)
Epoch: [49][100/123]	Total Loss -1.2697e+01 (-1.2767e+01)	Consistency Loss 2.2502e+00 (2.1882e+00)	Entropy 2.9895e+00 (2.9909e+00)
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.981945753097534, 'consistency': 1.3897812366485596, 'total_loss': -1.5921645164489746}], 'lowest_loss_head': 0, 'lowest_loss': -1.5921645164489746}
No new lowest loss on validation set: -1.5936 -> -1.5922
Lowest loss head is 0
Evaluate with hungarian matching algorithm ...
{'ACC': 0.22264485862812222, 'ARI': 0.09611548604938049, 'NMI': 0.23981103851203686, 'ACC Top-5': 0.5258019525801952, 'hungarian_match': [(0, 3), (1, 17), (2, 15), (3, 6), (4, 14), (5, 0), (6, 12), (7, 18), (8, 11), (9, 2), (10, 10), (11, 5), (12, 13), (13, 4), (14, 1), (15, 9), (16, 8), (17, 19), (18, 7), (19, 16)]}
Checkpoint ...
[34mEvaluate best model based on SCAN metric at the end[0m
torch.Size([15774])
torch.Size([15774])
{'ACC': 0.21510079878280716, 'ARI': 0.09235346815736473, 'NMI': 0.24146289429120504, 'ACC Top-5': 0.5072270825408901, 'hungarian_match': [(0, 6), (1, 10), (2, 15), (3, 3), (4, 14), (5, 0), (6, 12), (7, 17), (8, 11), (9, 19), (10, 18), (11, 5), (12, 13), (13, 9), (14, 1), (15, 4), (16, 8), (17, 16), (18, 7), (19, 2)]}
